{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"TT_\" + \"BERT_Finetuned_M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt  \n",
       "0        2      test  \n",
       "1        3  training  \n",
       "2        2      test  \n",
       "3        2      test  \n",
       "4        3  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr2 = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [1], [1], [1], [0], [1], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr2.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 768)\n",
      "(1925, 768)\n",
      "(4500, 1)\n",
      "(1925, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0da6df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1703, 2797]))\n",
      "(array([0, 1]), array([ 699, 1226]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LOGISTIC REGRESSION ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 1.63 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1179\n",
      "False Positive : 45\n",
      "False Negative : 47\n",
      "True Negative : 654\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 96.324 %\n",
      "- Recall : 96.166 %\n",
      "- F1 : 0.96245\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 93.295 %\n",
      "- Recall : 93.562 %\n",
      "- F1 : 0.93429\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 95.221 %\n",
      "- Precision : 94.809 %\n",
      "- Recall : 94.864 %\n",
      "- F1 : 0.94836\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 95.221, 94.809, 94.864, 0.94836, 96.324, 96.166, 0.96245, 93.295, 93.562, 0.93429, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.0 seconds\n",
      "Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1189\n",
      "False Positive : 40\n",
      "False Negative : 37\n",
      "True Negative : 659\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 96.745 %\n",
      "- Recall : 96.982 %\n",
      "- F1 : 0.96864\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 94.684 %\n",
      "- Recall : 94.278 %\n",
      "- F1 : 0.9448\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 96.0 %\n",
      "- Precision : 95.715 %\n",
      "- Recall : 95.63 %\n",
      "- F1 : 0.95672\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 96.0, 95.715, 95.63, 0.95672, 96.745, 96.982, 0.96864, 94.684, 94.278, 0.9448, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 2.19 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1171\n",
      "False Positive : 59\n",
      "False Negative : 55\n",
      "True Negative : 640\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 95.203 %\n",
      "- Recall : 95.514 %\n",
      "- F1 : 0.95358\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 92.086 %\n",
      "- Recall : 91.559 %\n",
      "- F1 : 0.91822\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 94.078 %\n",
      "- Precision : 93.645 %\n",
      "- Recall : 93.537 %\n",
      "- F1 : 0.93591\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 94.078, 93.645, 93.537, 0.93591, 95.203, 95.514, 0.95358, 92.086, 91.559, 0.91822, \n",
      "--- END ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate()\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 95.792\n",
      "Saving after new best accuracy : 96.104\n",
      "Saving after new best accuracy : 96.208\n",
      "Saving after new best accuracy : 96.26\n",
      "Saving after new best accuracy : 96.416\n",
      "Saving after new best accuracy : 96.468\n",
      "-- Epoch 50, Train Loss : 1.103175438940525, Test Loss : 0.16209563612937927\n",
      "-- Epoch 100, Train Loss : 0.2621596026001498, Test Loss : 0.3080274760723114\n",
      "-- Epoch 150, Train Loss : 0.1640602854313329, Test Loss : 0.4337005317211151\n",
      "-- Epoch 200, Train Loss : 19.826052665244788, Test Loss : 1.5851019620895386\n",
      "-- Epoch 250, Train Loss : 0.23820039723068476, Test Loss : 0.3563900589942932\n",
      "-- Epoch 300, Train Loss : 0.05334027562639676, Test Loss : 0.5179547071456909\n",
      "-- Epoch 350, Train Loss : 0.0756923646258656, Test Loss : 0.3780054450035095\n",
      "-- Epoch 400, Train Loss : 0.007484805363674241, Test Loss : 0.5975538492202759\n",
      "-- Epoch 450, Train Loss : 0.0071676367424515774, Test Loss : 0.6712994575500488\n",
      "-- Epoch 500, Train Loss : 0.006804065329106379, Test Loss : 0.7267091274261475\n",
      "-- Epoch 550, Train Loss : 0.006590555930301889, Test Loss : 0.7884052395820618\n",
      "-- Epoch 600, Train Loss : 0.006267135665211754, Test Loss : 0.9309628009796143\n",
      "-- Epoch 650, Train Loss : 0.005823322181527146, Test Loss : 1.0280486345291138\n",
      "-- Epoch 700, Train Loss : 0.005688455423069172, Test Loss : 1.0896397829055786\n",
      "-- Epoch 750, Train Loss : 0.08987225277815014, Test Loss : 0.3145090937614441\n",
      "-- Epoch 800, Train Loss : 0.029977135629451368, Test Loss : 0.5599883198738098\n",
      "-- Epoch 850, Train Loss : 0.006670851261333155, Test Loss : 0.8419679403305054\n",
      "-- Epoch 900, Train Loss : 0.006355629881454661, Test Loss : 0.9662405252456665\n",
      "-- Epoch 950, Train Loss : 0.006278386356257215, Test Loss : 1.2056199312210083\n",
      "-- Epoch 1000, Train Loss : 0.005887043621896737, Test Loss : 1.2181406021118164\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1195\n",
      "False Positive : 37\n",
      "False Negative : 31\n",
      "True Negative : 662\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 96.997 %\n",
      "- Recall : 97.471 %\n",
      "- F1 : 0.97234\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 95.527 %\n",
      "- Recall : 94.707 %\n",
      "- F1 : 0.95115\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 96.468 %\n",
      "- Precision : 96.262 %\n",
      "- Recall : 96.089 %\n",
      "- F1 : 0.96175\n",
      "- Average Confidence : 94.06 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 96.468, 96.262, 96.089, 0.96175, 96.997, 97.471, 0.97234, 95.527, 94.707, 0.95115, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr2_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=256)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6df201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
