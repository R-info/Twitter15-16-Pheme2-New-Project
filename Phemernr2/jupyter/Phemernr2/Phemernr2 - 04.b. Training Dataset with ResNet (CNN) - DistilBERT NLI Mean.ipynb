{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"TT_\" + \"DistilBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_DistilBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt  \n",
       "0        2      test  \n",
       "1        3  training  \n",
       "2        2      test  \n",
       "3        2      test  \n",
       "4        3  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr2 = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [1], [1], [1], [0], [1], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr2.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 768)\n",
      "(1925, 768)\n",
      "(4500, 1)\n",
      "(1925, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10():\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1])\n",
    "\n",
    "    \n",
    "def CNNResNet18():\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def CNNResNet34():\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def CNNResNet50():\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def CNNResNet101():\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def CNNResNet152():\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "                    outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                \n",
    "                loss = self.criterion(outputs, targets)\n",
    "                try:\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                except Exception:\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_ResNet10_CNN_TT_DistilBERT_NLI_Mean\n",
      "Using cuda\n",
      "Saving after new best accuracy : 63.688\n",
      "Saving after new best accuracy : 68.935\n",
      "Saving after new best accuracy : 79.481\n",
      "Saving after new best accuracy : 81.87\n",
      "Saving after new best accuracy : 82.442\n",
      "Saving after new best accuracy : 82.649\n",
      "Saving after new best accuracy : 82.701\n",
      "Saving after new best accuracy : 83.065\n",
      "Saving after new best accuracy : 83.584\n",
      "Saving after new best accuracy : 83.896\n",
      "Saving after new best accuracy : 84.26\n",
      "Saving after new best accuracy : 84.571\n",
      "Saving after new best accuracy : 84.935\n",
      "Saving after new best accuracy : 85.195\n",
      "Saving after new best accuracy : 85.299\n",
      "Saving after new best accuracy : 85.351\n",
      "Saving after new best accuracy : 85.455\n",
      "Saving after new best accuracy : 85.61\n",
      "Saving after new best accuracy : 85.87\n",
      "-- Epoch 50, Train Loss : 0.15725572034716606, Test Loss : 0.36761748790740967\n",
      "-- Epoch 100, Train Loss : 0.03736104303970933, Test Loss : 0.41845691204071045\n",
      "-- Epoch 150, Train Loss : 0.016681941342540085, Test Loss : 0.45604294538497925\n",
      "-- Epoch 200, Train Loss : 0.010430325462948531, Test Loss : 0.48549768328666687\n",
      "-- Epoch 250, Train Loss : 0.00791681301780045, Test Loss : 0.5091777443885803\n",
      "-- Epoch 300, Train Loss : 0.006803176715038717, Test Loss : 0.5285214781761169\n",
      "-- Epoch 350, Train Loss : 0.006274800543906167, Test Loss : 0.5447180867195129\n",
      "-- Epoch 400, Train Loss : 0.005990966281387955, Test Loss : 0.5584251880645752\n",
      "-- Epoch 450, Train Loss : 0.005833354938658886, Test Loss : 0.570339024066925\n",
      "-- Epoch 500, Train Loss : 0.0057179581199306995, Test Loss : 0.5806820392608643\n",
      "-- Epoch 550, Train Loss : 0.005629824823699892, Test Loss : 0.5893657207489014\n",
      "Saving after new best accuracy : 85.922\n",
      "-- Epoch 600, Train Loss : 0.005507427958946209, Test Loss : 0.5969725251197815\n",
      "Saving after new best accuracy : 85.974\n",
      "Saving after new best accuracy : 86.026\n",
      "Saving after new best accuracy : 86.078\n",
      "-- Epoch 650, Train Loss : 0.00542675989709096, Test Loss : 0.6033816933631897\n",
      "Saving after new best accuracy : 86.13\n",
      "-- Epoch 700, Train Loss : 0.005286397543386556, Test Loss : 0.6101795434951782\n",
      "-- Epoch 750, Train Loss : 0.005229792957834434, Test Loss : 0.6156298518180847\n",
      "-- Epoch 800, Train Loss : 0.0049805680428107735, Test Loss : 0.6215463876724243\n",
      "-- Epoch 850, Train Loss : 0.004823348452191567, Test Loss : 0.6276571154594421\n",
      "-- Epoch 900, Train Loss : 0.004580963919579517, Test Loss : 0.6319671869277954\n",
      "-- Epoch 950, Train Loss : 0.004307780414819717, Test Loss : 0.6371431946754456\n",
      "-- Epoch 1000, Train Loss : 0.004112939775950508, Test Loss : 0.6454336047172546\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1108\n",
      "False Positive : 155\n",
      "False Negative : 118\n",
      "True Negative : 544\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.728 %\n",
      "- Recall : 90.375 %\n",
      "- F1 : 0.89032\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 82.175 %\n",
      "- Recall : 77.825 %\n",
      "- F1 : 0.79941\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.818 %\n",
      "- Precision : 84.951 %\n",
      "- Recall : 84.1 %\n",
      "- F1 : 0.84523\n",
      "- Average Confidence : 93.18 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 85.818, 84.951, 84.1, 0.84523, 87.728, 90.375, 0.89032, 82.175, 77.825, 0.79941, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_ResNet10_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors.reshape(test_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_ResNet18_CNN_TT_DistilBERT_NLI_Mean\n",
      "Using cuda\n",
      "Saving after new best accuracy : 63.688\n",
      "Saving after new best accuracy : 63.844\n",
      "Saving after new best accuracy : 66.494\n",
      "Saving after new best accuracy : 75.325\n",
      "Saving after new best accuracy : 80.779\n",
      "Saving after new best accuracy : 81.247\n",
      "Saving after new best accuracy : 83.169\n",
      "Saving after new best accuracy : 83.325\n",
      "Saving after new best accuracy : 83.429\n",
      "Saving after new best accuracy : 83.481\n",
      "Saving after new best accuracy : 83.584\n",
      "Saving after new best accuracy : 83.688\n",
      "Saving after new best accuracy : 83.74\n",
      "Saving after new best accuracy : 83.792\n",
      "Saving after new best accuracy : 83.896\n",
      "Saving after new best accuracy : 84.052\n",
      "Saving after new best accuracy : 84.312\n",
      "-- Epoch 50, Train Loss : 0.06556728715077043, Test Loss : 0.4044877886772156\n",
      "-- Epoch 100, Train Loss : 0.01790609583258629, Test Loss : 0.4454245865345001\n",
      "-- Epoch 150, Train Loss : 0.009696815337520093, Test Loss : 0.4754177927970886\n",
      "Saving after new best accuracy : 84.364\n",
      "Saving after new best accuracy : 84.416\n",
      "-- Epoch 200, Train Loss : 0.0069511768524535, Test Loss : 0.4981692433357239\n",
      "-- Epoch 250, Train Loss : 0.005757936160080135, Test Loss : 0.516542375087738\n",
      "-- Epoch 300, Train Loss : 0.005006780527764931, Test Loss : 0.5324878096580505\n",
      "-- Epoch 350, Train Loss : 0.005023924401029944, Test Loss : 0.5438172221183777\n",
      "-- Epoch 400, Train Loss : 0.004225582575600129, Test Loss : 0.557159423828125\n",
      "-- Epoch 450, Train Loss : 0.00392545823706314, Test Loss : 0.5681332945823669\n",
      "-- Epoch 500, Train Loss : 0.0037708540403400548, Test Loss : 0.5787102580070496\n",
      "Saving after new best accuracy : 84.468\n",
      "-- Epoch 550, Train Loss : 0.0054834632319398224, Test Loss : 0.5981965065002441\n",
      "-- Epoch 600, Train Loss : 0.0032372404930356424, Test Loss : 0.5998697280883789\n",
      "-- Epoch 650, Train Loss : 0.0031597874585713726, Test Loss : 0.6061905026435852\n",
      "-- Epoch 700, Train Loss : 0.003031332500540884, Test Loss : 0.622042179107666\n",
      "-- Epoch 750, Train Loss : 0.002622188945679227, Test Loss : 0.6269228458404541\n",
      "-- Epoch 800, Train Loss : 0.0026033362300950103, Test Loss : 0.6494922041893005\n",
      "-- Epoch 850, Train Loss : 0.0023708941553195473, Test Loss : 0.6479645371437073\n",
      "-- Epoch 900, Train Loss : 0.0022043339449737687, Test Loss : 0.6562609672546387\n",
      "-- Epoch 950, Train Loss : 0.002164251594876987, Test Loss : 0.6648080945014954\n",
      "-- Epoch 1000, Train Loss : 0.001958984575139766, Test Loss : 0.691781759262085\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1093\n",
      "False Positive : 175\n",
      "False Negative : 133\n",
      "True Negative : 524\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 86.199 %\n",
      "- Recall : 89.152 %\n",
      "- F1 : 0.8765\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 79.756 %\n",
      "- Recall : 74.964 %\n",
      "- F1 : 0.77286\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.0 %\n",
      "- Precision : 82.978 %\n",
      "- Recall : 82.058 %\n",
      "- F1 : 0.82515\n",
      "- Average Confidence : 91.92 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 84.0, 82.978, 82.058, 0.82515, 86.199, 89.152, 0.8765, 79.756, 74.964, 0.77286, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_ResNet18_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors.reshape(test_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
