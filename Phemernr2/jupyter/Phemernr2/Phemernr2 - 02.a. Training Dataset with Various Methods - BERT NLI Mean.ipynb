{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"TT_\" + \"SBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_SBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt  \n",
       "0        2      test  \n",
       "1        3  training  \n",
       "2        2      test  \n",
       "3        2      test  \n",
       "4        3  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr2 = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [1], [1], [1], [0], [1], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr2.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 768)\n",
      "(1925, 768)\n",
      "(4500, 1)\n",
      "(1925, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0da6df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1703, 2797]))\n",
      "(array([0, 1]), array([ 699, 1226]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LOGISTIC REGRESSION ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 3.19 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1074\n",
      "False Positive : 165\n",
      "False Negative : 152\n",
      "True Negative : 534\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 86.683 %\n",
      "- Recall : 87.602 %\n",
      "- F1 : 0.8714\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 77.843 %\n",
      "- Recall : 76.395 %\n",
      "- F1 : 0.77112\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.532 %\n",
      "- Precision : 82.263 %\n",
      "- Recall : 81.998 %\n",
      "- F1 : 0.8213\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 83.532, 82.263, 81.998, 0.8213, 86.683, 87.602, 0.8714, 77.843, 76.395, 0.77112, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.0 seconds\n",
      "Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1044\n",
      "False Positive : 128\n",
      "False Negative : 182\n",
      "True Negative : 571\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 89.078 %\n",
      "- Recall : 85.155 %\n",
      "- F1 : 0.87073\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 75.83 %\n",
      "- Recall : 81.688 %\n",
      "- F1 : 0.7865\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.896 %\n",
      "- Precision : 82.454 %\n",
      "- Recall : 83.422 %\n",
      "- F1 : 0.82935\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 83.896, 82.454, 83.422, 0.82935, 89.078, 85.155, 0.87073, 75.83, 81.688, 0.7865, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 5.62 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1078\n",
      "False Positive : 202\n",
      "False Negative : 148\n",
      "True Negative : 497\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 84.219 %\n",
      "- Recall : 87.928 %\n",
      "- F1 : 0.86034\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 77.054 %\n",
      "- Recall : 71.102 %\n",
      "- F1 : 0.73958\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.818 %\n",
      "- Precision : 80.637 %\n",
      "- Recall : 79.515 %\n",
      "- F1 : 0.80072\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 81.818, 80.637, 79.515, 0.80072, 84.219, 87.928, 0.86034, 77.054, 71.102, 0.73958, \n",
      "--- END ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate()\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 73.974\n",
      "Saving after new best accuracy : 74.805\n",
      "Saving after new best accuracy : 76.623\n",
      "Saving after new best accuracy : 77.351\n",
      "Saving after new best accuracy : 78.13\n",
      "Saving after new best accuracy : 78.909\n",
      "Saving after new best accuracy : 79.325\n",
      "Saving after new best accuracy : 81.558\n",
      "Saving after new best accuracy : 83.429\n",
      "Saving after new best accuracy : 84.416\n",
      "Saving after new best accuracy : 85.247\n",
      "Saving after new best accuracy : 85.714\n",
      "Saving after new best accuracy : 86.026\n",
      "-- Epoch 50, Train Loss : 0.271586190443486, Test Loss : 0.7812384366989136\n",
      "-- Epoch 100, Train Loss : 0.060002069862093776, Test Loss : 1.1862573623657227\n",
      "-- Epoch 150, Train Loss : 0.020288523119234014, Test Loss : 1.6319211721420288\n",
      "-- Epoch 200, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 250, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 300, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 350, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 400, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 450, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 500, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 550, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 600, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 650, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 700, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 750, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 800, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 850, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 900, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 950, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 1000, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1105\n",
      "False Positive : 148\n",
      "False Negative : 121\n",
      "True Negative : 551\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 88.188 %\n",
      "- Recall : 90.131 %\n",
      "- F1 : 0.89149\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 81.994 %\n",
      "- Recall : 78.827 %\n",
      "- F1 : 0.80379\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.026 %\n",
      "- Precision : 85.091 %\n",
      "- Recall : 84.479 %\n",
      "- F1 : 0.84784\n",
      "- Average Confidence : 92.26 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 86.026, 85.091, 84.479, 0.84784, 88.188, 90.131, 0.89149, 81.994, 78.827, 0.80379, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr2_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=256)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6df201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
