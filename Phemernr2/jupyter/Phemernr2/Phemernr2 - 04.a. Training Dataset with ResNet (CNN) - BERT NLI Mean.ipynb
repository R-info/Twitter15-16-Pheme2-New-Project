{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"TT_\" + \"SBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_SBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt  \n",
       "0        2      test  \n",
       "1        3  training  \n",
       "2        2      test  \n",
       "3        2      test  \n",
       "4        3  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr2 = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [1], [1], [1], [0], [1], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr2.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 768)\n",
      "(1925, 768)\n",
      "(4500, 1)\n",
      "(1925, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10():\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1])\n",
    "\n",
    "    \n",
    "def CNNResNet18():\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def CNNResNet34():\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def CNNResNet50():\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def CNNResNet101():\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def CNNResNet152():\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "                    outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                \n",
    "                loss = self.criterion(outputs, targets)\n",
    "                try:\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                except Exception:\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_ResNet10_CNN_TT_SBERT_NLI_Mean\n",
      "Using cuda\n",
      "Saving after new best accuracy : 63.688\n",
      "Saving after new best accuracy : 64.052\n",
      "Saving after new best accuracy : 71.792\n",
      "Saving after new best accuracy : 79.844\n",
      "Saving after new best accuracy : 81.974\n",
      "Saving after new best accuracy : 82.39\n",
      "Saving after new best accuracy : 83.013\n",
      "Saving after new best accuracy : 83.221\n",
      "Saving after new best accuracy : 83.636\n",
      "Saving after new best accuracy : 83.74\n",
      "Saving after new best accuracy : 83.896\n",
      "Saving after new best accuracy : 83.948\n",
      "Saving after new best accuracy : 84.156\n",
      "Saving after new best accuracy : 84.519\n",
      "Saving after new best accuracy : 84.675\n",
      "Saving after new best accuracy : 84.987\n",
      "Saving after new best accuracy : 85.039\n",
      "Saving after new best accuracy : 85.351\n",
      "Saving after new best accuracy : 85.558\n",
      "Saving after new best accuracy : 85.61\n",
      "Saving after new best accuracy : 85.714\n",
      "-- Epoch 50, Train Loss : 0.16040929965674877, Test Loss : 0.3889833390712738\n",
      "Saving after new best accuracy : 85.766\n",
      "Saving after new best accuracy : 85.87\n",
      "Saving after new best accuracy : 85.922\n",
      "Saving after new best accuracy : 85.974\n",
      "Saving after new best accuracy : 86.286\n",
      "-- Epoch 100, Train Loss : 0.034370370907709, Test Loss : 0.4227483570575714\n",
      "-- Epoch 150, Train Loss : 0.016252870089374483, Test Loss : 0.4593920409679413\n",
      "-- Epoch 200, Train Loss : 0.010261924006044865, Test Loss : 0.48765337467193604\n",
      "-- Epoch 250, Train Loss : 0.007740539847873151, Test Loss : 0.5106502175331116\n",
      "Saving after new best accuracy : 86.338\n",
      "-- Epoch 300, Train Loss : 0.0065677967795636505, Test Loss : 0.5295441150665283\n",
      "-- Epoch 350, Train Loss : 0.006008670578012243, Test Loss : 0.5458040833473206\n",
      "-- Epoch 400, Train Loss : 0.005739816522691399, Test Loss : 0.5599074959754944\n",
      "-- Epoch 450, Train Loss : 0.00559587603493128, Test Loss : 0.5721368789672852\n",
      "-- Epoch 500, Train Loss : 0.005487002854351886, Test Loss : 0.5824950933456421\n",
      "-- Epoch 550, Train Loss : 0.005398344052082393, Test Loss : 0.5921449661254883\n",
      "-- Epoch 600, Train Loss : 0.005325849058863241, Test Loss : 0.6006748080253601\n",
      "-- Epoch 650, Train Loss : 0.005197403814236168, Test Loss : 0.6082246899604797\n",
      "-- Epoch 700, Train Loss : 0.005096986729768105, Test Loss : 0.6151156425476074\n",
      "Saving after new best accuracy : 86.39\n",
      "-- Epoch 750, Train Loss : 0.005131180529133417, Test Loss : 0.6676087379455566\n",
      "-- Epoch 800, Train Loss : 0.00478855547044077, Test Loss : 0.6716720461845398\n",
      "-- Epoch 850, Train Loss : 0.004765275836689398, Test Loss : 0.6782264709472656\n",
      "-- Epoch 900, Train Loss : 0.004466709291591542, Test Loss : 0.6822550892829895\n",
      "-- Epoch 950, Train Loss : 0.004168619809206575, Test Loss : 0.6868829131126404\n",
      "-- Epoch 1000, Train Loss : 0.003912756546924356, Test Loss : 0.6931189894676208\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1113\n",
      "False Positive : 156\n",
      "False Negative : 113\n",
      "True Negative : 543\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.707 %\n",
      "- Recall : 90.783 %\n",
      "- F1 : 0.89218\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 82.774 %\n",
      "- Recall : 77.682 %\n",
      "- F1 : 0.80148\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.026 %\n",
      "- Precision : 85.241 %\n",
      "- Recall : 84.233 %\n",
      "- F1 : 0.84734\n",
      "- Average Confidence : 92.79 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 86.026, 85.241, 84.233, 0.84734, 87.707, 90.783, 0.89218, 82.774, 77.682, 0.80148, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_ResNet10_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors.reshape(test_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_ResNet18_CNN_TT_SBERT_NLI_Mean\n",
      "Using cuda\n",
      "Saving after new best accuracy : 63.688\n",
      "Saving after new best accuracy : 68.831\n",
      "Saving after new best accuracy : 73.039\n",
      "Saving after new best accuracy : 78.234\n",
      "Saving after new best accuracy : 81.922\n",
      "Saving after new best accuracy : 82.857\n",
      "Saving after new best accuracy : 83.221\n",
      "Saving after new best accuracy : 83.532\n",
      "Saving after new best accuracy : 83.74\n",
      "Saving after new best accuracy : 83.792\n",
      "Saving after new best accuracy : 83.948\n",
      "Saving after new best accuracy : 84.104\n",
      "Saving after new best accuracy : 84.364\n",
      "Saving after new best accuracy : 84.468\n",
      "Saving after new best accuracy : 84.519\n",
      "-- Epoch 50, Train Loss : 0.06425832491368055, Test Loss : 0.4019187390804291\n",
      "Saving after new best accuracy : 84.727\n",
      "Saving after new best accuracy : 84.831\n",
      "Saving after new best accuracy : 84.883\n",
      "Saving after new best accuracy : 84.935\n",
      "-- Epoch 100, Train Loss : 0.017494357307441533, Test Loss : 0.4438692033290863\n",
      "Saving after new best accuracy : 84.987\n",
      "Saving after new best accuracy : 85.039\n",
      "-- Epoch 150, Train Loss : 0.009461919777095318, Test Loss : 0.4731665849685669\n",
      "Saving after new best accuracy : 85.091\n",
      "-- Epoch 200, Train Loss : 0.006799430208047852, Test Loss : 0.4953930675983429\n",
      "Saving after new best accuracy : 85.143\n",
      "-- Epoch 250, Train Loss : 0.005622211407171562, Test Loss : 0.5136781930923462\n",
      "Saving after new best accuracy : 85.195\n",
      "-- Epoch 300, Train Loss : 0.005091402577818371, Test Loss : 0.5286538004875183\n",
      "-- Epoch 350, Train Loss : 0.00457484474463854, Test Loss : 0.5421624779701233\n",
      "-- Epoch 400, Train Loss : 0.004284603695850819, Test Loss : 0.5531493425369263\n",
      "-- Epoch 450, Train Loss : 0.004033452511066571, Test Loss : 0.5632585883140564\n",
      "Saving after new best accuracy : 85.299\n",
      "-- Epoch 500, Train Loss : 0.0038533936385647394, Test Loss : 0.5722266435623169\n",
      "-- Epoch 550, Train Loss : 0.004015638442069758, Test Loss : 0.5801223516464233\n",
      "-- Epoch 600, Train Loss : 0.0034861887761508115, Test Loss : 0.5902721285820007\n",
      "-- Epoch 650, Train Loss : 0.003237600853026379, Test Loss : 0.5948769450187683\n",
      "-- Epoch 700, Train Loss : 0.0035556428265408613, Test Loss : 0.6110160946846008\n",
      "-- Epoch 750, Train Loss : 0.0026124819396500243, Test Loss : 0.6134717464447021\n",
      "-- Epoch 800, Train Loss : 0.002509745925635798, Test Loss : 0.6695096492767334\n",
      "-- Epoch 850, Train Loss : 0.0022570893834199524, Test Loss : 0.6786147952079773\n",
      "-- Epoch 900, Train Loss : 0.002156872684281552, Test Loss : 0.6796277165412903\n",
      "-- Epoch 950, Train Loss : 0.0019795491816694266, Test Loss : 0.696862518787384\n",
      "-- Epoch 1000, Train Loss : 0.0019547254696590244, Test Loss : 0.704878032207489\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1099\n",
      "False Positive : 165\n",
      "False Negative : 127\n",
      "True Negative : 534\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 86.946 %\n",
      "- Recall : 89.641 %\n",
      "- F1 : 0.88273\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 80.787 %\n",
      "- Recall : 76.395 %\n",
      "- F1 : 0.78529\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.831 %\n",
      "- Precision : 83.866 %\n",
      "- Recall : 83.018 %\n",
      "- F1 : 0.8344\n",
      "- Average Confidence : 92.15 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 84.831, 83.866, 83.018, 0.8344, 86.946, 89.641, 0.88273, 80.787, 76.395, 0.78529, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_ResNet18_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors.reshape(test_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
