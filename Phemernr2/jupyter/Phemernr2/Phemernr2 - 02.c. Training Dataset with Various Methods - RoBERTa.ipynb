{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"TT_\" + \"RoBERTa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_RoBERTa_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt  \n",
       "0        2      test  \n",
       "1        3  training  \n",
       "2        2      test  \n",
       "3        2      test  \n",
       "4        3  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr2 = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [1], [1], [1], [0], [1], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr2.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 768)\n",
      "(1925, 768)\n",
      "(4500, 1)\n",
      "(1925, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0da6df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1703, 2797]))\n",
      "(array([0, 1]), array([ 699, 1226]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LOGISTIC REGRESSION ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 0.99 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1073\n",
      "False Positive : 185\n",
      "False Negative : 153\n",
      "True Negative : 514\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 85.294 %\n",
      "- Recall : 87.52 %\n",
      "- F1 : 0.86393\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 77.061 %\n",
      "- Recall : 73.534 %\n",
      "- F1 : 0.75256\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.442 %\n",
      "- Precision : 81.178 %\n",
      "- Recall : 80.527 %\n",
      "- F1 : 0.80851\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 82.442, 81.178, 80.527, 0.80851, 85.294, 87.52, 0.86393, 77.061, 73.534, 0.75256, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.0 seconds\n",
      "Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1007\n",
      "False Positive : 148\n",
      "False Negative : 219\n",
      "True Negative : 551\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.186 %\n",
      "- Recall : 82.137 %\n",
      "- F1 : 0.84586\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 71.558 %\n",
      "- Recall : 78.827 %\n",
      "- F1 : 0.75017\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 80.935 %\n",
      "- Precision : 79.372 %\n",
      "- Recall : 80.482 %\n",
      "- F1 : 0.79923\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 80.935, 79.372, 80.482, 0.79923, 87.186, 82.137, 0.84586, 71.558, 78.827, 0.75017, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 6.99 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1057\n",
      "False Positive : 162\n",
      "False Negative : 169\n",
      "True Negative : 537\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 86.71 %\n",
      "- Recall : 86.215 %\n",
      "- F1 : 0.86462\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 76.062 %\n",
      "- Recall : 76.824 %\n",
      "- F1 : 0.76441\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.805 %\n",
      "- Precision : 81.386 %\n",
      "- Recall : 81.52 %\n",
      "- F1 : 0.81453\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 82.805, 81.386, 81.52, 0.81453, 86.71, 86.215, 0.86462, 76.062, 76.824, 0.76441, \n",
      "--- END ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate()\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 63.688\n",
      "Saving after new best accuracy : 75.481\n",
      "Saving after new best accuracy : 75.532\n",
      "Saving after new best accuracy : 75.636\n",
      "Saving after new best accuracy : 76.208\n",
      "Saving after new best accuracy : 76.727\n",
      "Saving after new best accuracy : 77.039\n",
      "Saving after new best accuracy : 77.351\n",
      "Saving after new best accuracy : 77.403\n",
      "Saving after new best accuracy : 77.87\n",
      "Saving after new best accuracy : 78.13\n",
      "Saving after new best accuracy : 78.597\n",
      "Saving after new best accuracy : 78.909\n",
      "Saving after new best accuracy : 79.844\n",
      "Saving after new best accuracy : 80.104\n",
      "Saving after new best accuracy : 80.519\n",
      "Saving after new best accuracy : 82.13\n",
      "Saving after new best accuracy : 83.481\n",
      "Saving after new best accuracy : 83.584\n",
      "-- Epoch 50, Train Loss : 2.0036925673484802, Test Loss : 0.6906856298446655\n",
      "Saving after new best accuracy : 83.636\n",
      "Saving after new best accuracy : 84.156\n",
      "Saving after new best accuracy : 84.208\n",
      "Saving after new best accuracy : 84.468\n",
      "-- Epoch 100, Train Loss : 0.3090820701327175, Test Loss : 3.3682291507720947\n",
      "-- Epoch 150, Train Loss : 0.017704280573525466, Test Loss : 1.2470797300338745\n",
      "-- Epoch 200, Train Loss : 0.008510282976203598, Test Loss : 1.6105992794036865\n",
      "-- Epoch 250, Train Loss : 0.007094383845469565, Test Loss : 1.8543533086776733\n",
      "-- Epoch 300, Train Loss : 0.006333421833005559, Test Loss : 2.0683341026306152\n",
      "-- Epoch 350, Train Loss : 0.005864173494501301, Test Loss : 2.3223814964294434\n",
      "-- Epoch 400, Train Loss : 0.005657235156149909, Test Loss : 2.607692241668701\n",
      "-- Epoch 450, Train Loss : 0.0056296579900845245, Test Loss : 2.93135929107666\n",
      "-- Epoch 500, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 550, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 600, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 650, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 700, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 750, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 800, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 850, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 900, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 950, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n",
      "-- Epoch 1000, Train Loss : 684.3327713012695, Test Loss : 36.31168746948242\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1013\n",
      "False Positive : 86\n",
      "False Negative : 213\n",
      "True Negative : 613\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 92.175 %\n",
      "- Recall : 82.626 %\n",
      "- F1 : 0.8714\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 74.213 %\n",
      "- Recall : 87.697 %\n",
      "- F1 : 0.80393\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.468 %\n",
      "- Precision : 83.194 %\n",
      "- Recall : 85.162 %\n",
      "- F1 : 0.84166\n",
      "- Average Confidence : 92.21 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 84.468, 83.194, 85.162, 0.84166, 92.175, 82.626, 0.8714, 74.213, 87.697, 0.80393, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr2_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=256)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6df201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
