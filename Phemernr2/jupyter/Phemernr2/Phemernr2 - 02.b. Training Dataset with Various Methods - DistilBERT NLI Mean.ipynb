{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"TT_\" + \"DistilBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_DistilBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt  \n",
       "0        2      test  \n",
       "1        3  training  \n",
       "2        2      test  \n",
       "3        2      test  \n",
       "4        3  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr2 = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [1], [1], [1], [0], [1], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr2.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'training'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 768)\n",
      "(1925, 768)\n",
      "(4500, 1)\n",
      "(1925, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0da6df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1703, 2797]))\n",
      "(array([0, 1]), array([ 699, 1226]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LOGISTIC REGRESSION ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 3.23 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1069\n",
      "False Positive : 159\n",
      "False Negative : 157\n",
      "True Negative : 540\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.052 %\n",
      "- Recall : 87.194 %\n",
      "- F1 : 0.87123\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 77.475 %\n",
      "- Recall : 77.253 %\n",
      "- F1 : 0.77364\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.584 %\n",
      "- Precision : 82.264 %\n",
      "- Recall : 82.224 %\n",
      "- F1 : 0.82244\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 83.584, 82.264, 82.224, 0.82244, 87.052, 87.194, 0.87123, 77.475, 77.253, 0.77364, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.0 seconds\n",
      "Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1031\n",
      "False Positive : 117\n",
      "False Negative : 195\n",
      "True Negative : 582\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 89.808 %\n",
      "- Recall : 84.095 %\n",
      "- F1 : 0.86858\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 74.903 %\n",
      "- Recall : 83.262 %\n",
      "- F1 : 0.78862\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.792 %\n",
      "- Precision : 82.356 %\n",
      "- Recall : 83.678 %\n",
      "- F1 : 0.83012\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 83.792, 82.356, 83.678, 0.83012, 89.808, 84.095, 0.86858, 74.903, 83.262, 0.78862, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 5.58 seconds\n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1040\n",
      "False Positive : 155\n",
      "False Negative : 186\n",
      "True Negative : 544\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.029 %\n",
      "- Recall : 84.829 %\n",
      "- F1 : 0.85915\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 74.521 %\n",
      "- Recall : 77.825 %\n",
      "- F1 : 0.76137\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.286 %\n",
      "- Precision : 80.775 %\n",
      "- Recall : 81.327 %\n",
      "- F1 : 0.8105\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 82.286, 80.775, 81.327, 0.8105, 87.029, 84.829, 0.85915, 74.521, 77.825, 0.76137, \n",
      "--- END ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate()\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 73.974\n",
      "Saving after new best accuracy : 76.104\n",
      "Saving after new best accuracy : 76.26\n",
      "Saving after new best accuracy : 76.416\n",
      "Saving after new best accuracy : 77.87\n",
      "Saving after new best accuracy : 77.974\n",
      "Saving after new best accuracy : 79.169\n",
      "Saving after new best accuracy : 81.195\n",
      "Saving after new best accuracy : 83.74\n",
      "Saving after new best accuracy : 84.779\n",
      "Saving after new best accuracy : 85.61\n",
      "Saving after new best accuracy : 85.818\n",
      "Saving after new best accuracy : 85.922\n",
      "-- Epoch 50, Train Loss : 0.43655667267739773, Test Loss : 0.7571320533752441\n",
      "Saving after new best accuracy : 86.078\n",
      "-- Epoch 100, Train Loss : 0.0716951662034262, Test Loss : 0.9411075711250305\n",
      "-- Epoch 150, Train Loss : 0.03079316449293401, Test Loss : 1.474707007408142\n",
      "-- Epoch 200, Train Loss : 0.025649277511547552, Test Loss : 1.8751726150512695\n",
      "-- Epoch 250, Train Loss : 0.02065279911221296, Test Loss : 2.3388025760650635\n",
      "-- Epoch 300, Train Loss : 0.08939464803552255, Test Loss : 1.098500370979309\n",
      "-- Epoch 350, Train Loss : 0.012434699739969801, Test Loss : 1.9137904644012451\n",
      "-- Epoch 400, Train Loss : 0.007934263327115332, Test Loss : 2.4431850910186768\n",
      "-- Epoch 450, Train Loss : 0.006394090556113952, Test Loss : 2.791072368621826\n",
      "-- Epoch 500, Train Loss : 0.006204252860015913, Test Loss : 2.9762001037597656\n",
      "-- Epoch 550, Train Loss : 0.11545250820927322, Test Loss : 0.8190017342567444\n",
      "-- Epoch 600, Train Loss : 0.029908311931649223, Test Loss : 1.2345412969589233\n",
      "Saving after new best accuracy : 86.13\n",
      "-- Epoch 650, Train Loss : 0.01995020961476257, Test Loss : 1.6684739589691162\n",
      "Saving after new best accuracy : 86.182\n",
      "-- Epoch 700, Train Loss : 0.015128716022445587, Test Loss : 1.917237401008606\n",
      "Saving after new best accuracy : 86.234\n",
      "-- Epoch 750, Train Loss : 0.012223850264490466, Test Loss : 2.261871814727783\n",
      "-- Epoch 800, Train Loss : 0.5191878117620945, Test Loss : 0.6211653351783752\n",
      "-- Epoch 850, Train Loss : 0.03515208151657134, Test Loss : 1.4070985317230225\n",
      "-- Epoch 900, Train Loss : 0.02006109196372563, Test Loss : 1.8094598054885864\n",
      "-- Epoch 950, Train Loss : 0.014537054836182506, Test Loss : 2.2004342079162598\n",
      "-- Epoch 1000, Train Loss : 0.009365132150378486, Test Loss : 2.544105291366577\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1925, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 1105\n",
      "False Positive : 144\n",
      "False Negative : 121\n",
      "True Negative : 555\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 88.471 %\n",
      "- Recall : 90.131 %\n",
      "- F1 : 0.89293\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 82.101 %\n",
      "- Recall : 79.399 %\n",
      "- F1 : 0.80727\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.234 %\n",
      "- Precision : 85.286 %\n",
      "- Recall : 84.765 %\n",
      "- F1 : 0.85025\n",
      "- Average Confidence : 97.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 86.234, 85.286, 84.765, 0.85025, 88.471, 90.131, 0.89293, 82.101, 79.399, 0.80727, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr2_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(test_vectors),\n",
    "                torch.Tensor(test_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=256)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6df201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
