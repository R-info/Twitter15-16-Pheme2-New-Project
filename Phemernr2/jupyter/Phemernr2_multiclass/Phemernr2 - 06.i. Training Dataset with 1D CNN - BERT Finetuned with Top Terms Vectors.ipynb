{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNTF\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label2\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/phemernr2-multiclass_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "        \n",
    "bigram_vector_base = bigram_vector_base[:bigram_limit]\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519, 1)\n",
      "(1456, 1519, 1)\n",
      "(630, 1519, 1)\n",
      "(4339,)\n",
      "(1456,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 83.31\n",
      "-- Epoch 50, Train Loss : 6.711415767669678, Test Loss : 0.9069905281066895\n",
      "-- Epoch 100, Train Loss : 6.708506643772125, Test Loss : 0.9072178602218628\n",
      "Saving after new best accuracy : 83.448\n",
      "Saving after new best accuracy : 83.516\n",
      "-- Epoch 150, Train Loss : 6.707107245922089, Test Loss : 0.9063379764556885\n",
      "Saving after new best accuracy : 83.585\n",
      "-- Epoch 200, Train Loss : 6.706644535064697, Test Loss : 0.9062657356262207\n",
      "-- Epoch 250, Train Loss : 6.706429898738861, Test Loss : 0.9062239527702332\n",
      "-- Epoch 300, Train Loss : 6.706321895122528, Test Loss : 0.9062413573265076\n",
      "-- Epoch 350, Train Loss : 6.7062641978263855, Test Loss : 0.9062656164169312\n",
      "-- Epoch 400, Train Loss : 6.706232249736786, Test Loss : 0.9063240885734558\n",
      "-- Epoch 450, Train Loss : 6.706212997436523, Test Loss : 0.9064450263977051\n",
      "-- Epoch 500, Train Loss : 6.70617938041687, Test Loss : 0.9066926836967468\n",
      "-- Epoch 550, Train Loss : 6.704825162887573, Test Loss : 0.9068124890327454\n",
      "Saving after new best accuracy : 83.654\n",
      "-- Epoch 600, Train Loss : 6.702162504196167, Test Loss : 0.9052540063858032\n",
      "Saving after new best accuracy : 83.723\n",
      "-- Epoch 650, Train Loss : 6.702102720737457, Test Loss : 0.9050925374031067\n",
      "-- Epoch 700, Train Loss : 6.702085435390472, Test Loss : 0.9049769639968872\n",
      "-- Epoch 750, Train Loss : 6.702076971530914, Test Loss : 0.9048882126808167\n",
      "-- Epoch 800, Train Loss : 6.702072262763977, Test Loss : 0.9048070311546326\n",
      "-- Epoch 850, Train Loss : 6.702069282531738, Test Loss : 0.9047306776046753\n",
      "-- Epoch 900, Train Loss : 6.702067077159882, Test Loss : 0.9046622514724731\n",
      "-- Epoch 950, Train Loss : 6.702065706253052, Test Loss : 0.9046006202697754\n",
      "-- Epoch 1000, Train Loss : 6.70206481218338, Test Loss : 0.9045542478561401\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 180.71 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456])\n",
      "1456 vs 1456\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.735 %\n",
      "- Recall : 92.367 %\n",
      "- F1 : 0.90515\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 74.597 %\n",
      "- Recall : 72.549 %\n",
      "- F1 : 0.73559\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 70.588 %\n",
      "- Recall : 63.158 %\n",
      "- F1 : 0.66667\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 78.626 %\n",
      "- Recall : 71.034 %\n",
      "- F1 : 0.74638\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.723 %\n",
      "- Precision : 78.137 %\n",
      "- Recall : 74.777 %\n",
      "- F1 : 0.7642\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 83.723, 78.137, 74.777, 0.7642, 88.735, 92.367, 0.90515, 74.597, 72.549, 0.73559, 70.588, 63.158, 0.66667, 78.626, 71.034, 0.74638, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630])\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 90.307 %\n",
      "- Recall : 95.739 %\n",
      "- F1 : 0.92944\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 76.923 %\n",
      "- Recall : 71.429 %\n",
      "- F1 : 0.74074\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 83.333 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.74074\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 89.286 %\n",
      "- Recall : 86.207 %\n",
      "- F1 : 0.87719\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.619 %\n",
      "- Precision : 84.962 %\n",
      "- Recall : 80.01 %\n",
      "- F1 : 0.82412\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 87.619, 84.962, 80.01, 0.82412, 90.307, 95.739, 0.92944, 76.923, 71.429, 0.74074, 83.333, 66.667, 0.74074, 89.286, 86.207, 0.87719, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
