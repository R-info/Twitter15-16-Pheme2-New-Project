{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    testting  \n",
       "1        3  training    training  \n",
       "2        2      test  validation  \n",
       "3        2      test    training  \n",
       "4        3  training    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4323, 768)\n",
      "(1418, 768)\n",
      "(684, 768)\n",
      "(4323,)\n",
      "(1418,)\n",
      "(684,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input, n_output)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1], n_output)\n",
    "\n",
    "    \n",
    "def CNNResNet18(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet34(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet50(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet101(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet152(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3], n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        \n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "#                     outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_multiclass_ResNet10_CNN_RoBERTa_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 62.271\n",
      "Saving after new best accuracy : 69.394\n",
      "Saving after new best accuracy : 79.69\n",
      "Saving after new best accuracy : 84.274\n",
      "Saving after new best accuracy : 84.485\n",
      "Saving after new best accuracy : 84.556\n",
      "Saving after new best accuracy : 84.626\n",
      "Saving after new best accuracy : 84.697\n",
      "Saving after new best accuracy : 84.767\n",
      "-- Epoch 50, Train Loss : 0.004670880065532401, Test Loss : 1.969792127609253\n",
      "Saving after new best accuracy : 84.838\n",
      "-- Epoch 100, Train Loss : 0.004260498877556529, Test Loss : 2.0706942081451416\n",
      "-- Epoch 150, Train Loss : 0.004232010192936286, Test Loss : 2.1282248497009277\n",
      "-- Epoch 200, Train Loss : 0.004204308432235848, Test Loss : 2.164074182510376\n",
      "-- Epoch 250, Train Loss : 0.004144380982324947, Test Loss : 2.1866698265075684\n",
      "-- Epoch 300, Train Loss : 0.004049915414725547, Test Loss : 2.2004342079162598\n",
      "-- Epoch 350, Train Loss : 0.0039017137023620307, Test Loss : 2.20633602142334\n",
      "-- Epoch 400, Train Loss : 0.0036987737694289535, Test Loss : 2.208482265472412\n",
      "-- Epoch 450, Train Loss : 0.003428616319069988, Test Loss : 2.207404613494873\n",
      "-- Epoch 500, Train Loss : 0.0031157425983110443, Test Loss : 2.2081151008605957\n",
      "-- Epoch 550, Train Loss : 0.002783501638987218, Test Loss : 2.2122678756713867\n",
      "-- Epoch 600, Train Loss : 0.002491973325959407, Test Loss : 2.220583915710449\n",
      "-- Epoch 650, Train Loss : 0.0022596957269342965, Test Loss : 2.2330498695373535\n",
      "-- Epoch 700, Train Loss : 0.0020913179741910426, Test Loss : 2.2556099891662598\n",
      "-- Epoch 750, Train Loss : 0.001972105370441568, Test Loss : 2.2724738121032715\n",
      "-- Epoch 800, Train Loss : 0.0018931333920590987, Test Loss : 2.293142795562744\n",
      "-- Epoch 850, Train Loss : 0.0018378860395387164, Test Loss : 2.3175976276397705\n",
      "-- Epoch 900, Train Loss : 0.001799362622477929, Test Loss : 2.3355672359466553\n",
      "-- Epoch 950, Train Loss : 0.0017737884045345709, Test Loss : 2.3593051433563232\n",
      "-- Epoch 1000, Train Loss : 0.0017527977286135865, Test Loss : 2.377220392227173\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 667.24 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1418])\n",
      "1418 vs 1418\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.852 %\n",
      "- Recall : 92.072 %\n",
      "- F1 : 0.90434\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 76.763 %\n",
      "- Recall : 76.763 %\n",
      "- F1 : 0.76763\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 68.148 %\n",
      "- Recall : 60.927 %\n",
      "- F1 : 0.64336\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.976 %\n",
      "- Recall : 79.021 %\n",
      "- F1 : 0.83704\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.838 %\n",
      "- Precision : 80.685 %\n",
      "- Recall : 77.196 %\n",
      "- F1 : 0.78902\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet10_CNN_RoBERTa_Finetuned Validation, 84.838, 80.685, 77.196, 0.78902, 88.852, 92.072, 0.90434, 76.763, 76.763, 0.76763, 68.148, 60.927, 0.64336, 88.976, 79.021, 0.83704, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([684])\n",
      "684 vs 684\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.761 %\n",
      "- Recall : 89.791 %\n",
      "- F1 : 0.89273\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 66.957 %\n",
      "- Recall : 70.0 %\n",
      "- F1 : 0.68444\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 68.493 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.67568\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 76.667 %\n",
      "- Recall : 67.647 %\n",
      "- F1 : 0.71875\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.871 %\n",
      "- Precision : 75.219 %\n",
      "- Recall : 73.526 %\n",
      "- F1 : 0.74363\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet10_CNN_RoBERTa_Finetuned Validation, 81.871, 75.219, 73.526, 0.74363, 88.761, 89.791, 0.89273, 66.957, 70.0, 0.68444, 68.493, 66.667, 0.67568, 76.667, 67.647, 0.71875, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_multiclass_ResNet10_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_multiclass_ResNet18_CNN_RoBERTa_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 16.996\n",
      "Saving after new best accuracy : 73.131\n",
      "Saving after new best accuracy : 80.254\n",
      "Saving after new best accuracy : 84.767\n",
      "Saving after new best accuracy : 84.908\n",
      "-- Epoch 50, Train Loss : 0.0032819712650962174, Test Loss : 2.191436290740967\n",
      "-- Epoch 100, Train Loss : 0.003455287984252209, Test Loss : 2.2244021892547607\n",
      "-- Epoch 150, Train Loss : 0.0036950095473002875, Test Loss : 2.244612216949463\n",
      "-- Epoch 200, Train Loss : 0.0038356041422957787, Test Loss : 2.2559609413146973\n",
      "-- Epoch 250, Train Loss : 0.003911698790943774, Test Loss : 2.2624967098236084\n",
      "-- Epoch 300, Train Loss : 0.00392941631253052, Test Loss : 2.264785051345825\n",
      "-- Epoch 350, Train Loss : 0.003908193272764038, Test Loss : 2.263124465942383\n",
      "-- Epoch 400, Train Loss : 0.0038406114686040382, Test Loss : 2.2604784965515137\n",
      "-- Epoch 450, Train Loss : 0.0036586512301255425, Test Loss : 2.2528750896453857\n",
      "-- Epoch 500, Train Loss : 0.0033951689797504514, Test Loss : 2.244347333908081\n",
      "-- Epoch 550, Train Loss : 0.0030287883560049522, Test Loss : 2.228306531906128\n",
      "-- Epoch 600, Train Loss : 0.002641819767177367, Test Loss : 2.2197558879852295\n",
      "-- Epoch 650, Train Loss : 0.002319754869404278, Test Loss : 2.208216667175293\n",
      "-- Epoch 700, Train Loss : 0.002090430281441513, Test Loss : 2.2024714946746826\n",
      "-- Epoch 750, Train Loss : 0.0019448571765678935, Test Loss : 2.204237937927246\n",
      "-- Epoch 800, Train Loss : 0.0018388396879345237, Test Loss : 2.2090446949005127\n",
      "-- Epoch 850, Train Loss : 0.0017618447768654732, Test Loss : 2.217297315597534\n",
      "-- Epoch 900, Train Loss : 0.0017049186735675903, Test Loss : 2.226389169692993\n",
      "-- Epoch 950, Train Loss : 0.0016667251138642314, Test Loss : 2.2405638694763184\n",
      "-- Epoch 1000, Train Loss : 0.0016430416231969502, Test Loss : 2.2474687099456787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 1168.05 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1418])\n",
      "1418 vs 1418\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.636 %\n",
      "- Recall : 92.072 %\n",
      "- F1 : 0.90838\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 74.597 %\n",
      "- Recall : 76.763 %\n",
      "- F1 : 0.75665\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 69.466 %\n",
      "- Recall : 60.265 %\n",
      "- F1 : 0.64539\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 87.121 %\n",
      "- Recall : 80.42 %\n",
      "- F1 : 0.83636\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.908 %\n",
      "- Precision : 80.205 %\n",
      "- Recall : 77.38 %\n",
      "- F1 : 0.78767\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet18_CNN_RoBERTa_Finetuned Validation, 84.908, 80.205, 77.38, 0.78767, 89.636, 92.072, 0.90838, 74.597, 76.763, 0.75665, 69.466, 60.265, 0.64539, 87.121, 80.42, 0.83636, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([684])\n",
      "684 vs 684\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 91.449 %\n",
      "- Recall : 89.327 %\n",
      "- F1 : 0.90376\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 66.116 %\n",
      "- Recall : 72.727 %\n",
      "- F1 : 0.69264\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 68.919 %\n",
      "- Recall : 68.0 %\n",
      "- F1 : 0.68456\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 70.588 %\n",
      "- Recall : 70.588 %\n",
      "- F1 : 0.70588\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.456 %\n",
      "- Precision : 74.268 %\n",
      "- Recall : 75.161 %\n",
      "- F1 : 0.74712\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet18_CNN_RoBERTa_Finetuned Validation, 82.456, 74.268, 75.161, 0.74712, 91.449, 89.327, 0.90376, 66.116, 72.727, 0.69264, 68.919, 68.0, 0.68456, 70.588, 70.588, 0.70588, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_multiclass_ResNet18_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
