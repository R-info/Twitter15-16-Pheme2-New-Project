{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"BERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    testting  \n",
       "1        3  training    training  \n",
       "2        2      test  validation  \n",
       "3        2      test    training  \n",
       "4        3  training    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4323, 768)\n",
      "(1418, 768)\n",
      "(684, 768)\n",
      "(4323,)\n",
      "(1418,)\n",
      "(684,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input, n_output)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1], n_output)\n",
    "\n",
    "    \n",
    "def CNNResNet18(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet34(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet50(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet101(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet152(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3], n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        \n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "#                     outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_multiclass_ResNet10_CNN_BERT_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 22.638\n",
      "Saving after new best accuracy : 23.413\n",
      "Saving after new best accuracy : 64.034\n",
      "Saving after new best accuracy : 80.536\n",
      "Saving after new best accuracy : 82.934\n",
      "Saving after new best accuracy : 83.709\n",
      "Saving after new best accuracy : 83.921\n",
      "Saving after new best accuracy : 84.485\n",
      "Saving after new best accuracy : 84.556\n",
      "-- Epoch 50, Train Loss : 0.0029218254712759517, Test Loss : 1.9099702835083008\n",
      "-- Epoch 100, Train Loss : 0.002864083078748081, Test Loss : 1.9995781183242798\n",
      "-- Epoch 150, Train Loss : 0.003007406199685647, Test Loss : 2.0448012351989746\n",
      "-- Epoch 200, Train Loss : 0.0030610729945692583, Test Loss : 2.0679516792297363\n",
      "-- Epoch 250, Train Loss : 0.0030182358150341315, Test Loss : 2.078660249710083\n",
      "-- Epoch 300, Train Loss : 0.002918795073128422, Test Loss : 2.083233118057251\n",
      "-- Epoch 350, Train Loss : 0.0027864157964359038, Test Loss : 2.0850672721862793\n",
      "-- Epoch 400, Train Loss : 0.0026395988006697735, Test Loss : 2.0889313220977783\n",
      "-- Epoch 450, Train Loss : 0.0025037510686161113, Test Loss : 2.095949172973633\n",
      "-- Epoch 500, Train Loss : 0.002374767575020087, Test Loss : 2.104478120803833\n",
      "-- Epoch 550, Train Loss : 0.00226190409011906, Test Loss : 2.116791009902954\n",
      "-- Epoch 600, Train Loss : 0.00215588098308217, Test Loss : 2.1286909580230713\n",
      "-- Epoch 650, Train Loss : 0.0020612979883480875, Test Loss : 2.1439576148986816\n",
      "-- Epoch 700, Train Loss : 0.0019802985848400567, Test Loss : 2.1586408615112305\n",
      "-- Epoch 750, Train Loss : 0.0019137688163937128, Test Loss : 2.1725680828094482\n",
      "-- Epoch 800, Train Loss : 0.0018532374685946706, Test Loss : 2.1924755573272705\n",
      "-- Epoch 850, Train Loss : 0.0018002239080487925, Test Loss : 2.208346366882324\n",
      "-- Epoch 900, Train Loss : 0.0017606088401862507, Test Loss : 2.228828191757202\n",
      "-- Epoch 950, Train Loss : 0.001726596403386793, Test Loss : 2.24786639213562\n",
      "-- Epoch 1000, Train Loss : 0.0016988026246735899, Test Loss : 2.271829605102539\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 673.78 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1418])\n",
      "1418 vs 1418\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.27 %\n",
      "- Recall : 91.393 %\n",
      "- F1 : 0.90319\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 71.324 %\n",
      "- Recall : 80.498 %\n",
      "- F1 : 0.75634\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 74.359 %\n",
      "- Recall : 57.616 %\n",
      "- F1 : 0.64925\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.8 %\n",
      "- Recall : 77.622 %\n",
      "- F1 : 0.82836\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.556 %\n",
      "- Precision : 80.938 %\n",
      "- Recall : 76.782 %\n",
      "- F1 : 0.78805\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet10_CNN_BERT_Finetuned Validation, 84.556, 80.938, 76.782, 0.78805, 89.27, 91.393, 0.90319, 71.324, 80.498, 0.75634, 74.359, 57.616, 0.64925, 88.8, 77.622, 0.82836, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([684])\n",
      "684 vs 684\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 91.589 %\n",
      "- Recall : 90.951 %\n",
      "- F1 : 0.91269\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 68.254 %\n",
      "- Recall : 78.182 %\n",
      "- F1 : 0.72881\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 70.769 %\n",
      "- Recall : 61.333 %\n",
      "- F1 : 0.65714\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 84.615 %\n",
      "- Recall : 80.882 %\n",
      "- F1 : 0.82707\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.649 %\n",
      "- Precision : 78.807 %\n",
      "- Recall : 77.837 %\n",
      "- F1 : 0.78319\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet10_CNN_BERT_Finetuned Validation, 84.649, 78.807, 77.837, 0.78319, 91.589, 90.951, 0.91269, 68.254, 78.182, 0.72881, 70.769, 61.333, 0.65714, 84.615, 80.882, 0.82707, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_multiclass_ResNet10_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr2_multiclass_ResNet18_CNN_BERT_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 14.598\n",
      "Saving after new best accuracy : 21.58\n",
      "Saving after new best accuracy : 23.554\n",
      "Saving after new best accuracy : 25.458\n",
      "Saving after new best accuracy : 77.786\n",
      "Saving after new best accuracy : 82.581\n",
      "Saving after new best accuracy : 83.216\n",
      "Saving after new best accuracy : 83.568\n",
      "Saving after new best accuracy : 83.78\n",
      "Saving after new best accuracy : 83.921\n",
      "Saving after new best accuracy : 83.992\n",
      "-- Epoch 50, Train Loss : 0.0024743926333030686, Test Loss : 1.9550416469573975\n",
      "-- Epoch 100, Train Loss : 0.002368384661167511, Test Loss : 2.026057720184326\n",
      "-- Epoch 150, Train Loss : 0.0025673840782474144, Test Loss : 2.06777286529541\n",
      "-- Epoch 200, Train Loss : 0.0027695208691511652, Test Loss : 2.0940616130828857\n",
      "-- Epoch 250, Train Loss : 0.0029036404348516953, Test Loss : 2.1103057861328125\n",
      "-- Epoch 300, Train Loss : 0.0029681086698474246, Test Loss : 2.1180286407470703\n",
      "-- Epoch 350, Train Loss : 0.00296906964331356, Test Loss : 2.120192766189575\n",
      "Saving after new best accuracy : 84.062\n",
      "-- Epoch 400, Train Loss : 0.0028964011171410675, Test Loss : 2.116516351699829\n",
      "Saving after new best accuracy : 84.133\n",
      "-- Epoch 450, Train Loss : 0.0027920746574636723, Test Loss : 2.112736940383911\n",
      "-- Epoch 500, Train Loss : 0.0026368573735453538, Test Loss : 2.109311819076538\n",
      "-- Epoch 550, Train Loss : 0.00247263604796899, Test Loss : 2.104806661605835\n",
      "-- Epoch 600, Train Loss : 0.0023172277610683523, Test Loss : 2.1020071506500244\n",
      "-- Epoch 650, Train Loss : 0.002175519874526799, Test Loss : 2.1071507930755615\n",
      "-- Epoch 700, Train Loss : 0.0020493967172114935, Test Loss : 2.1122539043426514\n",
      "-- Epoch 750, Train Loss : 0.0019515334929565142, Test Loss : 2.1191089153289795\n",
      "-- Epoch 800, Train Loss : 0.0018565963280252618, Test Loss : 2.1291894912719727\n",
      "-- Epoch 850, Train Loss : 0.0017827820022375818, Test Loss : 2.1376869678497314\n",
      "-- Epoch 900, Train Loss : 0.0017217635158885969, Test Loss : 2.1547584533691406\n",
      "-- Epoch 950, Train Loss : 0.0016722279119676386, Test Loss : 2.1753649711608887\n",
      "-- Epoch 1000, Train Loss : 0.0016419952208934774, Test Loss : 2.1692004203796387\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 1195.1 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1418])\n",
      "1418 vs 1418\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.037 %\n",
      "- Recall : 91.053 %\n",
      "- F1 : 0.90034\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 70.849 %\n",
      "- Recall : 79.668 %\n",
      "- F1 : 0.75\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 72.881 %\n",
      "- Recall : 56.954 %\n",
      "- F1 : 0.63941\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.095 %\n",
      "- Recall : 77.622 %\n",
      "- F1 : 0.82528\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.133 %\n",
      "- Precision : 80.215 %\n",
      "- Recall : 76.324 %\n",
      "- F1 : 0.78221\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet18_CNN_BERT_Finetuned Validation, 84.133, 80.215, 76.324, 0.78221, 89.037, 91.053, 0.90034, 70.849, 79.668, 0.75, 72.881, 56.954, 0.63941, 88.095, 77.622, 0.82528, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([684])\n",
      "684 vs 684\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 91.569 %\n",
      "- Recall : 90.719 %\n",
      "- F1 : 0.91142\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 68.0 %\n",
      "- Recall : 77.273 %\n",
      "- F1 : 0.7234\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 71.429 %\n",
      "- Recall : 60.0 %\n",
      "- F1 : 0.65217\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 79.71 %\n",
      "- Recall : 80.882 %\n",
      "- F1 : 0.80292\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.211 %\n",
      "- Precision : 77.677 %\n",
      "- Recall : 77.219 %\n",
      "- F1 : 0.77447\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_ResNet18_CNN_BERT_Finetuned Validation, 84.211, 77.677, 77.219, 0.77447, 91.569, 90.719, 0.91142, 68.0, 77.273, 0.7234, 71.429, 60.0, 0.65217, 79.71, 80.882, 0.80292, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr2_multiclass_ResNet18_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(n_output=4), train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
