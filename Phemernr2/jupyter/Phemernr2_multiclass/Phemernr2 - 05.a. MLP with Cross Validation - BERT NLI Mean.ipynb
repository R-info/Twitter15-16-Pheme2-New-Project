{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "dataset_name = \"Phemernr2_CrossVal\"\n",
    "unique_name = \"SBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_SBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt  \n",
       "0        2      test  \n",
       "1        3  training  \n",
       "2        2      test  \n",
       "3        2      test  \n",
       "4        3  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256c8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = np.array([vectors[i] for i, p2 in data.iterrows() if p2['cv_fold'] == 0])\n",
    "test_labels = np.array([labels[i] for i, p2 in data.iterrows() if p2['cv_fold'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 768)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "print(test_vectors.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "#             if (epoch) % round(n_iter/20) == 0:\n",
    "#                 print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "#                 print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "#         # visualizing accuracy over epoch\n",
    "#         fig, ax2 = plt.subplots(1)\n",
    "#         plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "#         ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "#         ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "#         ax2.set_ylabel('Loss')\n",
    "#         ax2.set_xlabel('Epoch')\n",
    "#         ax2.set_xlim(0, len(train_losses))\n",
    "#         ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "#         ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "#         ax2.legend(loc='lower right')\n",
    "\n",
    "#         plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Fold Cross Validation with 4-Layer Linear Network\n",
      "Fold-1 Cross Validation\n",
      "Using cuda\n",
      "\n",
      "-------- Fold-1 Results --------\n",
      "1914 vs 1914\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 87.382 %\n",
      "- Recall : 90.375 %\n",
      "- F1 : 0.88853\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 73.422 %\n",
      "- Recall : 67.791 %\n",
      "- F1 : 0.70494\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 60.0 %\n",
      "- Recall : 60.963 %\n",
      "- F1 : 0.60477\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 81.29 %\n",
      "- Recall : 72.0 %\n",
      "- F1 : 0.76364\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.975 %\n",
      "- Precision : 75.523 %\n",
      "- Recall : 72.782 %\n",
      "- F1 : 0.74127\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_CrossVal_4LayerNet_SBERT_NLI_Mean_fold-1, 81.975, 75.523, 72.782, 0.74127, 87.382, 90.375, 0.88853, 73.422, 67.791, 0.70494, 60.0, 60.963, 0.60477, 81.29, 72.0, 0.76364, \n",
      "-------- Fold-1 End --------\n",
      "\n",
      "Fold-2 Cross Validation\n",
      "Using cuda\n",
      "\n",
      "-------- Fold-2 Results --------\n",
      "1920 vs 1920\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 86.317 %\n",
      "- Recall : 91.023 %\n",
      "- F1 : 0.88608\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 70.164 %\n",
      "- Recall : 69.481 %\n",
      "- F1 : 0.69821\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 68.927 %\n",
      "- Recall : 56.744 %\n",
      "- F1 : 0.62245\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.663 %\n",
      "- Recall : 71.22 %\n",
      "- F1 : 0.75648\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.615 %\n",
      "- Precision : 76.518 %\n",
      "- Recall : 72.117 %\n",
      "- F1 : 0.74252\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_CrossVal_4LayerNet_SBERT_NLI_Mean_fold-2, 81.615, 76.518, 72.117, 0.74252, 86.317, 91.023, 0.88608, 70.164, 69.481, 0.69821, 68.927, 56.744, 0.62245, 80.663, 71.22, 0.75648, \n",
      "-------- Fold-2 End --------\n",
      "\n",
      "Fold-3 Cross Validation\n",
      "Using cuda\n",
      "\n",
      "-------- Fold-3 Results --------\n",
      "1961 vs 1961\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 84.327 %\n",
      "- Recall : 93.475 %\n",
      "- F1 : 0.88665\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 73.355 %\n",
      "- Recall : 68.827 %\n",
      "- F1 : 0.71019\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 67.692 %\n",
      "- Recall : 40.0 %\n",
      "- F1 : 0.50286\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.952 %\n",
      "- Recall : 71.204 %\n",
      "- F1 : 0.75766\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.234 %\n",
      "- Precision : 76.582 %\n",
      "- Recall : 68.377 %\n",
      "- F1 : 0.72247\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_CrossVal_4LayerNet_SBERT_NLI_Mean_fold-3, 81.234, 76.582, 68.377, 0.72247, 84.327, 93.475, 0.88665, 73.355, 68.827, 0.71019, 67.692, 40.0, 0.50286, 80.952, 71.204, 0.75766, \n",
      "-------- Fold-3 End --------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"3-Fold Cross Validation with 4-Layer Linear Network\")\n",
    "\n",
    "folds = [1, 2, 3]\n",
    "for fold in folds:\n",
    "    val_folds = [fold]\n",
    "    train_folds = folds.copy()\n",
    "    train_folds.remove(fold)\n",
    "\n",
    "    train_vectors = np.array([vectors[i] for i, p2 in data.iterrows() if p2['cv_fold'] in train_folds])\n",
    "    val_vectors = np.array([vectors[i] for i, p2 in data.iterrows() if p2['cv_fold'] in val_folds])\n",
    "\n",
    "    train_labels = np.array([labels[i] for i, p2 in data.iterrows() if p2['cv_fold'] in train_folds])\n",
    "    val_labels = np.array([labels[i] for i, p2 in data.iterrows() if p2['cv_fold'] in val_folds])\n",
    "\n",
    "    print(f\"Fold-{fold} Cross Validation\")\n",
    "    model_name = f\"{dataset_name}_4LayerNet_{unique_name}_fold-{fold}\"\n",
    "    model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "    model.train_eval(torch.Tensor(train_vectors),\n",
    "                    torch.Tensor(train_labels),\n",
    "                    torch.Tensor(val_vectors),\n",
    "                    torch.Tensor(val_labels),\n",
    "                    saves=model_name,\n",
    "                    n_iter=1000,\n",
    "                    batch_size=512)\n",
    "\n",
    "    model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "    print(f\"\\n-------- Fold-{fold} Results --------\")\n",
    "    preds = model.predict(val_vectors)\n",
    "\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "        predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "        binary=False,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    conf_mat.evaluate(classes=labels_str)\n",
    "    print(f\"-------- Fold-{fold} End --------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f554ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Cross Validation Fold-1\n",
      "\n",
      "-------- Testing Results --------\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 82.933 %\n",
      "- Recall : 91.029 %\n",
      "- F1 : 0.86792\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 70.297 %\n",
      "- Recall : 65.138 %\n",
      "- F1 : 0.67619\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 60.0 %\n",
      "- Recall : 44.0 %\n",
      "- F1 : 0.50769\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 75.862 %\n",
      "- Recall : 65.672 %\n",
      "- F1 : 0.704\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 78.254 %\n",
      "- Precision : 72.273 %\n",
      "- Recall : 66.46 %\n",
      "- F1 : 0.69245\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_CrossVal_4LayerNet_SBERT_NLI_Mean_fold-1, 78.254, 72.273, 66.46, 0.69245, 82.933, 91.029, 0.86792, 70.297, 65.138, 0.67619, 60.0, 44.0, 0.50769, 75.862, 65.672, 0.704, \n",
      "-------- Testing End --------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold_n = 1\n",
    "print(f\"Testing Cross Validation Fold-{fold_n}\")\n",
    "\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}_fold-{fold_n}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(f\"\\n-------- Testing Results --------\")\n",
    "preds = model.predict(test_vectors)\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "print(f\"-------- Testing End --------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160ce715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Cross Validation Fold-2\n",
      "\n",
      "-------- Testing Results --------\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 83.051 %\n",
      "- Recall : 90.501 %\n",
      "- F1 : 0.86616\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 69.444 %\n",
      "- Recall : 68.807 %\n",
      "- F1 : 0.69124\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 66.667 %\n",
      "- Recall : 45.333 %\n",
      "- F1 : 0.53968\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 79.31 %\n",
      "- Recall : 68.657 %\n",
      "- F1 : 0.736\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 79.048 %\n",
      "- Precision : 74.618 %\n",
      "- Recall : 68.325 %\n",
      "- F1 : 0.71333\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_CrossVal_4LayerNet_SBERT_NLI_Mean_fold-2, 79.048, 74.618, 68.325, 0.71333, 83.051, 90.501, 0.86616, 69.444, 68.807, 0.69124, 66.667, 45.333, 0.53968, 79.31, 68.657, 0.736, \n",
      "-------- Testing End --------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold_n = 2\n",
    "print(f\"Testing Cross Validation Fold-{fold_n}\")\n",
    "\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}_fold-{fold_n}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(f\"\\n-------- Testing Results --------\")\n",
    "preds = model.predict(test_vectors)\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "print(f\"-------- Testing End --------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4677a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Cross Validation Fold-3\n",
      "\n",
      "-------- Testing Results --------\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 79.326 %\n",
      "- Recall : 93.14 %\n",
      "- F1 : 0.8568\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 76.042 %\n",
      "- Recall : 66.972 %\n",
      "- F1 : 0.7122\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 65.714 %\n",
      "- Recall : 30.667 %\n",
      "- F1 : 0.41818\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 70.37 %\n",
      "- Recall : 56.716 %\n",
      "- F1 : 0.6281\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 77.302 %\n",
      "- Precision : 72.863 %\n",
      "- Recall : 61.874 %\n",
      "- F1 : 0.6692\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_CrossVal_4LayerNet_SBERT_NLI_Mean_fold-3, 77.302, 72.863, 61.874, 0.6692, 79.326, 93.14, 0.8568, 76.042, 66.972, 0.7122, 65.714, 30.667, 0.41818, 70.37, 56.716, 0.6281, \n",
      "-------- Testing End --------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold_n = 3\n",
    "print(f\"Testing Cross Validation Fold-{fold_n}\")\n",
    "\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}_fold-{fold_n}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(f\"\\n-------- Testing Results --------\")\n",
    "preds = model.predict(test_vectors)\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "print(f\"-------- Testing End --------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
