{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "unique_name = \"BERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    training  \n",
       "1        3  training  validation  \n",
       "2        2      test  validation  \n",
       "3        2      test  validation  \n",
       "4        3  training    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4326, 768)\n",
      "(1463, 768)\n",
      "(636, 768)\n",
      "(4326,)\n",
      "(1463,)\n",
      "(636,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 81.818\n",
      "Saving after new best accuracy : 83.459\n",
      "Saving after new best accuracy : 83.664\n",
      "Saving after new best accuracy : 83.869\n",
      "Saving after new best accuracy : 84.005\n",
      "Saving after new best accuracy : 84.074\n",
      "Saving after new best accuracy : 84.142\n",
      "Saving after new best accuracy : 84.211\n",
      "-- Epoch 50, Train Loss : 0.016514484806975815, Test Loss : 1.616776943206787\n",
      "-- Epoch 100, Train Loss : 0.005685326032107696, Test Loss : 1.9974451065063477\n",
      "-- Epoch 150, Train Loss : 0.0005556416640501993, Test Loss : 2.5072553157806396\n",
      "-- Epoch 200, Train Loss : 0.00018534036956907585, Test Loss : 2.8816142082214355\n",
      "-- Epoch 250, Train Loss : 8.596562744855873e-05, Test Loss : 3.1432909965515137\n",
      "-- Epoch 300, Train Loss : 4.677599815039457e-05, Test Loss : 3.3504042625427246\n",
      "-- Epoch 350, Train Loss : 2.7958320693244332e-05, Test Loss : 3.5260159969329834\n",
      "-- Epoch 400, Train Loss : 1.7915831508119595e-05, Test Loss : 3.6811306476593018\n",
      "-- Epoch 450, Train Loss : 1.1870583645823274e-05, Test Loss : 3.8233699798583984\n",
      "-- Epoch 500, Train Loss : 8.11453126292605e-06, Test Loss : 3.9554920196533203\n",
      "-- Epoch 550, Train Loss : 5.688649567403559e-06, Test Loss : 4.080214977264404\n",
      "-- Epoch 600, Train Loss : 4.045782408645948e-06, Test Loss : 4.199322700500488\n",
      "-- Epoch 650, Train Loss : 2.9192001513855814e-06, Test Loss : 4.314326763153076\n",
      "-- Epoch 700, Train Loss : 2.1357333425120473e-06, Test Loss : 4.425721168518066\n",
      "-- Epoch 750, Train Loss : 1.5699734984275793e-06, Test Loss : 4.534304141998291\n",
      "-- Epoch 800, Train Loss : 1.1615579110224594e-06, Test Loss : 4.6410112380981445\n",
      "-- Epoch 850, Train Loss : 8.628443674413289e-07, Test Loss : 4.74570369720459\n",
      "-- Epoch 900, Train Loss : 6.504284745662003e-07, Test Loss : 4.848235130310059\n",
      "-- Epoch 950, Train Loss : 4.896222795813809e-07, Test Loss : 4.949289321899414\n",
      "-- Epoch 1000, Train Loss : 3.7165478071476965e-07, Test Loss : 5.04925537109375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 181.16 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1463])\n",
      "1463 vs 1463\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.494 %\n",
      "- Recall : 93.069 %\n",
      "- F1 : 0.90724\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 73.061 %\n",
      "- Recall : 74.274 %\n",
      "- F1 : 0.73663\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 73.387 %\n",
      "- Recall : 54.491 %\n",
      "- F1 : 0.62543\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 84.058 %\n",
      "- Recall : 79.452 %\n",
      "- F1 : 0.8169\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.211 %\n",
      "- Precision : 79.75 %\n",
      "- Recall : 75.322 %\n",
      "- F1 : 0.77473\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_BERT_Finetuned Validation, 84.211, 79.75, 75.322, 0.77473, 88.494, 93.069, 0.90724, 73.061, 74.274, 0.73663, 73.387, 54.491, 0.62543, 84.058, 79.452, 0.8169, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([636])\n",
      "636 vs 636\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 91.106 %\n",
      "- Recall : 93.58 %\n",
      "- F1 : 0.92326\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 82.474 %\n",
      "- Recall : 77.67 %\n",
      "- F1 : 0.8\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 70.0 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.68293\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 85.714 %\n",
      "- Recall : 83.077 %\n",
      "- F1 : 0.84375\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.264 %\n",
      "- Precision : 82.324 %\n",
      "- Recall : 80.248 %\n",
      "- F1 : 0.81273\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_BERT_Finetuned Test, 87.264, 82.324, 80.248, 0.81273, 91.106, 93.58, 0.92326, 82.474, 77.67, 0.8, 70.0, 66.667, 0.68293, 85.714, 83.077, 0.84375, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Phemernr2_multiclass_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
