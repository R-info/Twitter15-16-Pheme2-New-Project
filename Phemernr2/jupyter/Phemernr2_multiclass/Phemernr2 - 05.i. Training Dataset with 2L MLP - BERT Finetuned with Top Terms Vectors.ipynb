{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNTF\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label2\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ku Klux Klan', 'Child Left Behind', 'Portland-Milwaukie Light Rail', 'Minister Benjamin Netanyahu', 'Prime Minister Benjamin', 'Religious Freedom Restoration', 'Rio Grande Valley', 'Leticia Van de', 'Van de Putte', 'Catherine Cortez Masto']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2-multiclass_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519)\n",
      "(1456, 1519)\n",
      "(630, 1519)\n",
      "(4339,)\n",
      "(1456,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 83.173\n",
      "Saving after new best accuracy : 83.242\n",
      "Saving after new best accuracy : 83.31\n",
      "Saving after new best accuracy : 83.379\n",
      "-- Epoch 50, Train Loss : 0.027970751893008128, Test Loss : 1.2330788373947144\n",
      "Saving after new best accuracy : 83.448\n",
      "-- Epoch 100, Train Loss : 0.02072343725740211, Test Loss : 1.4872523546218872\n",
      "-- Epoch 150, Train Loss : 0.01755317758215824, Test Loss : 1.6506998538970947\n",
      "-- Epoch 200, Train Loss : 0.015260251735526253, Test Loss : 1.7728028297424316\n",
      "-- Epoch 250, Train Loss : 0.012931722792927758, Test Loss : 1.8749077320098877\n",
      "-- Epoch 300, Train Loss : 0.010710657463732787, Test Loss : 1.9792357683181763\n",
      "-- Epoch 350, Train Loss : 0.008146199079192229, Test Loss : 2.10310959815979\n",
      "-- Epoch 400, Train Loss : 0.006704752409518733, Test Loss : 2.2238340377807617\n",
      "-- Epoch 450, Train Loss : 0.005727250082372848, Test Loss : 2.3258326053619385\n",
      "-- Epoch 500, Train Loss : 0.00510130289319477, Test Loss : 2.4159297943115234\n",
      "-- Epoch 550, Train Loss : 0.0047016661601446685, Test Loss : 2.506336212158203\n",
      "-- Epoch 600, Train Loss : 0.004250075521099461, Test Loss : 2.5989959239959717\n",
      "Saving after new best accuracy : 83.516\n",
      "-- Epoch 650, Train Loss : 0.0038770216470993546, Test Loss : 2.7098050117492676\n",
      "-- Epoch 700, Train Loss : 0.0037017349220604956, Test Loss : 2.816697359085083\n",
      "-- Epoch 750, Train Loss : 0.0034807130734861857, Test Loss : 2.9328184127807617\n",
      "-- Epoch 800, Train Loss : 0.0032616063587056487, Test Loss : 3.0604255199432373\n",
      "-- Epoch 850, Train Loss : 0.0032113222782754747, Test Loss : 3.1813766956329346\n",
      "-- Epoch 900, Train Loss : 0.0030581359185646306, Test Loss : 3.3432979583740234\n",
      "-- Epoch 950, Train Loss : 0.0029799556285468043, Test Loss : 3.4846017360687256\n",
      "-- Epoch 1000, Train Loss : 0.0029372405146119718, Test Loss : 3.6255080699920654\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 174.45 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456])\n",
      "1456 vs 1456\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.687 %\n",
      "- Recall : 91.925 %\n",
      "- F1 : 0.90277\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 74.016 %\n",
      "- Recall : 73.725 %\n",
      "- F1 : 0.7387\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 69.63 %\n",
      "- Recall : 61.842 %\n",
      "- F1 : 0.65505\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 79.231 %\n",
      "- Recall : 71.034 %\n",
      "- F1 : 0.74909\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.516 %\n",
      "- Precision : 77.891 %\n",
      "- Recall : 74.632 %\n",
      "- F1 : 0.76227\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 83.516, 77.891, 74.632, 0.76227, 88.687, 91.925, 0.90277, 74.016, 73.725, 0.7387, 69.63, 61.842, 0.65505, 79.231, 71.034, 0.74909, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630])\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 90.307 %\n",
      "- Recall : 95.739 %\n",
      "- F1 : 0.92944\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 78.889 %\n",
      "- Recall : 72.449 %\n",
      "- F1 : 0.75532\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 80.328 %\n",
      "- Recall : 65.333 %\n",
      "- F1 : 0.72059\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 89.286 %\n",
      "- Recall : 86.207 %\n",
      "- F1 : 0.87719\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.619 %\n",
      "- Precision : 84.702 %\n",
      "- Recall : 79.932 %\n",
      "- F1 : 0.82248\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 87.619, 84.702, 79.932, 0.82248, 90.307, 95.739, 0.92944, 78.889, 72.449, 0.75532, 80.328, 65.333, 0.72059, 89.286, 86.207, 0.87719, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9a553",
   "metadata": {},
   "source": [
    "Phemernr2-RNTF_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 83.448, 77.737, 74.608, 0.7614, 88.782, 91.925, 0.90326, 73.228, 72.941, 0.73084, 70.149, 61.842, 0.65734, 78.788, 71.724, 0.7509,\n",
    "\n",
    "Phemernr2-RNTF_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 87.46, 83.976, 80.489, 0.82196, 90.67, 94.987, 0.92778, 77.778, 71.429, 0.74468, 81.25, 69.333, 0.7482, 86.207, 86.207, 0.86207,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
