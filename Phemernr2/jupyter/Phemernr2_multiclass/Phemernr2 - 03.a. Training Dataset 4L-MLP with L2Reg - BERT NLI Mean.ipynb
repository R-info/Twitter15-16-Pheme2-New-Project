{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "unique_name = \"SBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_SBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt      tvt2  \n",
       "0        2      test  training  \n",
       "1        3  training  training  \n",
       "2        2      test  training  \n",
       "3        2      test  training  \n",
       "4        3  training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3862, 768)\n",
      "(1280, 768)\n",
      "(1283, 768)\n",
      "(3862,)\n",
      "(1280,)\n",
      "(1283,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69d25f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 65.156\n",
      "Saving after new best accuracy : 67.734\n",
      "Saving after new best accuracy : 68.906\n",
      "Saving after new best accuracy : 70.703\n",
      "Saving after new best accuracy : 73.516\n",
      "Saving after new best accuracy : 73.906\n",
      "Saving after new best accuracy : 74.844\n",
      "Saving after new best accuracy : 76.016\n",
      "Saving after new best accuracy : 77.109\n",
      "Saving after new best accuracy : 77.812\n",
      "Saving after new best accuracy : 78.828\n",
      "Saving after new best accuracy : 78.984\n",
      "Saving after new best accuracy : 79.531\n",
      "Saving after new best accuracy : 80.781\n",
      "Saving after new best accuracy : 81.016\n",
      "Saving after new best accuracy : 81.172\n",
      "Saving after new best accuracy : 81.484\n",
      "Saving after new best accuracy : 81.562\n",
      "-- Epoch 50, Train Loss : 2.2859760373830795, Test Loss : 0.5363637208938599\n",
      "Saving after new best accuracy : 82.344\n",
      "Saving after new best accuracy : 82.578\n",
      "Saving after new best accuracy : 82.812\n",
      "Saving after new best accuracy : 83.047\n",
      "Saving after new best accuracy : 83.281\n",
      "Saving after new best accuracy : 83.438\n",
      "Saving after new best accuracy : 83.594\n",
      "Saving after new best accuracy : 83.672\n",
      "Saving after new best accuracy : 83.906\n",
      "-- Epoch 100, Train Loss : 0.7767993248999119, Test Loss : 0.7263377904891968\n",
      "Saving after new best accuracy : 84.062\n",
      "-- Epoch 150, Train Loss : 0.4995250590145588, Test Loss : 0.8439292907714844\n",
      "-- Epoch 200, Train Loss : 0.37462727539241314, Test Loss : 0.893841564655304\n",
      "Saving after new best accuracy : 84.375\n",
      "-- Epoch 250, Train Loss : 0.3231759946793318, Test Loss : 0.9402269124984741\n",
      "-- Epoch 300, Train Loss : 0.24760526977479458, Test Loss : 1.0104020833969116\n",
      "Saving after new best accuracy : 84.531\n",
      "Saving after new best accuracy : 84.609\n",
      "-- Epoch 350, Train Loss : 0.1723985569551587, Test Loss : 0.9993540048599243\n",
      "-- Epoch 400, Train Loss : 0.14767306577414274, Test Loss : 1.0967196226119995\n",
      "-- Epoch 450, Train Loss : 0.2163455169647932, Test Loss : 1.0903325080871582\n",
      "-- Epoch 500, Train Loss : 0.16033019195310771, Test Loss : 1.1372556686401367\n",
      "-- Epoch 550, Train Loss : 0.15764228161424398, Test Loss : 1.1048892736434937\n",
      "-- Epoch 600, Train Loss : 0.10834806133061647, Test Loss : 1.1643180847167969\n",
      "Saving after new best accuracy : 84.766\n",
      "-- Epoch 650, Train Loss : 0.057514478685334325, Test Loss : 1.1764981746673584\n",
      "Saving after new best accuracy : 84.844\n",
      "-- Epoch 700, Train Loss : 0.1504407273605466, Test Loss : 1.3280729055404663\n",
      "-- Epoch 750, Train Loss : 0.06442951736971736, Test Loss : 1.2264277935028076\n",
      "-- Epoch 800, Train Loss : 0.1690307823009789, Test Loss : 1.255298137664795\n",
      "-- Epoch 850, Train Loss : 0.10846239514648914, Test Loss : 1.3282567262649536\n",
      "-- Epoch 900, Train Loss : 0.0899471320444718, Test Loss : 1.369795799255371\n",
      "-- Epoch 950, Train Loss : 0.06117758387699723, Test Loss : 1.275452733039856\n",
      "-- Epoch 1000, Train Loss : 0.1049292937386781, Test Loss : 1.470421314239502\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ../../data/models/Phemernr2_multiclass_4LayerNet_L2Reg_SBERT_NLI_Mean.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1280])\n",
      "1280 vs 1280\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.161 %\n",
      "- Recall : 91.727 %\n",
      "- F1 : 0.90426\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 76.879 %\n",
      "- Recall : 71.892 %\n",
      "- F1 : 0.74302\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 76.316 %\n",
      "- Recall : 64.925 %\n",
      "- F1 : 0.70161\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 74.815 %\n",
      "- Recall : 79.528 %\n",
      "- F1 : 0.77099\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.844 %\n",
      "- Precision : 79.293 %\n",
      "- Recall : 77.018 %\n",
      "- F1 : 0.78139\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_L2Reg_SBERT_NLI_Mean Validation, 84.844, 79.293, 77.018, 0.78139, 89.161, 91.727, 0.90426, 76.879, 71.892, 0.74302, 76.316, 64.925, 0.70161, 74.815, 79.528, 0.77099, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1283])\n",
      "1283 vs 1283\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 86.449 %\n",
      "- Recall : 91.471 %\n",
      "- F1 : 0.88889\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 74.869 %\n",
      "- Recall : 69.082 %\n",
      "- F1 : 0.71859\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 68.75 %\n",
      "- Recall : 54.225 %\n",
      "- F1 : 0.6063\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 72.581 %\n",
      "- Recall : 72.0 %\n",
      "- F1 : 0.72289\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.839 %\n",
      "- Precision : 75.662 %\n",
      "- Recall : 71.695 %\n",
      "- F1 : 0.73625\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_L2Reg_SBERT_NLI_Mean Test, 81.839, 75.662, 71.695, 0.73625, 86.449, 91.471, 0.88889, 74.869, 69.082, 0.71859, 68.75, 54.225, 0.6063, 72.581, 72.0, 0.72289, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr2_multiclass_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
