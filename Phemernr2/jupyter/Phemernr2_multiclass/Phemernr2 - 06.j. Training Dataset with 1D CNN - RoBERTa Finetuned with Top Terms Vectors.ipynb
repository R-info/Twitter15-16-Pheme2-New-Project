{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNTF\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label2\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/phemernr2-multiclass_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "        \n",
    "bigram_vector_base = bigram_vector_base[:bigram_limit]\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519, 1)\n",
      "(1456, 1519, 1)\n",
      "(630, 1519, 1)\n",
      "(4339,)\n",
      "(1456,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 84.203\n",
      "Saving after new best accuracy : 84.272\n",
      "Saving after new best accuracy : 84.341\n",
      "-- Epoch 50, Train Loss : 6.723447263240814, Test Loss : 0.8952113389968872\n",
      "Saving after new best accuracy : 84.409\n",
      "Saving after new best accuracy : 84.478\n",
      "-- Epoch 100, Train Loss : 6.716797769069672, Test Loss : 0.8969417810440063\n",
      "-- Epoch 150, Train Loss : 6.714404582977295, Test Loss : 0.8985151648521423\n",
      "-- Epoch 200, Train Loss : 6.714053630828857, Test Loss : 0.8989081978797913\n",
      "-- Epoch 250, Train Loss : 6.7138537764549255, Test Loss : 0.8989806175231934\n",
      "-- Epoch 300, Train Loss : 6.71366673707962, Test Loss : 0.8989604711532593\n",
      "Saving after new best accuracy : 84.547\n",
      "-- Epoch 350, Train Loss : 6.713586151599884, Test Loss : 0.8987277746200562\n",
      "-- Epoch 400, Train Loss : 6.713533282279968, Test Loss : 0.8986003994941711\n",
      "-- Epoch 450, Train Loss : 6.713540196418762, Test Loss : 0.8985135555267334\n",
      "Saving after new best accuracy : 84.615\n",
      "-- Epoch 500, Train Loss : 6.71342396736145, Test Loss : 0.8984347581863403\n",
      "-- Epoch 550, Train Loss : 6.7131969928741455, Test Loss : 0.8984482884407043\n",
      "-- Epoch 600, Train Loss : 6.713170886039734, Test Loss : 0.8982487916946411\n",
      "-- Epoch 650, Train Loss : 6.712481260299683, Test Loss : 0.8991342186927795\n",
      "-- Epoch 700, Train Loss : 6.712454676628113, Test Loss : 0.8991953134536743\n",
      "-- Epoch 750, Train Loss : 6.712445855140686, Test Loss : 0.8991748094558716\n",
      "-- Epoch 800, Train Loss : 6.712435662746429, Test Loss : 0.8992169499397278\n",
      "-- Epoch 850, Train Loss : 6.712431013584137, Test Loss : 0.8992474675178528\n",
      "-- Epoch 900, Train Loss : 6.712427914142609, Test Loss : 0.8992810249328613\n",
      "-- Epoch 950, Train Loss : 6.712425649166107, Test Loss : 0.8993219137191772\n",
      "-- Epoch 1000, Train Loss : 6.712424159049988, Test Loss : 0.8993672132492065\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 177.03 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456])\n",
      "1456 vs 1456\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.574 %\n",
      "- Recall : 93.142 %\n",
      "- F1 : 0.91323\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 76.955 %\n",
      "- Recall : 73.333 %\n",
      "- F1 : 0.751\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 65.278 %\n",
      "- Recall : 61.842 %\n",
      "- F1 : 0.63514\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 84.496 %\n",
      "- Recall : 75.172 %\n",
      "- F1 : 0.79562\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.615 %\n",
      "- Precision : 79.076 %\n",
      "- Recall : 75.872 %\n",
      "- F1 : 0.77441\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 84.615, 79.076, 75.872, 0.77441, 89.574, 93.142, 0.91323, 76.955, 73.333, 0.751, 65.278, 61.842, 0.63514, 84.496, 75.172, 0.79562, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630])\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.786 %\n",
      "- Recall : 94.737 %\n",
      "- F1 : 0.92195\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 75.556 %\n",
      "- Recall : 69.388 %\n",
      "- F1 : 0.7234\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 75.758 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.70922\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 88.679 %\n",
      "- Recall : 81.034 %\n",
      "- F1 : 0.84685\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.19 %\n",
      "- Precision : 82.445 %\n",
      "- Recall : 77.956 %\n",
      "- F1 : 0.80138\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 86.19, 82.445, 77.956, 0.80138, 89.786, 94.737, 0.92195, 75.556, 69.388, 0.7234, 75.758, 66.667, 0.70922, 88.679, 81.034, 0.84685, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
