{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    testting  \n",
       "1        3  training    training  \n",
       "2        2      test  validation  \n",
       "3        2      test    training  \n",
       "4        3  training    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4323, 768)\n",
      "(1418, 768)\n",
      "(684, 768)\n",
      "(4323,)\n",
      "(1418,)\n",
      "(684,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 84.908\n",
      "-- Epoch 50, Train Loss : 0.02388525507194572, Test Loss : 1.5273817777633667\n",
      "-- Epoch 100, Train Loss : 0.014499368377300925, Test Loss : 2.085505485534668\n",
      "-- Epoch 150, Train Loss : 0.010920917070734504, Test Loss : 2.405564308166504\n",
      "-- Epoch 200, Train Loss : 0.009739112403664762, Test Loss : 2.7048709392547607\n",
      "-- Epoch 250, Train Loss : 0.005527055680339288, Test Loss : 3.0850718021392822\n",
      "-- Epoch 300, Train Loss : 0.0035176907890077658, Test Loss : 3.6924021244049072\n",
      "-- Epoch 350, Train Loss : 0.00320781408414883, Test Loss : 4.126949787139893\n",
      "-- Epoch 400, Train Loss : 0.003075996622843691, Test Loss : 4.432519912719727\n",
      "-- Epoch 450, Train Loss : 0.0030110635466904373, Test Loss : 4.69698429107666\n",
      "-- Epoch 500, Train Loss : 0.0029710663399491327, Test Loss : 4.943790435791016\n",
      "-- Epoch 550, Train Loss : 0.002944597155867257, Test Loss : 5.183165073394775\n",
      "-- Epoch 600, Train Loss : 0.002918633048747843, Test Loss : 5.4115400314331055\n",
      "-- Epoch 650, Train Loss : 0.0029022191752960946, Test Loss : 5.653133869171143\n",
      "-- Epoch 700, Train Loss : 0.0028868703833350162, Test Loss : 5.900601863861084\n",
      "-- Epoch 750, Train Loss : 0.009062054188666124, Test Loss : 3.9947690963745117\n",
      "-- Epoch 800, Train Loss : 0.004262121838280536, Test Loss : 4.72096061706543\n",
      "-- Epoch 850, Train Loss : 0.003647646217359579, Test Loss : 5.065694808959961\n",
      "-- Epoch 900, Train Loss : 0.003361360797320842, Test Loss : 5.300397872924805\n",
      "-- Epoch 950, Train Loss : 0.003188620361740377, Test Loss : 5.501963138580322\n",
      "-- Epoch 1000, Train Loss : 0.0030709494272400384, Test Loss : 5.688497543334961\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 159.0 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1418])\n",
      "1418 vs 1418\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.18 %\n",
      "- Recall : 92.412 %\n",
      "- F1 : 0.90768\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 73.438 %\n",
      "- Recall : 78.008 %\n",
      "- F1 : 0.75654\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 71.667 %\n",
      "- Recall : 56.954 %\n",
      "- F1 : 0.63469\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 89.764 %\n",
      "- Recall : 79.72 %\n",
      "- F1 : 0.84444\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.908 %\n",
      "- Precision : 81.012 %\n",
      "- Recall : 76.774 %\n",
      "- F1 : 0.78836\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_RoBERTa_Finetuned Validation, 84.908, 81.012, 76.774, 0.78836, 89.18, 92.412, 0.90768, 73.438, 78.008, 0.75654, 71.667, 56.954, 0.63469, 89.764, 79.72, 0.84444, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([684])\n",
      "684 vs 684\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 90.719 %\n",
      "- Recall : 90.719 %\n",
      "- F1 : 0.90719\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 63.78 %\n",
      "- Recall : 73.636 %\n",
      "- F1 : 0.68354\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 72.727 %\n",
      "- Recall : 64.0 %\n",
      "- F1 : 0.68085\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 76.667 %\n",
      "- Recall : 67.647 %\n",
      "- F1 : 0.71875\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.749 %\n",
      "- Precision : 75.973 %\n",
      "- Recall : 74.001 %\n",
      "- F1 : 0.74974\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_RoBERTa_Finetuned Test, 82.749, 75.973, 74.001, 0.74974, 90.719, 90.719, 0.90719, 63.78, 73.636, 0.68354, 72.727, 64.0, 0.68085, 76.667, 67.647, 0.71875, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"Phemernr2_multiclass_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
