{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "unique_name = \"SBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_SBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test  \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training  \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test  \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test  \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3862, 768)\n",
      "(1280, 768)\n",
      "(1283, 768)\n",
      "(3862,)\n",
      "(1280,)\n",
      "(1283,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 65.156\n",
      "Saving after new best accuracy : 66.562\n",
      "Saving after new best accuracy : 70.078\n",
      "Saving after new best accuracy : 72.578\n",
      "Saving after new best accuracy : 74.219\n",
      "Saving after new best accuracy : 74.609\n",
      "Saving after new best accuracy : 74.922\n",
      "Saving after new best accuracy : 75.469\n",
      "Saving after new best accuracy : 75.859\n",
      "Saving after new best accuracy : 76.25\n",
      "Saving after new best accuracy : 76.719\n",
      "Saving after new best accuracy : 76.953\n",
      "Saving after new best accuracy : 77.969\n",
      "Saving after new best accuracy : 79.922\n",
      "Saving after new best accuracy : 80.156\n",
      "Saving after new best accuracy : 80.391\n",
      "Saving after new best accuracy : 80.703\n",
      "Saving after new best accuracy : 81.562\n",
      "Saving after new best accuracy : 82.031\n",
      "Saving after new best accuracy : 82.188\n",
      "-- Epoch 50, Train Loss : 0.9757373072206974, Test Loss : 0.5999240279197693\n",
      "Saving after new best accuracy : 82.5\n",
      "Saving after new best accuracy : 82.734\n",
      "Saving after new best accuracy : 82.891\n",
      "Saving after new best accuracy : 83.203\n",
      "Saving after new best accuracy : 83.75\n",
      "Saving after new best accuracy : 83.984\n",
      "-- Epoch 100, Train Loss : 0.05202048528008163, Test Loss : 0.855706512928009\n",
      "-- Epoch 150, Train Loss : 0.036877109203487635, Test Loss : 1.0014278888702393\n",
      "-- Epoch 200, Train Loss : 0.03133086528396234, Test Loss : 1.1160768270492554\n",
      "-- Epoch 250, Train Loss : 0.08120255870744586, Test Loss : 0.7554123401641846\n",
      "-- Epoch 300, Train Loss : 0.024478575098328292, Test Loss : 0.9415407180786133\n",
      "-- Epoch 350, Train Loss : 0.015295600693207234, Test Loss : 1.03659987449646\n",
      "-- Epoch 400, Train Loss : 0.012518134550191462, Test Loss : 1.1063963174819946\n",
      "-- Epoch 450, Train Loss : 0.011678209732053801, Test Loss : 1.1587574481964111\n",
      "-- Epoch 500, Train Loss : 0.01055466546677053, Test Loss : 1.198307752609253\n",
      "-- Epoch 550, Train Loss : 0.01003397916792892, Test Loss : 1.2311147451400757\n",
      "-- Epoch 600, Train Loss : 0.0095003402675502, Test Loss : 1.2599029541015625\n",
      "-- Epoch 650, Train Loss : 0.00861537606397178, Test Loss : 1.2866708040237427\n",
      "-- Epoch 700, Train Loss : 0.008049918389588129, Test Loss : 1.3114217519760132\n",
      "-- Epoch 750, Train Loss : 0.007390794729872141, Test Loss : 1.3354170322418213\n",
      "-- Epoch 800, Train Loss : 0.006454270023823483, Test Loss : 1.3598849773406982\n",
      "-- Epoch 850, Train Loss : 0.005852834790857742, Test Loss : 1.3859354257583618\n",
      "-- Epoch 900, Train Loss : 0.00545553660049336, Test Loss : 1.411015272140503\n",
      "-- Epoch 950, Train Loss : 0.004620506550054415, Test Loss : 1.4412846565246582\n",
      "-- Epoch 1000, Train Loss : 0.004438035670318641, Test Loss : 1.469714641571045\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1280])\n",
      "1280 vs 1280\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 86.883 %\n",
      "- Recall : 92.926 %\n",
      "- F1 : 0.89803\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 79.085 %\n",
      "- Recall : 65.405 %\n",
      "- F1 : 0.71598\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 73.913 %\n",
      "- Recall : 63.433 %\n",
      "- F1 : 0.68273\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 78.333 %\n",
      "- Recall : 74.016 %\n",
      "- F1 : 0.76113\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.984 %\n",
      "- Precision : 79.554 %\n",
      "- Recall : 73.945 %\n",
      "- F1 : 0.76647\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_SBERT_NLI_Mean Validation, 83.984, 79.554, 73.945, 0.76647, 86.883, 92.926, 0.89803, 79.085, 65.405, 0.71598, 73.913, 63.433, 0.68273, 78.333, 74.016, 0.76113, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1283])\n",
      "1283 vs 1283\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 84.65 %\n",
      "- Recall : 92.707 %\n",
      "- F1 : 0.88496\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 75.0 %\n",
      "- Recall : 63.768 %\n",
      "- F1 : 0.6893\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 65.6 %\n",
      "- Recall : 57.746 %\n",
      "- F1 : 0.61423\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 84.375 %\n",
      "- Recall : 64.8 %\n",
      "- F1 : 0.73303\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.45 %\n",
      "- Precision : 77.406 %\n",
      "- Recall : 69.755 %\n",
      "- F1 : 0.73382\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_SBERT_NLI_Mean Test, 81.45, 77.406, 69.755, 0.73382, 84.65, 92.707, 0.88496, 75.0, 63.768, 0.6893, 65.6, 57.746, 0.61423, 84.375, 64.8, 0.73303, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr2_multiclass_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
