{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNTF\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label2\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/phemernr2-multiclass_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "        \n",
    "bigram_vector_base = bigram_vector_base[:bigram_limit]\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519)\n",
      "(1456, 1519)\n",
      "(630, 1519)\n",
      "(4339,)\n",
      "(1456,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 84.203\n",
      "Saving after new best accuracy : 84.341\n",
      "Saving after new best accuracy : 84.409\n",
      "-- Epoch 50, Train Loss : 0.05138502432964742, Test Loss : 1.0997650623321533\n",
      "Saving after new best accuracy : 84.547\n",
      "Saving after new best accuracy : 84.615\n",
      "Saving after new best accuracy : 84.684\n",
      "-- Epoch 100, Train Loss : 0.03429842198966071, Test Loss : 1.3910340070724487\n",
      "-- Epoch 150, Train Loss : 0.030078206589678302, Test Loss : 1.6590975522994995\n",
      "-- Epoch 200, Train Loss : 0.0279837937123375, Test Loss : 1.877467393875122\n",
      "-- Epoch 250, Train Loss : 0.026308074971893802, Test Loss : 2.08290696144104\n",
      "-- Epoch 300, Train Loss : 0.02497732060146518, Test Loss : 2.269888162612915\n",
      "-- Epoch 350, Train Loss : 0.024584264116128907, Test Loss : 2.450331211090088\n",
      "-- Epoch 400, Train Loss : 0.02239356005884474, Test Loss : 2.5999066829681396\n",
      "-- Epoch 450, Train Loss : 0.022203850756341126, Test Loss : 2.7421443462371826\n",
      "-- Epoch 500, Train Loss : 0.019772085339354817, Test Loss : 2.884610652923584\n",
      "-- Epoch 550, Train Loss : 0.01863123453949811, Test Loss : 3.0031557083129883\n",
      "-- Epoch 600, Train Loss : 0.01753490580813377, Test Loss : 3.1476094722747803\n",
      "-- Epoch 650, Train Loss : 0.018553867637820076, Test Loss : 3.266934633255005\n",
      "-- Epoch 700, Train Loss : 0.015119057861738838, Test Loss : 3.4084718227386475\n",
      "-- Epoch 750, Train Loss : 0.01595717422424059, Test Loss : 3.5403459072113037\n",
      "-- Epoch 800, Train Loss : 0.013712583322558203, Test Loss : 3.7220590114593506\n",
      "-- Epoch 850, Train Loss : 0.01305087253513193, Test Loss : 3.914703130722046\n",
      "-- Epoch 900, Train Loss : 0.013690393711840443, Test Loss : 3.998896360397339\n",
      "-- Epoch 950, Train Loss : 0.012628741417756828, Test Loss : 4.2319488525390625\n",
      "-- Epoch 1000, Train Loss : 0.012236254904109956, Test Loss : 4.430782318115234\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 169.77 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456])\n",
      "1456 vs 1456\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.67 %\n",
      "- Recall : 93.142 %\n",
      "- F1 : 0.91373\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 77.731 %\n",
      "- Recall : 72.549 %\n",
      "- F1 : 0.75051\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 65.333 %\n",
      "- Recall : 64.474 %\n",
      "- F1 : 0.64901\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 83.721 %\n",
      "- Recall : 74.483 %\n",
      "- F1 : 0.78832\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.684 %\n",
      "- Precision : 79.114 %\n",
      "- Recall : 76.162 %\n",
      "- F1 : 0.7761\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 84.684, 79.114, 76.162, 0.7761, 89.67, 93.142, 0.91373, 77.731, 72.549, 0.75051, 65.333, 64.474, 0.64901, 83.721, 74.483, 0.78832, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630])\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.786 %\n",
      "- Recall : 94.737 %\n",
      "- F1 : 0.92195\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 77.907 %\n",
      "- Recall : 68.367 %\n",
      "- F1 : 0.72826\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 75.0 %\n",
      "- Recall : 68.0 %\n",
      "- F1 : 0.71329\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 87.273 %\n",
      "- Recall : 82.759 %\n",
      "- F1 : 0.84956\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.349 %\n",
      "- Precision : 82.491 %\n",
      "- Recall : 78.466 %\n",
      "- F1 : 0.80428\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 86.349, 82.491, 78.466, 0.80428, 89.786, 94.737, 0.92195, 77.907, 68.367, 0.72826, 75.0, 68.0, 0.71329, 87.273, 82.759, 0.84956, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
