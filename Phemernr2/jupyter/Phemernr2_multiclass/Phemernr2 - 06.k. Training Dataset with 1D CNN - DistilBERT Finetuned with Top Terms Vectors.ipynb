{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNTF\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label2\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/phemernr2-multiclass_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "        \n",
    "bigram_vector_base = bigram_vector_base[:bigram_limit]\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519, 1)\n",
      "(1456, 1519, 1)\n",
      "(630, 1519, 1)\n",
      "(4339,)\n",
      "(1456,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 78.915\n",
      "Saving after new best accuracy : 80.288\n",
      "Saving after new best accuracy : 81.731\n",
      "Saving after new best accuracy : 82.212\n",
      "-- Epoch 50, Train Loss : 6.704820930957794, Test Loss : 0.9199010133743286\n",
      "-- Epoch 100, Train Loss : 6.701378881931305, Test Loss : 0.9216323494911194\n",
      "-- Epoch 150, Train Loss : 6.700309634208679, Test Loss : 0.9231330752372742\n",
      "-- Epoch 200, Train Loss : 6.6996700167655945, Test Loss : 0.9244848489761353\n",
      "-- Epoch 250, Train Loss : 6.6993401646614075, Test Loss : 0.9248687624931335\n",
      "-- Epoch 300, Train Loss : 6.698981046676636, Test Loss : 0.9250938296318054\n",
      "-- Epoch 350, Train Loss : 6.698814749717712, Test Loss : 0.9251731038093567\n",
      "-- Epoch 400, Train Loss : 6.6987528800964355, Test Loss : 0.9251570105552673\n",
      "-- Epoch 450, Train Loss : 6.698898434638977, Test Loss : 0.926192045211792\n",
      "-- Epoch 500, Train Loss : 6.698233008384705, Test Loss : 0.9261265993118286\n",
      "-- Epoch 550, Train Loss : 6.6982033252716064, Test Loss : 0.9262390732765198\n",
      "-- Epoch 600, Train Loss : 6.698187470436096, Test Loss : 0.9263355135917664\n",
      "-- Epoch 650, Train Loss : 6.69817727804184, Test Loss : 0.9264018535614014\n",
      "-- Epoch 700, Train Loss : 6.698171317577362, Test Loss : 0.9264747500419617\n",
      "-- Epoch 750, Train Loss : 6.698167085647583, Test Loss : 0.9265398979187012\n",
      "-- Epoch 800, Train Loss : 6.698163986206055, Test Loss : 0.9265908598899841\n",
      "-- Epoch 850, Train Loss : 6.698162019252777, Test Loss : 0.9266471266746521\n",
      "-- Epoch 900, Train Loss : 6.698160350322723, Test Loss : 0.9266876578330994\n",
      "-- Epoch 950, Train Loss : 6.698159277439117, Test Loss : 0.9267377853393555\n",
      "-- Epoch 1000, Train Loss : 6.69815856218338, Test Loss : 0.9267833828926086\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 180.74 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456])\n",
      "1456 vs 1456\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 86.517 %\n",
      "- Recall : 93.695 %\n",
      "- F1 : 0.89963\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 73.82 %\n",
      "- Recall : 67.451 %\n",
      "- F1 : 0.70492\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 64.706 %\n",
      "- Recall : 50.658 %\n",
      "- F1 : 0.56827\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.8 %\n",
      "- Recall : 69.655 %\n",
      "- F1 : 0.74815\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.212 %\n",
      "- Precision : 76.461 %\n",
      "- Recall : 70.365 %\n",
      "- F1 : 0.73286\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Validation, 82.212, 76.461, 70.365, 0.73286, 86.517, 93.695, 0.89963, 73.82, 67.451, 0.70492, 64.706, 50.658, 0.56827, 80.8, 69.655, 0.74815, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630])\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 87.471 %\n",
      "- Recall : 94.486 %\n",
      "- F1 : 0.90843\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 78.313 %\n",
      "- Recall : 66.327 %\n",
      "- F1 : 0.71823\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 77.586 %\n",
      "- Recall : 60.0 %\n",
      "- F1 : 0.67669\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 84.483 %\n",
      "- Recall : 84.483 %\n",
      "- F1 : 0.84483\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.079 %\n",
      "- Precision : 81.963 %\n",
      "- Recall : 76.324 %\n",
      "- F1 : 0.79043\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Test, 85.079, 81.963, 76.324, 0.79043, 87.471, 94.486, 0.90843, 78.313, 66.327, 0.71823, 77.586, 60.0, 0.67669, 84.483, 84.483, 0.84483, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4d368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
