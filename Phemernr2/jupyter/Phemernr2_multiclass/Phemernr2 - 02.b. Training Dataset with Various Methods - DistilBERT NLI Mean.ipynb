{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "unique_name = \"DistilBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_DistilBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test  \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training  \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test  \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test  \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = data['label2'].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d['label2'])\n",
    "#     labels.append([1 if j == lab else 0 for j in range(len(labels_str))])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3862, 768)\n",
      "(1280, 768)\n",
      "(1283, 768)\n",
      "(3862,)\n",
      "(1280,)\n",
      "(1283,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 65.156\n",
      "Saving after new best accuracy : 67.969\n",
      "Saving after new best accuracy : 68.516\n",
      "Saving after new best accuracy : 72.969\n",
      "Saving after new best accuracy : 74.062\n",
      "Saving after new best accuracy : 74.141\n",
      "Saving after new best accuracy : 75.781\n",
      "Saving after new best accuracy : 76.328\n",
      "Saving after new best accuracy : 77.344\n",
      "Saving after new best accuracy : 78.047\n",
      "Saving after new best accuracy : 81.406\n",
      "Saving after new best accuracy : 81.562\n",
      "Saving after new best accuracy : 82.344\n",
      "Saving after new best accuracy : 82.734\n",
      "Saving after new best accuracy : 82.969\n",
      "-- Epoch 50, Train Loss : 0.9934362471103668, Test Loss : 0.5552955865859985\n",
      "Saving after new best accuracy : 83.281\n",
      "Saving after new best accuracy : 83.359\n",
      "Saving after new best accuracy : 83.438\n",
      "-- Epoch 100, Train Loss : 0.06436486588791013, Test Loss : 0.9092872738838196\n",
      "-- Epoch 150, Train Loss : 0.041301033459603786, Test Loss : 1.0762025117874146\n",
      "-- Epoch 200, Train Loss : 0.048473117931280285, Test Loss : 1.2122666835784912\n",
      "-- Epoch 250, Train Loss : 0.05832515982910991, Test Loss : 0.8622986078262329\n",
      "-- Epoch 300, Train Loss : 0.024364082724787295, Test Loss : 1.0475170612335205\n",
      "-- Epoch 350, Train Loss : 0.016655243060085922, Test Loss : 1.1230738162994385\n",
      "-- Epoch 400, Train Loss : 0.014402155502466485, Test Loss : 1.182132363319397\n",
      "-- Epoch 450, Train Loss : 0.013772418344160542, Test Loss : 1.229186773300171\n",
      "-- Epoch 500, Train Loss : 0.013068014042801224, Test Loss : 1.267661690711975\n",
      "-- Epoch 550, Train Loss : 0.01243654232530389, Test Loss : 1.3003157377243042\n",
      "-- Epoch 600, Train Loss : 0.011866846776683815, Test Loss : 1.3298008441925049\n",
      "-- Epoch 650, Train Loss : 0.01098660216666758, Test Loss : 1.3557603359222412\n",
      "-- Epoch 700, Train Loss : 0.009732815567986108, Test Loss : 1.3804950714111328\n",
      "-- Epoch 750, Train Loss : 0.008729621600650717, Test Loss : 1.4094746112823486\n",
      "-- Epoch 800, Train Loss : 0.007746040209895, Test Loss : 1.4385545253753662\n",
      "-- Epoch 850, Train Loss : 0.006954794516786933, Test Loss : 1.4682259559631348\n",
      "-- Epoch 900, Train Loss : 0.006009779706801055, Test Loss : 1.4996252059936523\n",
      "-- Epoch 950, Train Loss : 0.005310824737534858, Test Loss : 1.5336432456970215\n",
      "-- Epoch 1000, Train Loss : 0.004673680374253308, Test Loss : 1.5750811100006104\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1280])\n",
      "1280 vs 1280\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.417 %\n",
      "- Recall : 92.446 %\n",
      "- F1 : 0.90387\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 67.857 %\n",
      "- Recall : 71.892 %\n",
      "- F1 : 0.69816\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 73.469 %\n",
      "- Recall : 53.731 %\n",
      "- F1 : 0.62069\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 80.702 %\n",
      "- Recall : 72.441 %\n",
      "- F1 : 0.76349\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.438 %\n",
      "- Precision : 77.611 %\n",
      "- Recall : 72.628 %\n",
      "- F1 : 0.75037\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_DistilBERT_NLI_Mean Validation, 83.438, 77.611, 72.628, 0.75037, 88.417, 92.446, 0.90387, 67.857, 71.892, 0.69816, 73.469, 53.731, 0.62069, 80.702, 72.441, 0.76349, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1283])\n",
      "1283 vs 1283\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 85.682 %\n",
      "- Recall : 93.201 %\n",
      "- F1 : 0.89284\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 68.473 %\n",
      "- Recall : 67.15 %\n",
      "- F1 : 0.67805\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 70.103 %\n",
      "- Recall : 47.887 %\n",
      "- F1 : 0.56904\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 77.67 %\n",
      "- Recall : 64.0 %\n",
      "- F1 : 0.70175\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.138 %\n",
      "- Precision : 75.482 %\n",
      "- Recall : 68.06 %\n",
      "- F1 : 0.71579\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2_multiclass_4LayerNet_DistilBERT_NLI_Mean Test, 81.138, 75.482, 68.06, 0.71579, 85.682, 93.201, 0.89284, 68.473, 67.15, 0.67805, 70.103, 47.887, 0.56904, 77.67, 64.0, 0.70175, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr2_multiclass_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
