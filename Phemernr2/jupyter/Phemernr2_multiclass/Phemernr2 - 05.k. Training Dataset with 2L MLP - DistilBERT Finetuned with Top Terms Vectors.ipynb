{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNTF\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'true', 'unverified', 'false']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label2\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector_base = []\n",
    "with open(\"../../data/processed/phemernr2-multiclass_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        bigram_vector_base.append(t)\n",
    "        \n",
    "bigram_vector_base = bigram_vector_base[:bigram_limit]\n",
    "len(bigram_vector_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    bigrams = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    bigrams = [t for t in bigrams if t not in string.punctuation]\n",
    "    bigrams = [t for t in bigrams if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(bigrams)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "bigram_vectors = bigrams_vectors_generation(texts)\n",
    "\n",
    "vectors = np.concatenate([vectors, bigram_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519)\n",
      "(1456, 1519)\n",
      "(630, 1519)\n",
      "(4339,)\n",
      "(1456,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 78.915\n",
      "Saving after new best accuracy : 81.799\n",
      "Saving after new best accuracy : 82.212\n",
      "-- Epoch 50, Train Loss : 0.014678345483844168, Test Loss : 1.4516501426696777\n",
      "-- Epoch 100, Train Loss : 0.0106615454533312, Test Loss : 1.7533926963806152\n",
      "-- Epoch 150, Train Loss : 0.008737530246889946, Test Loss : 1.968947172164917\n",
      "-- Epoch 200, Train Loss : 0.007044689576559904, Test Loss : 2.156506299972534\n",
      "-- Epoch 250, Train Loss : 0.005898758642388202, Test Loss : 2.3221850395202637\n",
      "-- Epoch 300, Train Loss : 0.005134868478990029, Test Loss : 2.4570631980895996\n",
      "-- Epoch 350, Train Loss : 0.004676587965150247, Test Loss : 2.576918601989746\n",
      "-- Epoch 400, Train Loss : 0.004286199777880029, Test Loss : 2.688373327255249\n",
      "-- Epoch 450, Train Loss : 0.004015793558437508, Test Loss : 2.8100829124450684\n",
      "-- Epoch 500, Train Loss : 0.0037831804934285174, Test Loss : 2.924804925918579\n",
      "-- Epoch 550, Train Loss : 0.0035545757632462482, Test Loss : 3.0542027950286865\n",
      "-- Epoch 600, Train Loss : 0.0034578813842927048, Test Loss : 3.170196294784546\n",
      "-- Epoch 650, Train Loss : 0.0032409899690719612, Test Loss : 3.2984156608581543\n",
      "-- Epoch 700, Train Loss : 0.003115282201406444, Test Loss : 3.4262263774871826\n",
      "-- Epoch 750, Train Loss : 0.003017808757419971, Test Loss : 3.5661494731903076\n",
      "-- Epoch 800, Train Loss : 0.0030048440610812577, Test Loss : 3.6803834438323975\n",
      "-- Epoch 850, Train Loss : 0.00291397748600275, Test Loss : 3.808917760848999\n",
      "-- Epoch 900, Train Loss : 0.002894923278986994, Test Loss : 3.931925058364868\n",
      "-- Epoch 950, Train Loss : 0.00284395410081828, Test Loss : 4.133303642272949\n",
      "-- Epoch 1000, Train Loss : 0.0028205509296803655, Test Loss : 4.358400821685791\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAFXCAYAAABN1VJsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkfklEQVR4nO3de5wcZZ3v8c+XmWSGXCQYI0KiCShwDCEXmUMgiFwS1AWUXdYLGDAobpawLwJeQBAvLIfs6jm7gMAKRAUUBkSRgAusCAgSDxDOBAMkXJZbIOFOJFcIhPA7f3RNpRkmMz2Zrq6a6e/79epXuquqq56q6fS3n+epekoRgZmZGcBWeRfAzMyKw6FgZmYph4KZmaUcCmZmlnIomJlZyqFgZmYph4LZZkjaV9KjNdzev0o6qVbb62T7Z0i6oov590rarZZlstpzKFinJC2VNC3vctSSpJD0kfbXETE/Inat0bZHAF8GLq7F9rbQvwFn5l0Iy5ZDweqOpMa8y9CJY4CbIuL1vAvShd8BB0j6QN4Fsew4FKxHJDVJOlfSc8njXElNybz3SbpB0kpJf5U0X9JWybxvS3pW0hpJj0qaupn1byPpl5JelvS0pO9K2irZ7kpJ48qWHSHpdUnvT14fKmlRstxdksaXLbs0KcMDwLqOwSDpzuTp/ZLWSvqipP0lLe+wjpMlPSBpnaSfS9pO0n8l+3WrpG3Llt8rKcdKSfdL2r+LQ/s3wJ86lKm7/TlN0kOSXpV0qaTmsvn/IOnx5O/wO0k7lM3bTdItybwXJX2nbLMDk+O/RtISSS3tMyJiPbAQ+FQX+2F9XUT44ce7HsBSYFon088E7gHeD4wA7gL+VzLvX4GLgAHJY19AwK7AMmCHZLkxwIc3s91fAtcDQ5Pl/hs4Npl3CTCnbNl/An6fPJ8EvARMBhqAGck+NJXtzyLgg8DWm9l2AB8pe70/sLzDMbkH2A4YmWzvvmTbzcAfgR8ky44EVgAHU/rxdVDyesRmtv0y8D/LXleyP4uT/Xkv8H+Bs5J5BwKvAB8DmoDzgTuTeUOB54FvJmUeCkxO5p0BrE/K3JD8Pe/pUM7zgLPz/nz6kd3DNQXrqenAmRHxUkS8DPwzcHQybwOwPTA6IjZEqU0+gI2UvpzGShoQEUsj4omOK5bUABwBnBYRayJiKfDvZeu/Mpnf7kvJNICZwMURsSAiNkbEL4A3gL3Klj8vIpZF75pozo+IFyPiWWA+sCAi/hKlX9HzKH2ZAxxFqTnopoh4OyJuAdoofeF2Zhiwpux1JftzQbI/fwXmAEcm06cDl0TEfRHxBnAasLekMcChwAsR8e8RsT45zgvK1vnnpMwbgcuBCR3KuSYpq/VTDgXrqR2Ap8teP51MA/g/wOPAHyQ9KelUgIh4HDiJ0i/RlyT9qrw5o8z7KNUwOq5/ZPL8dmCQpMnJF9xESl/EAKOBbyZNLSslraT0K7p8O8t6urOdeLHs+eudvB5SVp7PdyjPxymFZmdepfSrvV1P96f87/COv1FErKVUSxmZrONdgVzmhbLnrwHNHZrahgIru3i/9XEOBeup5yh9YbX7UDKN5FfnNyNiJ+CzwDfa+w4i4sqI+Hjy3gB+1Mm6X6FU2+i4/meTdWwEfk3pF/GRwA0R0f7rehmlpqVhZY9BEXFV2bpqOSTwMuDyDuUZHBE/3MzyDwC7dHh/d/vzwbLn6d+BDn8jSYOB4ZSO4zJgp17s10eB+3vxfis4h4J1ZYCk5rJHI3AV8N2kk/d9wPeBKyDtGP2IJAGrKDUbvS1pV0kHJh3S6yn9on6748bKvvTnSBoqaTTwjfb1J64EvkipieTKsuk/BY5LahGSNFjSIZLKf31350V694VZ7grgM5I+JakhOX77Sxq1meVvAvYre13J/vyTpFGS3gucDlydTL8K+Iqkickx/xdKzVxLgRuA7SWdlHTeD5U0uZIdSjqy9wBuqfAYWB/kULCu3ETpC7z9cQZwFqW28QeAByl1tJ6VLL8zcCuwFrgb+ElE3E6pP+GHlGoCL1DqpD5tM9s8AVgHPAn8mdIX/yXtM5P273WUmkj+q2x6G/APwAWUmmIep3SaZ0+cAfwiaa75Qg/f+w4RsQw4DPgOpU7kZcDJbP7/3C+BgyVtnby/kv25EvgDpWP1BMnfISJuBb4H/JZSp/KHSfpikprVQcBnKP0tHgMOqHC3PgPcERHPdbuk9Vkq9QOaWd4k/QvwUkScW8GyS4GvJQFQE5IWUDoTbHGttmm1V8SLeMzqUkR8p/ul8hMRFTUzWd/m5iMzM0u5+cjMzFKuKZiZWcqhYGZmqUJ1NEvvi9JwNyV77JFfWczM+oKFCxe+EhEjqrW+QoVCKRDaABg9Gtraci2MmVnhSXq6+6UqV8jmo0GDYM6cvEthZlZ/ChcKo0fD3LkwfXreJTEzqz+Faj7aaSd4oqvxG83MLFOZ1hQkfT25e9NiSVeV3xnKzMyKJ7NQkDQSmA20RMQ4SndyOqLrd5mZWZ6y7lNoBLZOhlwexKbx3s3MrIAyC4XkdoX/BjxDafjeVRHxh6y2Z2ZmvZdl89G2lMaT35HS2PeDJR3VyXIzJbVJalu9enVWxTEzswpk2Xw0DXgqIl6OiA3AtcCUjgtFxNyIaImIlve85z0ZFsfMzLqTZSg8A+wlaVBye8apwMNdvcEDtpqZ5SvLPoUFwDWUbtf4YLKtuVltz8zMei/Ti9ci4gfAD7LchpmZVU/hhrkwM7P8OBTMzCzlUDAzs5RDwczMUg4FMzNLORTMzCzlUDAzs5RDwczMUoUKBQ9zYWaWr0KFgpmZ5cuhYGZmKYeCmZmlHApmZpZyKJiZWcqhYGZmKYeCmZmlHApmZpYqVCj44jUzs3wVKhTMzCxfDgUzM0s5FMzMLOVQMDOzlEPBzMxSDgUzM0s5FMzMLJVZKEjaVdKissdqSSdltT0zM+u9xqxWHBGPAhMBJDUAzwLzstqemZn1Xq2aj6YCT0TE0zXanpmZbYFahcIRwFXdLeRhLszM8pV5KEgaCHwW+M1m5s+U1Capbe3atVkXx8zMulCLmsLfAPdFxIudzYyIuRHREhEtQ4YMqUFxzMxsc2oRCkdSQdORmZnlL9NQkDQYOAi4NsvtmJlZdWR2SipARKwDhme5DTMzqx5f0WxmZimHgpmZpRwKZmaWciiYmVnKoWBmZqlChYKHuTAzy1ehQsHMzPLlUDAzs5RDwczMUg4FMzNLORTMzCzlUDAzs5RDwczMUg4FMzNLORTMzCzlUDAzs1ShQsHDXJiZ5atQoWBmZvlyKJiZWcqhYGZmKYeCmZmlHApmZpZyKJiZWcqhYGZmKYeCmZmlHApmZpbKNBQkDZN0jaRHJD0sae8st2dmZr3TmPH6fwz8PiI+J2kgMKirhT3MhZlZvjILBUnbAJ8AjgGIiDeBN7PanpmZ9V6WzUc7Ai8Dl0r6i6SfSRrccSFJMyW1SWpbt25dhsUxM7PuZBkKjcDHgAsjYhKwDji140IRMTciWiKiZfDgd2WGmZnVUJahsBxYHhELktfXUAoJMzMrqMxCISJeAJZJ2jWZNBV4KKvtmZlZ72V99tEJQGty5tGTwFcy3p6ZmfVCpqEQEYuAliy3YWZm1eMrms3MLOVQMDOzlEPBzMxSDgUzM0sVKhQ89pGZWb4KFQpmZpYvh4KZmaUcCmZmlnIomJlZyqFgZmYph4KZmaUcCmZmlnIomJlZyqFgZmYph4KZmaUKFQoe5sLMLF+FCgUzM8uXQ8HMzFIOBTMzSzkUzMws5VAwM7OUQ8HMzFIOBTMzSzkUzMws5VAwM7NUY5Yrl7QUWANsBN6KiJYst2dmZr2TaSgkDoiIVypZ0MNcmJnly81HZmaWyjoUAviDpIWSZna2gKSZktoktb322msZF8fMzLqSdfPRxyPiWUnvB26R9EhE3Fm+QETMBeYCbL99ixuQzMxylGlNISKeTf59CZgH7Jnl9szMrHcyCwVJgyUNbX8OfBJYnNX2zMys97JsPtoOmCepfTtXRsTvM9yemZn1UmahEBFPAhOyWr+ZmVWfT0k1M7OUQ8HMzFIOBTMzSxUqFDzMhZlZvgoVCmZmli+HgpmZpRwKZmaWciiYmVnKoWBmZimHgpmZpRwKZmaWciiYmVnKoWBmZimHgplZX3P88SCBxB6wRzVXnfXtOHvEw1yYmXXh+OPhwgsz3URFNYXkLmpbJc93kfRZSQMyLZmZmZW01wwyDgSovPnoTqBZ0kjgD8DRwGVZFcrMzIBp02oWBu0qDQVFxGvA4cBPIuLzwG7ZFcvMrI61h8Ftt9V80xWHgqS9genAjcm0hmyKZGZWh8o6j/MIg3aVdjSfBJwGzIuIJZJ2Am7PrFRmZvWiBp3HPVFRKETEn4A/ASQdzq9ExOwsC2Zm1q9Nm1aVGkFAVc/brPTsoyslvUfSYGAx8JCkk6tZEDOzulCt/oLGRrjiCu6D+6pTsJJK+xTGRsRq4G+B/wJ2pHQGkpmZdae1FZqaqhMGzc1wxRWwYQNMn16d8pWptE9hQHJdwt8CF0TEBkm+1MzMrCvV7C+YOhVuvbU66+pCpaFwMbAUuB+4U9JoYHVWhTIz69Oq1F8A1CwM2lXUfBQR50XEyIg4OEqeBg6o5L2SGiT9RdIN3W+nkjWamRVQNZuIkv4CImoaCFB5R/M2ks6W1JY8/h0YXOE2TgQe3uISmpkVWfv1BUcdBW++2bt1ZdxfUIlKO5ovAdYAX0geq4FLu3uTpFHAIcDPtrSAZmaFU36hWTX6DKZOLdUKXn89tzBoV2mfwocj4u/LXv+zpEUVvO9c4BRg6OYWkDQTmAkwZMjYCotjZlYjra3wj/8I69ZVf9017i+oRKU1hdclfbz9haR9gNe7eoOkQ4GXImJhV8tFxNyIaImIlq233rrC4piZZai8f+Coo6ofCLNm5dJfUIlKawrHAb+UtE3y+lVgRjfv2Qf4rKSDgWbgPZKuiIijtqyoZmYZqcVQE83N8LOf5d481J1Kh7m4H5gg6T3J69WSTgIe6OI9p1EaLwlJ+wPfciCYWSFU85TR7hSwiagrPbodZ0SsTq5sBvhGBuUxM6u+9qElajkKaYGbiLrSm3s0q9IFI+KOiDi0F9syM6tc+dlBtRyKuv2U0gj4yU9qs80q6809mn2pmZkVRy2bhMr1kb6CSnUZCpLW0PmXvwCfKmRm+cjzHgRDhsBFF/WbEOioy1CIiM1eX5AFD3NhZpuVZxDMmtVnm4N6qjfNR2Zm2ckrBPpZc1BPORTMLH959QdAnztlNGu9OfvIzGzL5HV2EGwaZ6j94UB4B4eCmWWvYwjUslmo/DRRh0C33HxkZtlobYWvfrX3w0lvCTcJbTGHgplVh68T6BccCma2ZfLsHHYQZMahYGaVc22g33MomFnn8uoTcH9Arnz2kZltUn6WUDXuOVwJnx1UKK4pmNWzPK4adlNQoRUqFDz2kVnG8jxNtI7GD+rLChUKZpaBPGoD7hfosxwKZv1Rrc8Scgj0G+5oNuvrWluhqan2YwmVjyHkQOg3HApmfVH5PYdrdZZQ+z2HHQT9mkPBrC/IY1TRjqeKupO4LrhPwaxofHMZy5FrCmZFUF4TqGUglDcJvf66A8FcUzCrqTyvEwDXBqxbDgWzLOUdAuDTRa1H3HxkVk0dTw+t1ZlB5XyWkPVCZjUFSc3AnUBTsp1rIuIHXb3Hw1xYn5TnfQXANQGrqixrCm8AB0bEBGAi8GlJe2W4PbPaKL9GoNY3nQePKmqZyqymEBEBrE1eDkgergtY3+M7jFkdybRPQVKDpEXAS8AtEbGgk2VmSmqT1PbGG29kWRyznmmvEeRZE/BpolZjmYZCRGyMiInAKGBPSeM6WWZuRLREREtTU1OWxTF7t87GDapls1DHTmEHgeWsJmcfRcRK4Hbg07XYntlmdRwuotZnB3UMAQ8dYQWTWShIGiFpWPJ8a+Ag4JGstmfWqY41gVoPH+EQsD4my4vXtgd+IamBUvj8OiJuyHB7ZiV5jR0EPj3U+rwszz56AJiU1frNAF8jYFZlvqLZ+pY8hpAuV35jGV8jYP2Qxz6yYivC2EEAY8fCkiX5lsGsBgpVU/AwF/auq4XzGDuonFS6ZsCBYHWiUKFgdSjPISM6Dhcxdeo750+dCm+/7WsGrK4UKhRefRXGjCm1GFg/1LE/II8+ga5uKnPrre4vsLpXuD6Fp5+GmTNLz/0DrY/L89TQdh47yKxHFAVqyJdaAtoAGD0ali7NtzzWQz491KzmJC2MiJZqra9QzUflnnkm7xJYtzyEtFm/U9hQ+NCH8i6BvUNnA8flHQIeOM6s6grXpwAwaBDMmZN3KczNQWb1p3A1hdGjYe5c/wCsuSLUBHy1sFnuClVTGDbMncs1k/eVwj4ryKyQChUKBToRqv/Kq0nIIWDWJxQqFKzKPIS0mfWQQ6G/ySsIHAJm/UKhOprdfLSFyoePqFUgdLyjmAPBrF9wTaGvqnWNwDUBs7pQqJqCdaOWNQLXBMzqkmsKRVerGsGsWb6pvJkVKxTcp5Co1TUEvpuYmXXg5qMiaR9gLou7jTU2wvDhpfWPHu27iZlZpwpVU6hLWTYP+YIxM+uhQoVC3TQfOQjMrKAKFQr9Wpb9BA4CM6sSh0LWshpryEFgZhnIrKNZ0gcl3S7pIUlLJJ2Y1bYKp/x6gmoGQvlNZnyDGTPLQJY1hbeAb0bEfZKGAgsl3RIRD23uDX2+TyGrWoGvITCzGsksFCLieeD55PkaSQ8DI4HNhkKflFVfgYeVMLMc1OQ6BUljgEnAgk7mzZTUJqltw4YNtShOdbQ3EVXzmoLy5iEHgpnlIPNQkDQE+C1wUkSs7jg/IuZGREtEtDQ2Dsi6OL1TfsvKap1SOmSI+wnMrDAyPftI0gBKgdAaEddmua1MtbbCjBmwcWP11ul+AjMroMxCQZKAnwMPR8TZWW0nU9W+yMz9BGZWcFk2H+0DHA0cKGlR8jg4w+1VT3t/QTUCwf0EZtaHZHn20Z8B9ew9GRWmUtU8pdS1AjPrgzxKKmwanbQagdB+cxoHgpn1QfU9zEW1agYecsLM+olC1RRq1nzU3mfQ20BorxX4VFIz6yfqq6ZQrbOJfDqpmfVT9REKra1w9NG9q4o0NsJll7lGYGb9Wv8Phd12g4d6MdyS+wvMrI703z6F1tZSv8GWBsLUqe4vMLO60z9rCr2pHfj6AjOrY4WqKfRab2oHY8f6+gIzq3uFCoVeNR9Nm1YaxrqnGhtLw1AsWdKLjZuZ9Q/9o/loS5qLGhrgF79wf4GZWZm+HwojR8Jzz/XsPb7OwMysU307FLbdFlaurHz5HXaAZ5/NrDhmZn1d3+1T6GkgzJrlQDAz60bfrCn0JBBcOzAzq1ihagoV6UkgTJ3qQDAz64FChUK3zUc9CYRZs3zNgZlZD/Wd5qORIysLBAkuv9ynmpqZbYG+EQrTplV22umwYfDqq5kXx8ysvypU81Gnjj++spvhOBDMzHqtUKHwrj6F1tbKborjQDAzq4pChcK7HHNM98s4EMzMqqa4oTBtGrz1VtfLSA4EM7MqKlQopM1Hra2V9SNcfnmm5TEzqzeFCoXUccd1v8zUqT7t1MysyjI7JVXSJcChwEsRMa7iN7a2wtq1XS8zdqwvTDMruA0bNrB8+XLWr1+fd1H6hebmZkaNGsWAAQMy3Y6iqjdGLlux9AlgLfDLSkOhoaElNg5cAl19iBoauu9rMLPcPfXUUwwdOpThw4cjKe/i9GkRwYoVK1izZg077rjjO+ZJWhgRLdXaVmbNRxFxJ/DXnrxn27f/2nUgQOnGOGZWeOvXr3cgVIkkhg8fXpNaV6H6FEbxTNcLDB7sfgSzPsSBUD21Opa5h4KkmZLaJLU1srHrhS++uDaFMrM+b8WKFUycOJGJEyfygQ98gJEjR6av33zzzS7f29bWxuzZs3u0vTFjxvDKK6/0psiFkHsoRMTciGjptk3MZxuZ9WutrTBmDGy1Venf1tberW/48OEsWrSIRYsWcdxxx/H1r389fT1w4EDe6qJvsqWlhfPOO693Beijcg+FivlsI7N+q7UVZs6Ep58uXa/09NOl170Nho6OOeYYjjvuOCZPnswpp5zCvffey957782kSZOYMmUKjz76KAB33HEHhx56KABnnHEGX/3qV9l///3ZaaedehQWS5cu5cADD2T8+PFMnTqVZ54pNZH/5je/Ydy4cUyYMIFPfOITACxZsoQ999yTiRMnMn78eB577LHq7nyFsjwl9Spgf+B9kpYDP4iIn2/RyoYPr2LJzKzWTjoJFi3a/Px77oE33njntNdeg2OPhZ/+tPP3TJwI557b87IsX76cu+66i4aGBlavXs38+fNpbGzk1ltv5Tvf+Q6//e1v3/WeRx55hNtvv501a9aw6667MmvWrIpODT3hhBOYMWMGM2bM4JJLLmH27Nlcd911nHnmmdx8882MHDmSlcktAS666CJOPPFEpk+fzptvvsnGjd00p2cks1CIiCOrtrIf/7hqqzKz4ukYCN1N743Pf/7zNDQ0ALBq1SpmzJjBY489hiQ2bNjQ6XsOOeQQmpqaaGpq4v3vfz8vvvgio0aN6nZbd999N9deey0ARx99NKeccgoA++yzD8cccwxf+MIXOPzwwwHYe++9mTNnDsuXL+fwww9n5513rsbu9ljfuJ+C+xLM+rTuftGPGVNqMupo9Gi4447qlmXw4MHp8+9973sccMABzJs3j6VLl7L//vt3+p6mpqb0eUNDQ5f9EZW46KKLWLBgATfeeCN77LEHCxcu5Etf+hKTJ0/mxhtv5OCDD+biiy/mwAMP7NV2tkTx+xTcdGTW782ZA4MGvXPaoEGl6VlatWoVI0eOBOCyyy6r+vqnTJnCr371KwBaW1vZd999AXjiiSeYPHkyZ555JiNGjGDZsmU8+eST7LTTTsyePZvDDjuMBx54oOrlqUTxQ8FNR2b93vTpMHduqWYglf6dOzf7RoJTTjmF0047jUmTJvX61z/A+PHjGTVqFKNGjeIb3/gG559/Ppdeeinjx4/n8ssv58fJ99nJJ5/M7rvvzrhx45gyZQoTJkzg17/+NePGjWPixIksXryYL3/5y70uz5bIbJiLLdEiRVvHiQUqn5lV7uGHH+ajH/1o3sXoVzo7pn1mmIuqSDqDzMysNoodCjmdkmVmVq+KHQqjR+ddAjOzulLsUMj61AMzM3uHYoeCr08wM6up4oaCr08wM6u5Yl7RPGCAr08ws15ZsWIFU6dOBeCFF16goaGBESNGAHDvvfcycODALt9/xx13MHDgQKZMmfKueZdddhltbW1ccMEF1S94zgpXU1i/3Wi49FI3HZnVmyqPnd3d0NndueOOO7jrrrt6VYa+qFChsJA9WHD1UgeCWb2p0djZCxcuZL/99mOPPfbgU5/6FM8//zwA5513HmPHjmX8+PEcccQRLF26lIsuuohzzjmHiRMnMn/+/IrWf/bZZzNu3DjGjRvHucmAT+vWreOQQw5hwoQJjBs3jquvvhqAU089Nd3mt771raruZ28UrvloM4MUmllfVoCxsyOCE044geuvv54RI0Zw9dVXc/rpp3PJJZfwwx/+kKeeeoqmpiZWrlzJsGHDOO644xgyZEjFX9gLFy7k0ksvZcGCBUQEkydPZr/99uPJJ59khx124MYbbwRK4y2tWLGCefPm8cgjjyApHT67CApVUwD45Cerc9clM+tDajB29htvvMHixYs56KCDmDhxImeddRbLly8HSmMWTZ8+nSuuuILGxi37rfznP/+Zv/u7v2Pw4MEMGTKEww8/nPnz57P77rtzyy238O1vf5v58+ezzTbbsM0229Dc3Myxxx7Ltddey6COowHmqHA1hfKaI7glyaxfKMDY2RHBbrvtxt133/2ueTfeeCN33nkn//mf/8mcOXN48MEHq7JNgF122YX77ruPm266ie9+97tMnTqV73//+9x7773cdtttXHPNNVxwwQX88Y9/rNo2e6NwNYV2r70Gp5+edynMrCZqMHZ2U1MTL7/8choKGzZsYMmSJbz99tssW7aMAw44gB/96EesWrWKtWvXMnToUNasWVPx+vfdd1+uu+46XnvtNdatW8e8efPYd999ee655xg0aBBHHXUUJ598Mvfddx9r165l1apVHHzwwZxzzjncf//9VdvP3ipcTaFccjtTM+vv2psETj+99B//Qx8qBUIVmwq22morrrnmGmbPns2qVat46623OOmkk9hll1046qijWLVqFRHB7NmzGTZsGJ/5zGf43Oc+x/XXX8/555+f3guh3WWXXcZ1112Xvr7nnns45phj2HPPPQH42te+xqRJk7j55ps5+eST2WqrrRgwYAAXXngha9as4bDDDmP9+vVEBGeffXbV9rO3CjV0ttQSsGnw7NGjYenS/MpjZlvOQ2dXX10PnT1ggIc+MjOrtcKGgpR3CczM6k9hQ+HNN93RbGZWa4UNBej8DDUz6zuK1GfZ19XqWBY6FACOPz7vEpjZlmhubmbFihUOhiqICFasWEFzc3Pm2yr02UflZs2Cn/ykxgUysy22YcMGli9fzvr16/MuSr/Q3NzMqFGjGDBgwDumV/vsoz4TCn2Bg8vMas2hYGZmZVqIaKva+ZqF71MwM7PacSiYmVmqYM1H226EDzuozMwqtpSIV6rWfFSwUFBbNTtM+jIfixIfh018LDbxsdik2sfCv8rNzCzlUDAzs1TRQmFu3gUoEB+LEh+HTXwsNvGx2KSqx6JQfQpmZpavotUUzMwsR4UIBUmflvSopMclnZp3ebIm6YOSbpf0kKQlkk5Mpr9X0i2SHkv+3TaZLknnJcfnAUkfy3cPqk9Sg6S/SLoheb2jpAXJPl8taWAyvSl5/Xgyf0yuBa8yScMkXSPpEUkPS9q7Xj8Xkr6e/P9YLOkqSc318rmQdImklyQtLpvW48+BpBnJ8o9JmlHJtnMPBUkNwH8AfwOMBY6UNDbfUmXuLeCbETEW2Av4p2SfTwVui4idgduS11A6Njsnj5nAhbUvcuZOBB4ue/0j4JyI+AjwKnBsMv1Y4NVk+jnJcv3Jj4HfR8T/ACZQOiZ197mQNBKYDbRExDigATiC+vlcXAZ8usO0Hn0OJL0X+AEwGdgT+EF7kHQpInJ9AHsDN5e9Pg04Le9y1fgYXA8cBDwKbJ9M2x54NHl+MXBk2fLpcv3hAYxKPuQHAjcAAl4BGjt+RoCbgb2T543Jcsp7H6p0HLYBnuq4P/X4uQBGAsuA9yZ/5xuAT9XT5wIYAyze0s8BcCRwcdn0dyy3uUfuNQU2/fHbLU+m1YWkmjsJWABsFxHPJ7NeALZLnvf3Y3QucArwdvJ6OLAyIt5KXpfvb3oskvmrkuX7gx2Bl4FLk6a0n0kaTB1+LiLiWeDfgGeA5yn9nRdSn5+Ldj39HGzR56MIoVC3JA0BfgucFBGry+dFKdr7/alhkg4FXoqIhXmXpQAagY8BF0bEJGAdm5oIgLr6XGwLHEYpKHcABvPu5pS6leXnoAih8CzwwbLXo5Jp/ZqkAZQCoTUirk0mvyhp+2T+9sBLyfT+fIz2AT4raSnwK0pNSD8GhklqTJYp39/0WCTztwFW1LLAGVoOLI+IBcnrayiFRD1+LqYBT0XEyxGxAbiW0melHj8X7Xr6Odiiz0cRQuH/ATsnZxUMpNSZ9Lucy5QpSQJ+DjwcEWeXzfod0H6GwAxKfQ3t07+cnGWwF7CqrBrZp0XEaRExKiLGUPrb/zEipgO3A59LFut4LNqP0eeS5fvFL+eIeAFYJmnXZNJU4CHq8HNBqdloL0mDkv8v7cei7j4XZXr6ObgZ+KSkbZOa1yeTaV3LuzMl+bsdDPw38ARwet7lqcH+fpxS1e8BYFHyOJhSG+htwGPArcB7k+VF6QytJ4AHKZ2Rkft+ZHBc9gduSJ7vBNwLPA78BmhKpjcnrx9P5u+Ud7mrfAwmUrrT1APAdcC29fq5AP4ZeARYDFwONNXL5wK4ilJfygZKNchjt+RzAHw1OSaPA1+pZNu+otnMzFJFaD4yM7OCcCiYmVnKoWBmZimHgpmZpRwKZmaWcihYXZG0UdKiskfVRuWVNKZ8VEuzvqix+0XM+pXXI2Ji3oUwKyrXFMwASUsl/W9JD0q6V9JHkuljJP0xGaf+NkkfSqZvJ2mepPuTx5RkVQ2SfprcB+APkrbObafMtoBDwerN1h2aj75YNm9VROwOXEBp5FaA84FfRMR4oBU4L5l+HvCniJhAaXyiJcn0nYH/iIjdgJXA32e6N2ZV5iuara5IWhsRQzqZvhQ4MCKeTAYrfCEihkt6hdIY9huS6c9HxPskvQyMiog3ytYxBrglSjdBQdK3gQERcVYNds2sKlxTMNskNvO8J94oe74R99tZH+NQMNvki2X/3p08v4vS6K0A04H5yfPbgFmQ3l96m1oV0ixL/hVj9WZrSYvKXv8+ItpPS91W0gOUfu0fmUw7gdKd0E6mdFe0ryTTTwTmSjqWUo1gFqVRLc36NPcpmJH2KbRExCt5l8UsT24+MjOzlGsKZmaWck3BzMxSDgUzM0s5FMzMLOVQMDOzlEPBzMxSDgUzM0v9fzgDOQll0moxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 175.83 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456])\n",
      "1456 vs 1456\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 86.442 %\n",
      "- Recall : 93.805 %\n",
      "- F1 : 0.89973\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 74.89 %\n",
      "- Recall : 66.667 %\n",
      "- F1 : 0.70539\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 66.379 %\n",
      "- Recall : 50.658 %\n",
      "- F1 : 0.57463\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 77.273 %\n",
      "- Recall : 70.345 %\n",
      "- F1 : 0.73646\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.212 %\n",
      "- Precision : 76.246 %\n",
      "- Recall : 70.369 %\n",
      "- F1 : 0.7319\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Validation, 82.212, 76.246, 70.369, 0.7319, 86.442, 93.805, 0.89973, 74.89, 66.667, 0.70539, 66.379, 50.658, 0.57463, 77.273, 70.345, 0.73646, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630])\n",
      "630 vs 630\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 87.471 %\n",
      "- Recall : 94.486 %\n",
      "- F1 : 0.90843\n",
      "\n",
      "Class true Evaluation\n",
      "- Precision : 78.313 %\n",
      "- Recall : 66.327 %\n",
      "- F1 : 0.71823\n",
      "\n",
      "Class unverified Evaluation\n",
      "- Precision : 77.193 %\n",
      "- Recall : 58.667 %\n",
      "- F1 : 0.66667\n",
      "\n",
      "Class false Evaluation\n",
      "- Precision : 83.051 %\n",
      "- Recall : 84.483 %\n",
      "- F1 : 0.83761\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.921 %\n",
      "- Precision : 81.507 %\n",
      "- Recall : 75.991 %\n",
      "- F1 : 0.78652\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,non-rumours,,,true,,,unverified,,,false,,,\n",
      "Phemernr2-RNTF_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Test, 84.921, 81.507, 75.991, 0.78652, 87.471, 94.486, 0.90843, 78.313, 66.327, 0.71823, 77.193, 58.667, 0.66667, 83.051, 84.483, 0.83761, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = False\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=4, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=binary,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
