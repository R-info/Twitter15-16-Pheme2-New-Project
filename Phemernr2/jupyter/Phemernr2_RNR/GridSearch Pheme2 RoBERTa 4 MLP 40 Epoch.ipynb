{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msi/anaconda3/envs/pytorch-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "torch.manual_seed(33)\n",
    "np.random.seed(33)\n",
    "random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned_Check_Finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/vectors/40_Epoch_Phemernr2-RNR_RoBERTa_base_finetuned_vectors_check_finetune.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>the east london mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>breaking - a germanwings airbus a320 plane rep...</td>\n",
       "      <td>true</td>\n",
       "      <td>validation</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>reports that two of the dead in the #charliehe...</td>\n",
       "      <td>true</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>after #putin disappeared russian tv no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>saw #ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>testting</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  the east london mosque would like to offer its...   \n",
       "1  580318210609696769  breaking - a germanwings airbus a320 plane rep...   \n",
       "2  552798891994009601  reports that two of the dead in the #charliehe...   \n",
       "3  576790814942236672  after #putin disappeared russian tv no longer ...   \n",
       "4  499678822598340608  saw #ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label        tvt2    tvt2_1  \n",
       "0  non-rumours    training  training  \n",
       "1         true  validation  testting  \n",
       "2         true    training  training  \n",
       "3  non-rumours  validation  training  \n",
       "4  non-rumours    testting  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/phemernr2_dataset_with_tvt.csv\", sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['label'].replace(['true', 'unverfied', 'false'], 'rumours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumours', 'non-rumours']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4336, 768)\n",
      "(1462, 768)\n",
      "(627, 768)\n",
      "(4336,)\n",
      "(1462,)\n",
      "(627,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(train_vectors, dtype=torch.float32)\n",
    "y = torch.tensor(train_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5399,  0.6523, -0.1750,  ...,  1.5126, -0.2599, -1.1257],\n",
      "        [ 0.5139, -0.1890,  0.3052,  ..., -0.8881,  0.4728,  0.7124],\n",
      "        [-0.4865,  0.4412, -0.2613,  ...,  1.6282, -0.1829, -0.7105],\n",
      "        ...,\n",
      "        [ 0.4678, -0.1784,  0.3317,  ..., -0.9926,  0.0118,  0.8226],\n",
      "        [-0.4078,  0.4802, -0.2571,  ...,  1.3258, -0.1092, -1.0044],\n",
      "        [-0.4353,  0.5631, -0.2498,  ...,  1.1105, -0.2882, -1.3151]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1,  ..., 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import skorch\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(32, n_output)\n",
    "        )\n",
    "        # self.layer = nn.Linear(n_input, 256)\n",
    "        # self.act = nn.LeakyReLU(0.1)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        # self.layer = nn.Linear(256,128)\n",
    "        # self.act = nn.LeakyReLU(0.1)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        # self.layer = nn.Linear(128,64)\n",
    "        # self.act = nn.LeakyReLU(0.1)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        # self.layer = nn.Linear(64,32)\n",
    "        # self.act = nn.LeakyReLU(0.1)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        # self.output = nn.Linear(32,n_output)\n",
    "        # self.prob = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "    # def forward(self, input):\n",
    "    #     x = self.act(self.layer(input))\n",
    "    #     x = self.prob(self.output(x))\n",
    "    #     return x\n",
    "\n",
    "\n",
    "NNmodeling = NNModel(train_vectors.shape[1], n_output=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from dask_searchcv import GridSearchCV\n",
    "\n",
    "\n",
    "model = NeuralNetClassifier(\n",
    "    NNmodeling,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=optim.Adam,  # Specify optimizer class without instantiating it\n",
    "    optimizer__lr=4e-5,  # Set optimizer-related hyperparameters using optimizer__ prefix\n",
    "    optimizer__betas=(0.5, 0.999),\n",
    "    optimizer__weight_decay=1e-5,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# model = torch.nn.DataParallel(model)\n",
    "# cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Test Score: 0.935194 using parameters {'batch_size': 512, 'max_epochs': 1000}\n",
      "Mean Test Score: 0.891373, Standard Deviation: 0.004518, with parameters: {'batch_size': 256, 'max_epochs': 10}\n",
      "Mean Test Score: 0.891373, Standard Deviation: 0.004518, with parameters: {'batch_size': 256, 'max_epochs': 50}\n",
      "Mean Test Score: 0.891373, Standard Deviation: 0.004518, with parameters: {'batch_size': 256, 'max_epochs': 100}\n",
      "Mean Test Score: 0.928274, Standard Deviation: 0.003122, with parameters: {'batch_size': 256, 'max_epochs': 500}\n",
      "Mean Test Score: 0.934270, Standard Deviation: 0.003408, with parameters: {'batch_size': 256, 'max_epochs': 1000}\n",
      "Mean Test Score: 0.891142, Standard Deviation: 0.004635, with parameters: {'batch_size': 512, 'max_epochs': 10}\n",
      "Mean Test Score: 0.891373, Standard Deviation: 0.004518, with parameters: {'batch_size': 512, 'max_epochs': 50}\n",
      "Mean Test Score: 0.891373, Standard Deviation: 0.004518, with parameters: {'batch_size': 512, 'max_epochs': 100}\n",
      "Mean Test Score: 0.926430, Standard Deviation: 0.001441, with parameters: {'batch_size': 512, 'max_epochs': 500}\n",
      "Mean Test Score: 0.935194, Standard Deviation: 0.000663, with parameters: {'batch_size': 512, 'max_epochs': 1000}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'batch_size': [256, 512],\n",
    "    'max_epochs': [10, 50, 100, 500, 1000]\n",
    "}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, pre_dispatch=\"2*n_jobs\")\n",
    "grid_result = grid.fit(X, y)\n",
    " \n",
    "# summarize results\n",
    "print(\"Best Mean Test Score: %f using parameters %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean Test Score: %f, Standard Deviation: %f, with parameters: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
