{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'rumours']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 people have', 'Chocolate Cafe in', 'release the name', 'die as martyrs', 'as heavily armed', 'explosions heard at', 'Andreas Lubitz', 'Cpl Nathan Cirillo', 'at Massey Hall', 'gunmen were involved']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519, 1)\n",
      "(1456, 1519, 1)\n",
      "(630, 1519, 1)\n",
      "(4339, 1)\n",
      "(1456, 1)\n",
      "(630, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 86.813\n",
      "Saving after new best accuracy : 86.882\n",
      "-- Epoch 50, Train Loss : 0.01990380282586557, Test Loss : 1.0787070989608765\n",
      "Saving after new best accuracy : 86.951\n",
      "-- Epoch 100, Train Loss : 0.014585238820473023, Test Loss : 1.425264835357666\n",
      "-- Epoch 150, Train Loss : 0.012426153364685888, Test Loss : 2.3561418056488037\n",
      "-- Epoch 200, Train Loss : 0.010380841812320796, Test Loss : 2.7345426082611084\n",
      "-- Epoch 250, Train Loss : 0.008711066401474454, Test Loss : 3.2387173175811768\n",
      "-- Epoch 300, Train Loss : 0.007551445366516418, Test Loss : 3.7369604110717773\n",
      "-- Epoch 350, Train Loss : 0.006641044670232077, Test Loss : 4.222742557525635\n",
      "-- Epoch 400, Train Loss : 0.006069517529567747, Test Loss : 4.618679523468018\n",
      "-- Epoch 450, Train Loss : 0.005453027886687778, Test Loss : 5.048550605773926\n",
      "-- Epoch 500, Train Loss : 0.004846547869874485, Test Loss : 5.535965919494629\n",
      "-- Epoch 550, Train Loss : 0.004286821491518822, Test Loss : 6.089792251586914\n",
      "-- Epoch 600, Train Loss : 0.0039387716252576865, Test Loss : 6.509202480316162\n",
      "-- Epoch 650, Train Loss : 0.00318052141695091, Test Loss : 7.119287014007568\n",
      "-- Epoch 700, Train Loss : 0.002964481755761028, Test Loss : 7.798562049865723\n",
      "-- Epoch 750, Train Loss : 0.0028627773246725496, Test Loss : 8.138998985290527\n",
      "-- Epoch 800, Train Loss : 0.002813181768063444, Test Loss : 8.396539688110352\n",
      "-- Epoch 850, Train Loss : 0.0027810963360859198, Test Loss : 8.586145401000977\n",
      "-- Epoch 900, Train Loss : 0.0027806710715738703, Test Loss : 8.761219024658203\n",
      "-- Epoch 950, Train Loss : 0.0027356587970328583, Test Loss : 8.932313919067383\n",
      "-- Epoch 1000, Train Loss : 0.0027288055386933685, Test Loss : 9.039939880371094\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 78.8 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 445\n",
      "False Positive : 83\n",
      "False Negative : 107\n",
      "True Negative : 821\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 84.28 %\n",
      "- Recall : 80.616 %\n",
      "- F1 : 0.82407\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.47 %\n",
      "- Recall : 90.819 %\n",
      "- F1 : 0.89629\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.951 %\n",
      "- Precision : 86.375 %\n",
      "- Recall : 85.717 %\n",
      "- F1 : 0.86045\n",
      "- Average Confidence : 98.28 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Validation, 86.951, 86.375, 85.717, 0.86045, 84.28, 80.616, 0.82407, 88.47, 90.819, 0.89629, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 193\n",
      "False Positive : 29\n",
      "False Negative : 38\n",
      "True Negative : 370\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 86.937 %\n",
      "- Recall : 83.55 %\n",
      "- F1 : 0.8521\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 90.686 %\n",
      "- Recall : 92.732 %\n",
      "- F1 : 0.91698\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 89.365 %\n",
      "- Precision : 88.812 %\n",
      "- Recall : 88.141 %\n",
      "- F1 : 0.88475\n",
      "- Average Confidence : 98.64 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_DistilBERT_Finetuned_with_TopTermsVectors Test, 89.365, 88.812, 88.141, 0.88475, 86.937, 83.55, 0.8521, 90.686, 92.732, 0.91698, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56e75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
