{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'rumours']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 people have', 'Chocolate Cafe in', 'release the name', 'die as martyrs', 'as heavily armed', 'explosions heard at', 'Andreas Lubitz', 'Cpl Nathan Cirillo', 'at Massey Hall', 'gunmen were involved']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519)\n",
      "(1456, 1519)\n",
      "(630, 1519)\n",
      "(4339, 1)\n",
      "(1456, 1)\n",
      "(630, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 86.607\n",
      "Saving after new best accuracy : 86.676\n",
      "Saving after new best accuracy : 86.745\n",
      "-- Epoch 50, Train Loss : 0.1323893559165299, Test Loss : 0.9423947334289551\n",
      "-- Epoch 100, Train Loss : 0.12488668691366911, Test Loss : 1.1319825649261475\n",
      "Saving after new best accuracy : 86.813\n",
      "-- Epoch 150, Train Loss : 0.11057552485726774, Test Loss : 4.038262367248535\n",
      "-- Epoch 200, Train Loss : 0.10314364079385996, Test Loss : 4.919301509857178\n",
      "-- Epoch 250, Train Loss : 0.0991327331867069, Test Loss : 5.22094202041626\n",
      "-- Epoch 300, Train Loss : 0.09550998476333916, Test Loss : 5.345265865325928\n",
      "Saving after new best accuracy : 86.951\n",
      "-- Epoch 350, Train Loss : 0.09329372178763151, Test Loss : 5.3616814613342285\n",
      "-- Epoch 400, Train Loss : 0.09126364928670228, Test Loss : 5.488813877105713\n",
      "-- Epoch 450, Train Loss : 0.08918510749936104, Test Loss : 5.612274169921875\n",
      "-- Epoch 500, Train Loss : 0.08767811581492424, Test Loss : 5.623234748840332\n",
      "-- Epoch 550, Train Loss : 0.08648631954565644, Test Loss : 5.807966232299805\n",
      "-- Epoch 600, Train Loss : 0.08509107399731874, Test Loss : 5.818451881408691\n",
      "-- Epoch 650, Train Loss : 0.0840364689938724, Test Loss : 5.999024868011475\n",
      "-- Epoch 700, Train Loss : 0.08323579141870141, Test Loss : 5.951171875\n",
      "-- Epoch 750, Train Loss : 0.08235076279379427, Test Loss : 6.012617588043213\n",
      "-- Epoch 800, Train Loss : 0.08164494624361396, Test Loss : 6.022765159606934\n",
      "-- Epoch 850, Train Loss : 0.08100210828706622, Test Loss : 6.022643566131592\n",
      "-- Epoch 900, Train Loss : 0.08048630249686539, Test Loss : 6.149095058441162\n",
      "-- Epoch 950, Train Loss : 0.07991846045479178, Test Loss : 6.153582572937012\n",
      "-- Epoch 1000, Train Loss : 0.07960212603211403, Test Loss : 6.158144474029541\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 75.62 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 459\n",
      "False Positive : 97\n",
      "False Negative : 93\n",
      "True Negative : 807\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 82.554 %\n",
      "- Recall : 83.152 %\n",
      "- F1 : 0.82852\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.667 %\n",
      "- Recall : 89.27 %\n",
      "- F1 : 0.89468\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.951 %\n",
      "- Precision : 86.11 %\n",
      "- Recall : 86.211 %\n",
      "- F1 : 0.8616\n",
      "- Average Confidence : 98.22 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 86.951, 86.11, 86.211, 0.8616, 82.554, 83.152, 0.82852, 89.667, 89.27, 0.89468, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 197\n",
      "False Positive : 26\n",
      "False Negative : 34\n",
      "True Negative : 373\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 88.341 %\n",
      "- Recall : 85.281 %\n",
      "- F1 : 0.86784\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 91.646 %\n",
      "- Recall : 93.484 %\n",
      "- F1 : 0.92556\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 90.476 %\n",
      "- Precision : 89.993 %\n",
      "- Recall : 89.383 %\n",
      "- F1 : 0.89687\n",
      "- Average Confidence : 98.35 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 90.476, 89.993, 89.383, 0.89687, 88.341, 85.281, 0.86784, 91.646, 93.484, 0.92556, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
