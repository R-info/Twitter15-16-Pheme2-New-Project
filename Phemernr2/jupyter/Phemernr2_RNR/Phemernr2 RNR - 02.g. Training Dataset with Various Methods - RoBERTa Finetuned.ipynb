{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    testting  \n",
       "1        3  training    training  \n",
       "2        2      test  validation  \n",
       "3        2      test    training  \n",
       "4        3  training  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4327, 768)\n",
      "(1450, 768)\n",
      "(648, 768)\n",
      "(4327,)\n",
      "(1450,)\n",
      "(648,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 87.517\n",
      "Saving after new best accuracy : 87.586\n",
      "Saving after new best accuracy : 87.655\n",
      "-- Epoch 50, Train Loss : 0.23672072915360332, Test Loss : 0.48662009835243225\n",
      "-- Epoch 100, Train Loss : 0.23239566665142775, Test Loss : 0.494281142950058\n",
      "-- Epoch 150, Train Loss : 0.2255492014810443, Test Loss : 0.49509844183921814\n",
      "-- Epoch 200, Train Loss : 0.22112553799524903, Test Loss : 0.5094568729400635\n",
      "-- Epoch 250, Train Loss : 0.2152203069999814, Test Loss : 0.5356339812278748\n",
      "Saving after new best accuracy : 87.793\n",
      "-- Epoch 300, Train Loss : 0.21015511499717832, Test Loss : 0.5708776116371155\n",
      "Saving after new best accuracy : 87.862\n",
      "Saving after new best accuracy : 88.0\n",
      "-- Epoch 350, Train Loss : 0.2120659020729363, Test Loss : 0.5870996713638306\n",
      "-- Epoch 400, Train Loss : 0.2064963816665113, Test Loss : 0.6211240291595459\n",
      "-- Epoch 450, Train Loss : 0.2077932939864695, Test Loss : 0.6115251779556274\n",
      "-- Epoch 500, Train Loss : 0.20197268296033144, Test Loss : 0.6490012407302856\n",
      "-- Epoch 550, Train Loss : 0.20210305182263255, Test Loss : 0.6393804550170898\n",
      "-- Epoch 600, Train Loss : 0.2126158932223916, Test Loss : 0.6236924529075623\n",
      "-- Epoch 650, Train Loss : 0.2011985187418759, Test Loss : 0.6548336148262024\n",
      "-- Epoch 700, Train Loss : 0.2105883900076151, Test Loss : 0.6267028450965881\n",
      "-- Epoch 750, Train Loss : 0.19756908272393048, Test Loss : 0.706386387348175\n",
      "-- Epoch 800, Train Loss : 0.19455487770028412, Test Loss : 0.6996684074401855\n",
      "-- Epoch 850, Train Loss : 0.21084981132298708, Test Loss : 0.6844229102134705\n",
      "-- Epoch 900, Train Loss : 0.20450700027868152, Test Loss : 0.6813192963600159\n",
      "-- Epoch 950, Train Loss : 0.20627375529147685, Test Loss : 0.7130531072616577\n",
      "-- Epoch 1000, Train Loss : 0.1994773312471807, Test Loss : 0.7635745406150818\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 139.55 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1450])\n",
      "1450 vs 1450\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 85.82 %\n",
      "- Recall : 82.771 %\n",
      "- F1 : 0.84268\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 89.305 %\n",
      "- Recall : 91.319 %\n",
      "- F1 : 0.90301\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.0 %\n",
      "- Precision : 87.562 %\n",
      "- Recall : 87.045 %\n",
      "- F1 : 0.87303\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_RoBERTa_Finetuned Validation, 88.0, 87.562, 87.045, 0.87303, 85.82, 82.771, 0.84268, 89.305, 91.319, 0.90301, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([648])\n",
      "648 vs 648\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 83.186 %\n",
      "- Recall : 78.008 %\n",
      "- F1 : 0.80514\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 87.441 %\n",
      "- Recall : 90.663 %\n",
      "- F1 : 0.89023\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.957 %\n",
      "- Precision : 85.313 %\n",
      "- Recall : 84.336 %\n",
      "- F1 : 0.84822\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_RoBERTa_Finetuned Test, 85.957, 85.313, 84.336, 0.84822, 83.186, 78.008, 0.80514, 87.441, 90.663, 0.89023, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
