{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"BERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    testting  \n",
       "1        3  training    training  \n",
       "2        2      test  validation  \n",
       "3        2      test    training  \n",
       "4        3  training  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4327, 768)\n",
      "(1450, 768)\n",
      "(648, 768)\n",
      "(4327,)\n",
      "(1450,)\n",
      "(648,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 86.207\n",
      "Saving after new best accuracy : 86.552\n",
      "-- Epoch 50, Train Loss : 0.009101573562929843, Test Loss : 1.6381508111953735\n",
      "-- Epoch 100, Train Loss : 0.000148278494023657, Test Loss : 2.5856919288635254\n",
      "-- Epoch 150, Train Loss : 3.8058366723436876e-05, Test Loss : 2.980496406555176\n",
      "-- Epoch 200, Train Loss : 1.6563942836500534e-05, Test Loss : 3.2308762073516846\n",
      "-- Epoch 250, Train Loss : 8.795654389090468e-06, Test Loss : 3.418642282485962\n",
      "-- Epoch 300, Train Loss : 5.1366009043429806e-06, Test Loss : 3.572877883911133\n",
      "-- Epoch 350, Train Loss : 3.2505043878611195e-06, Test Loss : 3.705167293548584\n",
      "-- Epoch 400, Train Loss : 2.1481058662814467e-06, Test Loss : 3.822936534881592\n",
      "-- Epoch 450, Train Loss : 1.475109712545386e-06, Test Loss : 3.9301719665527344\n",
      "-- Epoch 500, Train Loss : 1.0365100160253382e-06, Test Loss : 4.030094623565674\n",
      "-- Epoch 550, Train Loss : 7.403749277962168e-07, Test Loss : 4.1240458488464355\n",
      "-- Epoch 600, Train Loss : 5.373591692586777e-07, Test Loss : 4.213515281677246\n",
      "-- Epoch 650, Train Loss : 3.934762905499767e-07, Test Loss : 4.299514293670654\n",
      "-- Epoch 700, Train Loss : 2.910342073447758e-07, Test Loss : 4.382412433624268\n",
      "-- Epoch 750, Train Loss : 2.172287000834494e-07, Test Loss : 4.462677955627441\n",
      "-- Epoch 800, Train Loss : 1.6274734314369876e-07, Test Loss : 4.5409464836120605\n",
      "-- Epoch 850, Train Loss : 1.23166677731823e-07, Test Loss : 4.617361068725586\n",
      "-- Epoch 900, Train Loss : 9.359749374160398e-08, Test Loss : 4.6922607421875\n",
      "-- Epoch 950, Train Loss : 7.078027207396698e-08, Test Loss : 4.765458106994629\n",
      "-- Epoch 1000, Train Loss : 5.401656533177146e-08, Test Loss : 4.836706161499023\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAFXCAYAAABN1VJsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAk40lEQVR4nO3deZhU9Z3v8feXBroFGVQkUelIS6LeIEIT+4pijAs4ZlDjxMmiAYNRx6HNIxgTjEoW45WZ5N6JCzqixigqpTFxTcTEuBHxqngbgwgu45JG2p02IIIg4Pf+UaebsumupavOUlWf1/PUQ9U5p+r8TnVRn/ot53fM3REREQHoE3cBREQkORQKIiLSSaEgIiKdFAoiItJJoSAiIp0UCiIi0kmhINIDMzvUzF6McH//YWZnR7W/bvZ/oZnNz7L+KTPbL8oySfQUCtItM2s1s4lxlyNKZuZm9rmOx+6+yN33jWjfQ4FvA9dEsb9e+k/gorgLIeFSKEjVMbO+cZehG6cA97n7h3EXJIvfA0eY2W5xF0TCo1CQgphZrZldZmZvBLfLzKw2WLermd1rZmvM7D0zW2RmfYJ1PzSz181snZm9aGYTenj9wWZ2k5m9a2YrzexHZtYn2O8aMxuVse1QM/vQzD4VPD7WzJYG2z1uZqMztm0NyrAMWN81GMzs0eDuM2b2gZl908wON7O2Lq8x08yWmdl6M/u1mX3azP4YHNeDZrZzxvYHBeVYY2bPmNnhWd7afwL+0qVMuY7nfDN7zsz+bmY3mFldxvp/NbOXg7/D781sj4x1+5nZA8G6t83sgozd9g/e/3VmtsLMmjpWuPtGYAlwdJbjkHLn7rrptt0NaAUmdrP8IuBJ4FPAUOBx4H8F6/4DuBroF9wOBQzYF1gF7BFs1wB8tof93gTcAwwKtvtv4LRg3fXA7Ixtvwv8Kbg/FngHGAfUAFODY6jNOJ6lwGeAHXrYtwOfy3h8ONDW5T15Evg0MCzY39PBvuuAh4GfBtsOA9qBSaR/fB0VPB7aw77fBf5nxuN8jmd5cDy7AP8XuDhYdySwGvgCUAtcATwarBsEvAl8PyjzIGBcsO5CYGNQ5prg7/lkl3LOAS6J+/OpW3g31RSkUJOBi9z9HXd/F/gZcHKwbjOwOzDc3Td7uk3ega2kv5xGmlk/d29191e6vrCZ1QAnAue7+zp3bwV+mfH6twTrO3wrWAZwBnCNuy92963ufiOwCTgoY/s57r7Ki2uiucLd33b314FFwGJ3/6unf0XfRfrLHGAK6eag+9z9Y3d/AGgh/YXbnZ2AdRmP8zmeK4PjeQ+YDZwULJ8MXO/uT7v7JuB84GAzawCOBd5y91+6+8bgfV6c8ZqPBWXeCtwMjOlSznVBWaVCKRSkUHsAKzMerwyWAfwf4GXgz2b2qpmdB+DuLwNnk/4l+o6Z/SazOSPDrqRrGF1ff1hw/xFggJmNC77gGkl/EQMMB74fNLWsMbM1pH9FZ+5nVaEH2423M+5/2M3jHTPK8/Uu5fki6dDszt9J/2rvUOjxZP4dPvE3cvcPSNdShgWvsV0gZ3gr4/4GoK5LU9sgYE2W50uZUyhIod4g/YXVYc9gGcGvzu+7+wjgK8A5HX0H7n6Lu38xeK4Dv+jmtVeTrm10ff3Xg9fYCvyW9C/ik4B73b3j1/Uq0k1LO2XcBrj7rRmvFeWUwKuAm7uUZ6C7/7yH7ZcB+3R5fq7j+UzG/c6/A13+RmY2EBhC+n1cBYwo4rg+DzxTxPMl4RQKkk0/M6vLuPUFbgV+FHTy7gr8BJgPnR2jnzMzA9aSbjb62Mz2NbMjgw7pjaR/UX/cdWcZX/qzzWyQmQ0Hzul4/cAtwDdJN5HckrH8V8C0oBZhZjbQzI4xs8xf37m8TXFfmJnmA8eZ2dFmVhO8f4ebWX0P298HHJbxOJ/j+a6Z1ZvZLsAs4LZg+a3Ad8ysMXjP/510M1crcC+wu5mdHXTeDzKzcfkcUNCRfQDwQJ7vgZQhhYJkcx/pL/CO24XAxaTbxpcBz5LuaL042H5v4EHgA+AJ4Cp3f4R0f8LPSdcE3iLdSX1+D/s8C1gPvAo8RvqL//qOlUH793rSTSR/zFjeAvwrcCXpppiXSQ/zLMSFwI1Bc803CnzuJ7j7KuB44ALSncirgJn0/H/uJmCSme0QPD+f47kF+DPp9+oVgr+Duz8I/Bi4g3Sn8mcJ+mKCmtVRwHGk/xYvAUfkeVjHAQvd/Y2cW0rZsnQ/oIjEzcz+HXjH3S/LY9tW4PQgACJhZotJjwRbHtU+JXpJPIlHpCq5+wW5t4qPu+fVzCTlTc1HIiLSSc1HIiLSSTUFERHppFAQEZFOiepo3nXXXb2hoSHuYoiIhO+996C1FYpswm8FVrtbKYoECQuFhoYGWlpa4i6GiEjppVJw6qnw0Uclfdmm3JsUJFGhICJSUSZOhIceirsUBUlUn8KSJdDQkA5UEZGyM3EimG27lVkgQMJCAWDlSjjjDAWDiJSBOEOguRncWZK+8FHJJC4UADZsgFmz4i6FiEgXZ54Zewh03q66KpTdJLZP4bXX4i6BiFS9M8+EuXPj2Xdzc2hf/NkkNhT23DPuEohI1QlphFBeYgqBrhIZCgMGwOzZcZdCRCqeQmA7iQuF4cPTgTB5ctwlEZGKE2cITJgAD0Y203mvJSoURoyAV7JdPVZEpFBxnStQJiHQVaJCQUSkaAqBoiRySKqISN7iGiZaVwfz528bIloBgQCqKYhIuYmrX6CuDq67ruI7PBUKIpJ8cTUJJXSEUJjUfCQiyRNHk1DX5qAQzxpOMtUURCR+cTUJVWFNIBeFgojEI44moQoZIRSmRDUfFXkBIhFJsjiahCZM+GRzkAIhp0SFgohUkFQKamu3hUAUE8tV6DDRKCkURKR0MmsDU6ZE00eQOaX0hx9W/JDRsKlPQUR6L44OYvULhEqhICKFibqDuEpOGksKNR+JSHZd+waiCAQ1CcVGNQUR2V7UVxxTk1BiqKYgItGPFNIoocRSKIhUq6hHCqlJqCyo+UikmkTZSawO4rKkmoJIJYv6LGLVBsqeagoilSbK2oA6iCuOagoi5S7O2oACoeIkqqagCfFE8qS+AQmJagoi5WLiRPUNSOgUCiJJFeWZxF3PG9CFZ6pWopqPRKpelGcSq5NYuqFQEIlbVP0D6huQPKj5SCQOUfUPqG9ACqSagkhUoqgRqDYgRVIoiIQlqgvQqG9ASkihIFJKCgIpc+pTEClW5tDRMGcb1ZnEEgHVFER6I4oagfoHJAaJCgVNcyGJFkUQqFlIYpaoUBBJHAWBVBmFgkhXCgKpYqF3NJtZjZn91czuDXtfIr0WRWexOoqlDEQx+mgG8HwE+xEpTNRBoEnmpAyEGgpmVg8cA1wX5n5ECtIxxYSCQGQ7YdcULgPOBT7uaQMzO8PMWsysZd26dSEXR6pW2HMNKQikQoQWCmZ2LPCOuy/Jtp27X+vuTe7eNGjQoLCKI9Uo8zKVCgKRvIQ5+ugQ4CtmNgmoA/7BzOa7+5QQ9ynVLuyRQ83NCgCpaKHVFNz9fHevd/cG4ETgYQWChCbMfgLVCKSKaO4jKV9hNg8pCKRKRXLymrsvBBZGsS+pcGE2D6lpSERnNEuZCOsCNTqzWOQTEhUKmhBPPkFBIBI59SlIsoTVT1BXB/Pna4oJkRwSVVOQKhZWrUD9BCIFUShIfMLqNFbzkEivKRQkemHUCnSVMpGSUJ+CRCNzRtJSBkLH+QQffqhAECkB1RQkXGeeCXPnlvY11TwkEhqFgoSj1E1ECgKRSKj5SEqn1E1EGkYqEjnVFKR4qRRMnQpbt5bm9VQrEImNagrSex0nmk2ZUppA6Og0ViCIxEY1BSlcKfsLVCsQSRTVFCR/HdcsKEUgqFYgkkiJqiloQryEKlXNQCeYiSReokJBEqSUU1CoiUikbKj5SD4plYK+fUtzWUs1EYmUHdUUJK2Uw0o1M6lI2VIoCOy3Hzz3XHGvof4CkYqgUKhmpehAVn+BSEVRKFQjhYGI9EChUE0UBiKSg0YfVYOO6SiKCQSNJBKpCqopVLJUCk4+ubizAjWSSKSqKBQqVbEjihQGIlVJoVBpiu03UJ+BSFVTn0KlSKWK6zeYMEF9BiKSrJqCJsTrpWKailQzEJEMqimUs45RRb0JhJEjVTMQke0oFMpRKgV9+sDcuYU/t6Ymfd3jFStKXy4RKXuJaj6SPBTTVKQRRSKSg2oK5aKjI7k3gdDRiaxAEJEcVFMoB70dZrrHHvD666Uvj4hULNUUkqyj76A3gdDcrEAQkYKpppBUva0djBypTmQR6TXVFJJo2LDCA0GjikSkBBQKSdLRmfzGG4U9r7kZtmzRVc9EpGhqPkqK3jQXqSNZREpMNYUk6E1z0YQJCgQRKTmFQpx601zU0Xeg6SlEJASJaj6qqgnxetNcpMnrRCRkiQqFqlHoVBVmcPPN6kgWkdApFKKUSsHUqbB1a/7PUWeyiERIfQpROfNMmDKlsEBQZ7KIREw1hSgU2n+g5iIRiYlCIWyF9h+ouUhEYqTmozAVGghqLhKRmCkUwlJoIDQ3a7ipiMROzUdhKCQQ+vaFefPUfyAiiRBaKJhZHfAoUBvs53Z3/2lY+0uMYcPyP0NZ01yLSMKE2Xy0CTjS3ccAjcCXzeygEPcXv0ICYcIEBYKIJE5ooeBpHwQP+wW3yp3IYr/98g8E9R+ISEKF2tFsZjVmthR4B3jA3ReHub/YFNKH0NwMV10VbnlERHop1FBw963u3gjUAwea2aiu25jZGWbWYmYt69evD7M44VAgiEgFiWRIqruvAR4BvtzNumvdvcndmwYMGBhFcUpn4kQFgohUlNBCwcyGmtlOwf0dgKOAF8LaX+TOPDP/qSvmz1cgiEhZCPM8hd2BG82shnT4/Nbd7w1xf9FJpWDu3Py2nT9f5yCISNkILRTcfRkwNqzXj9XUqflt19ysQBCRsqJpLgo1bFh+01+rD0FEypBCoRD5nougQBCRMqVQyFe+I40mTFAgiEjZUijkI5XKb6TRyJE6U1lEyppCIR+nnJJ7mz320FxGIlL2FAq5TJwIW7Zk38ZMF8cRkYqgUMgm32ajm28OvywiIhFQKGSTT7ORzkUQkQqiUOhJPs1GGmkkIhUmUaHgSbnaQj7NRjU1GmkkIhUnUaGQGPk0G914Y+jFEBGJmkKhq3ybjdSPICIVSKGQSc1GIlLlFAqZTj899zZqNhKRCqZQ6JBKwcaN2bdRs5GIVDiFQodctQQ1G4lIFVAoQH61BDUbiUgVUChA7iGoajYSkSqhUMhnCKqajUSkSlR3KOQzBLW5OZqyiIgkQF6hYGYDzaxPcH8fM/uKmfULt2gRmDUr9zaa20hEqki+NYVHgTozGwb8GTgZmBdWoSKzcmX29aoliEiVyTcUzN03ACcAV7n714H9Sl2YSCfES6Wyr6+pUS1BRKpO3qFgZgcDk4EFwbKacIoUkX/7t+zrNQRVRKpQvqFwNnA+cJe7rzCzEcAjoZUqbKkUrF/f83ozDUEVkarUN5+N3P0vwF8Agg7n1e4+PcyChSpXB/O0adGUQ0QkYfIdfXSLmf2DmQ0ElgPPmdnMcIsWolwdzOpLEJEqlW/z0Uh3fx/4Z+CPwF6kRyCVn1wdzEOGRFMOEZEEyjcU+gXnJfwz8Ht33wwk5eKZhcnVwXz55dGUQ0QkgfINhWuAVmAg8KiZDQfeD6tQoVEHs4hIVvl2NM8B5mQsWmlmR4RTpBCpg1lEJKt8O5oHm9klZtYS3H5JutZQXtTBLCKSVb7NR9cD64BvBLf3gRvCKlQs1MEsIpJf8xHwWXf/l4zHPzOzpSGUJzxnnpl9vTqYRUTyril8aGZf7HhgZocAH4ZTpJBcc03P69TBLCIC5F9TmAbcZGaDg8d/B6aWujChTYiXSsHHH/e8Xh3MIiJAevbT/Dc2+wcAd3/fzM5298tKWZjddmvyt95qKeVLpjU0ZO9kjnR6VhGR0jGzJe7eVKrXK+jKa+7+fnBmM8A5pSpE6HKNOhIREaC4y3FayUoRp+HD4y6BiEhiFBMK5dHmkmvU0ezZ0ZRDRKQMZO1TMLN1dP/lb8AO7p5vR3VeQulT6NsXtm7tfp1Z9g5oEZGEK3WfQtYvdXcfVKodxaanQACNOhIR6aKY5qPkyzVNtqa1EBH5hMoOhRkz4i6BiEhZqexQaG/veZ1GHYmIbKeyQyEbjToSEdlO5YZCrv4EzXUkIrKdyg2FbP0JmiZbRKRblRsK2foTNE22iEi3EhUKJZuXTk1HIiK9EloomNlnzOwRM3vOzFaYWXTjQ3Ndi1lERLpV0mkqutgCfN/dnzazQcASM3vA3Z8LcZ9p2WZFVX+CiEiPQqspuPub7v50cH8d8DwwLKz9fUKfLIel/gQRkR5F0qdgZg3AWGBxN+vOMLMWM2v58MMSXeEz2yR36k8QEelR6KFgZjsCdwBnZ1ygp5O7X+vuTe7etMMOOxS/w1ydzCIi0qNQQ8HM+pEOhJS73xnmvjrp/AQRkV4Lc/SRAb8Gnnf3S8Laz3Z0foKISK+FWVM4BDgZONLMlga3SSHuLzf1J4iIZBXakFR3f4yor+Os/gQRkaIk6ozmomU7aU39CSIiOVVWKGQ7aU39CSIiOVVWKNTUdL/cTP0JIiJ5SFQoFD0h3tatIb2wiEh1SFQoFCVbJ3NPNQgREfmE8g+FVAoaGmDKlJ636akGISIinxDmLKnhS6XgjDNgw4bs2w0fHk15RETKXHnXFGbNyh0IALNnh18WEZEKUN6h8Nprubfp318jj0RE8lTeodC/f+5tPvoo/HKIiFSI8g2FVAo2bYq7FCIiFaV8QyHf6zBregsRkbyVbyjk058Amt5CRKQA5RsKu+ySe5vmZnUyi4gUoDxDIZWCNWtyb3fVVaEXRUSkkpRnKMyYobOURURCkKhQyHveumyX3BQRkV5LVCiU1MCBcZdARKTslGco5PrC79MHrrkmmrKIiFSQ8gyFurrs62+6SaOORER6oTxDIVufwpAhCgQRkV4qv1BIpdKX1+yJTlYTEem18guFWbN6Hqakk9VERIpSfqGwcmXP63SymohIUcovFHq63rKuwywiUrTyC4WezmTWGc4iIkUrv1Do00ORVVMQESlaeYVCKgUff9z9OtUURESKVl6hMGNGz+uGD4+uHCIiFSpRoZBzQrxsJ63Nnl3SsoiIVKNEhUJRdH6CiEjRyicUUqme12U7w1lERPJWPqGQrT8h7wsxiIhINuUTCtn6E9TJLCJSEuUTCtmok1lEpCTKIxSy9SeAOplFREqkPEIhW3+CiIiUTHmEgvoTREQikfxQyNV0pP4EEZGSMU/QcM5dd23y1atbui7MXlNIUPlFRKJmZkvcvalUr5f8mkKu6zGLiEjJJD8UstH1mEVESirZoaChqCIikUpUKGzXPaChqCIikUpUKGxHQ1FFRCKV3FDQUFQRkcglakjqkCFN3t4eDEnVUFQRkZyqZ0iqhqKKiEQumaGQq+lIQ1FFREIRWiiY2fVm9o6ZLS/4yblGHWkoqohIKMKsKcwDvtyrZ6rpSEQkFqGFgrs/CrxX8BPVdCQiEpvY+xTM7AwzazGzlo0bN6npSEQkRrGHgrtf6+5N7t5UV1erpiMRkRjFHgqZBm7K0dqkpiMRkVAlKhSGbHgt+wZqOhIRCVWYQ1JvBZ4A9jWzNjM7LddzanxrzyvVdCQiErq+Yb2wu59U0hdU05GISOgS1XyUlZqORERCVx6hoKYjEZFIlEcoqOlIRCQS5REKajoSEYlEeYSCiIhEIvmhoMtuiohEJvmhoMtuiohEJvmhoP4EEZHIJDsU1HQkIhKpZIfCpElxl0BEpKokOxTuuy/uEoiIVJVkh8JrOWZNFRGRkkp2KOy5Z9wlEBGpKskNhf79NRxVRCRiyQ2FQYM0HFVEJGKhXU+haO/luDSniCTa5s2baWtrY+PGjXEXpSLU1dVRX19Pv379Qt1PckNB/QkiZa2trY1BgwbR0NCAmcVdnLLm7rS3t9PW1sZee+0V6r6S2Xw0YID6E0TK3MaNGxkyZIgCoQTMjCFDhkRS60peKAwfDtdeq/4EkQqgQCidqN7LRIXCR1YLra0KBBEpWnt7O42NjTQ2NrLbbrsxbNiwzscfffRR1ue2tLQwffr0gvbX0NDA6tWriylyIiQqFPr7JmhogFQq7qKISMRSqfR//z59SvM1MGTIEJYuXcrSpUuZNm0a3/ve9zof9+/fny1btvT43KamJubMmVNcAcpUokIBgJUr4YwzFAwiVSSVSv+3X7kS3MP7GjjllFOYNm0a48aN49xzz+Wpp57i4IMPZuzYsYwfP54XX3wRgIULF3LssccCcOGFF3Lqqady+OGHM2LEiILCorW1lSOPPJLRo0czYcIEXgtmafjd737HqFGjGDNmDF/60pcAWLFiBQceeCCNjY2MHj2al156qbQHn6dkjj7asAFmzVIzkkiFOPtsWLq05/VPPgmbNn1y2YYNcNpp8Ktfdf+cxka47LLCy9LW1sbjjz9OTU0N77//PosWLaJv3748+OCDXHDBBdxxxx3bPeeFF17gkUceYd26dey77740NzfnNTT0rLPOYurUqUydOpXrr7+e6dOnc/fdd3PRRRdx//33M2zYMNasWQPA1VdfzYwZM5g8eTIfffQRW7duLfzgSiCZoQCa90ikinQNhFzLi/H1r3+dmpoaANauXcvUqVN56aWXMDM2b97c7XOOOeYYamtrqa2t5VOf+hRvv/029fX1Off1xBNPcOeddwJw8sknc+655wJwyCGHcMopp/CNb3yDE044AYCDDz6Y2bNn09bWxgknnMDee+9disMtWHJDQecpiFSMXL/oGxrSTUZdDR8OCxeWtiwDBw7svP/jH/+YI444grvuuovW1lYOP/zwbp9TW1vbeb+mpiZrf0Q+rr76ahYvXsyCBQs44IADWLJkCd/61rcYN24cCxYsYNKkSVxzzTUceeSRRe2nN5LXpwA6T0Gkysyenf5vnymKr4G1a9cybNgwAObNm1fy1x8/fjy/+c1vAEilUhx66KEAvPLKK4wbN46LLrqIoUOHsmrVKl599VVGjBjB9OnTOf7441m2bFnJy5OP5IWCzlMQqTqTJ6f/2w8fDmbRfQ2ce+65nH/++YwdO7boX/8Ao0ePpr6+nvr6es455xyuuOIKbrjhBkaPHs3NN9/M5ZdfDsDMmTPZf//9GTVqFOPHj2fMmDH89re/ZdSoUTQ2NrJ8+XK+/e1vF12e3jB3j2XH3Wky85bhw9M/DxQKImXt+eef5/Of/3zcxago3b2nZrbE3ZtKtY/k1RQ0JFVEJDbJCwXYNiRVREQilcxQAA1JFRGJQXJDQUNSRUQil8xQ0JBUEZFYJC8UNCRVRCQ2iTqjeVm/A6C1Je5iiEgFaG9vZ8KECQC89dZb1NTUMHToUACeeuop+vfvn/X5CxcupH///owfP367dfPmzaOlpYUrr7yy9AWPWfJqCiJSnUo8d3auqbNzWbhwIY8//nhRZShHiQqFBJ1HJyJRimju7CVLlnDYYYdxwAEHcPTRR/Pmm28CMGfOHEaOHMno0aM58cQTaW1t5eqrr+bSSy+lsbGRRYsW5fX6l1xyCaNGjWLUqFFcFkz4tH79eo455hjGjBnDqFGjuO222wA477zzOvf5gx/8oKTHWYxENR+JSIVKwNzZ7s5ZZ53FPffcw9ChQ7ntttuYNWsW119/PT//+c/529/+Rm1tLWvWrGGnnXZi2rRp7Ljjjnl/YS9ZsoQbbriBxYsX4+6MGzeOww47jFdffZU99tiDBQsWAOn5ltrb27nrrrt44YUXMLPO6bOTQDUFEYlfBHNnb9q0ieXLl3PUUUfR2NjIxRdfTFtbG5Ces2jy5MnMnz+fvn1791v5scce46tf/SoDBw5kxx135IQTTmDRokXsv//+PPDAA/zwhz9k0aJFDB48mMGDB1NXV8dpp53GnXfeyYCuswHGSDUFEQlfAubOdnf2228/nnjiie3WLViwgEcffZQ//OEPzJ49m2effbYk+wTYZ599ePrpp7nvvvv40Y9+xIQJE/jJT37CU089xUMPPcTtt9/OlVdeycMPP1yyfRYjUTUFEalSEcydXVtby7vvvtsZCps3b2bFihV8/PHHrFq1iiOOOIJf/OIXrF27lg8++IBBgwaxbt26vF//0EMP5e6772bDhg2sX7+eu+66i0MPPZQ33niDAQMGMGXKFGbOnMnTTz/NBx98wNq1a5k0aRKXXnopzzzzTMmOs1iJqimo+UikSnWclzRrVnqKmz33LPlsyX369OH2229n+vTprF27li1btnD22Wezzz77MGXKFNauXYu7M336dHbaaSeOO+44vva1r3HPPfdwxRVXdF4LocO8efO4++67Ox8/+eSTnHLKKRx44IEAnH766YwdO5b777+fmTNn0qdPH/r168fcuXNZt24dxx9/PBs3bsTdueSSS0p2nMVK1NTZNTVNvnWrzlMQqQSaOrv0qm7q7ATlk4hIVUpUKIiISLwSFQruJTmRUUREeilRoQC68JpIJUlSn2W5i+q9TFwoQPpExhkz4i6FiBSjrq6O9vZ2BUMJuDvt7e3U1dWFvq9EDUnN1N4OZlBXB9ddp5m0RcpNfX09bW1tvPvuu3EXpSLU1dVRX18f+n4SNSTVrMmhNENShwyByy9XmIhIZSv1kNSKDQURkerQhHuLlerVEtmnICIi8VAoiIhIp4Q1H+3q0BB3MUREykgr7qtL1nyUsNFH7UvcV5esw6ScmVlLKTuPypXeh230Xmyj92IbMytpR6yaj0REpJNCQUREOiUtFK6NuwAJovciTe/DNnovttF7sU1J34tEdTSLiEi8klZTEBGRGCUiFMzsy2b2opm9bGbnxV2esJnZZ8zsETN7zsxWmNmMYPkuZvaAmb0U/LtzsNzMbE7w/iwzsy/EewSlZ2Y1ZvZXM7s3eLyXmS0Ojvk2M+sfLK8NHr8crG+IteAlZmY7mdntZvaCmT1vZgdX6+fCzL4X/P9Ybma3mlldtXwuzOx6M3vHzJZnLCv4c2BmU4PtXzKzqfnsO/ZQMLMa4L+AfwJGAieZ2ch4SxW6LcD33X0kcBDw3eCYzwMecve9gYeCx5B+b/YObmcAc6MvcuhmAM9nPP4FcKm7fw74O3BasPw04O/B8kuD7SrJ5cCf3P1/AGNIvydV97kws2HAdKDJ3UcBNcCJVM/nYh7w5S7LCvocmNkuwE+BccCBwE87giQrd4/1BhwM3J/x+Hzg/LjLFfF7cA9wFPAisHuwbHfgxeD+NcBJGdt3blcJN6A++JAfCdwLGLAa6Nv1MwLcDxwc3O8bbGdxH0OJ3ofBwN+6Hk81fi6AYcAqYJfg73wvcHQ1fS5In8m7vLefA+Ak4JqM5Z/Yrqdb7DUFtv3xO7QFy6pCUM0dCywGPu3ubwar3gI+Hdyv9PfoMuBc4OPg8RBgjbtvCR5nHm/nexGsXxtsXwn2At4Fbgia0q4zs4FU4efC3V8H/hN4DXiT9N95CdX5uehQ6OegV5+PJIRC1TKzHYE7gLPd/f3MdZ6O9oofGmZmxwLvuPuSuMuSAH2BLwBz3X0ssJ5tTQRAVX0udgaOJx2UewAD2b45pWqF+TlIQii8Dnwm43F9sKyimVk/0oGQcvc7g8Vvm9nuwfrdgXeC5ZX8Hh0CfMXMWoHfkG5CuhzYycw6pmHJPN7O9yJYPxhoj7LAIWoD2tx9cfD4dtIhUY2fi4nA39z9XXffDNxJ+rNSjZ+LDoV+Dnr1+UhCKPw/YO9gVEF/0p1Jv4+5TKEyMwN+DTzv7pdkrPo90DFCYCrpvoaO5d8ORhkcBKzNqEaWNXc/393r3b2B9N/+YXefDDwCfC3YrOt70fEefS3YviJ+Obv7W8AqM9s3WDQBeI4q/FyQbjY6yMwGBP9fOt6LqvtcZCj0c3A/8I9mtnNQ8/rHYFl2cXemBH+3ScB/A68As+IuTwTH+0XSVb9lwNLgNol0G+hDwEvAg8AuwfZGeoTWK8CzpEdkxH4cIbwvhwP3BvdHAE8BLwO/A2qD5XXB45eD9SPiLneJ34NG0leaWgbcDexcrZ8L4GfAC8By4Gagtlo+F8CtpPtSNpOuQZ7Wm88BcGrwnrwMfCeffeuMZhER6ZSE5iMREUkIhYKIiHRSKIiISCeFgoiIdFIoiIhIJ4WCVBUz22pmSzNuJZuV18waMme1FClHfXNvIlJRPnT3xrgLIZJUqimIAGbWamb/28yeNbOnzOxzwfIGM3s4mKf+ITPbM1j+aTO7y8yeCW7jg5eqMbNfBdcB+LOZ7RDbQYn0gkJBqs0OXZqPvpmxbq277w9cSXrmVoArgBvdfTSQAuYEy+cAf3H3MaTnJ1oRLN8b+C933w9YA/xLqEcjUmI6o1mqipl94O47drO8FTjS3V8NJit8y92HmNlq0nPYbw6Wv+nuu5rZu0C9u2/KeI0G4AFPXwQFM/sh0M/dL47g0ERKQjUFkW28h/uF2JRxfyvqt5Myo1AQ2eabGf8+Edx/nPTsrQCTgUXB/YeAZui8vvTgqAopEib9ipFqs4OZLc14/Cd37xiWurOZLSP9a/+kYNlZpK+ENpP0VdG+EyyfAVxrZqeRrhE0k57VUqSsqU9BhM4+hSZ3Xx13WUTipOYjERHppJqCiIh0Uk1BREQ6KRRERKSTQkFERDopFEREpJNCQUREOikURESk0/8HtsNjPB8FzzUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 138.5 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1450])\n",
      "1450 vs 1450\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 84.074 %\n",
      "- Recall : 80.639 %\n",
      "- F1 : 0.82321\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 88.022 %\n",
      "- Recall : 90.304 %\n",
      "- F1 : 0.89149\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.552 %\n",
      "- Precision : 86.048 %\n",
      "- Recall : 85.472 %\n",
      "- F1 : 0.85759\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_BERT_Finetuned Validation, 86.552, 86.048, 85.472, 0.85759, 84.074, 80.639, 0.82321, 88.022, 90.304, 0.89149, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([648])\n",
      "648 vs 648\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 83.857 %\n",
      "- Recall : 77.593 %\n",
      "- F1 : 0.80603\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 87.294 %\n",
      "- Recall : 91.155 %\n",
      "- F1 : 0.89183\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.111 %\n",
      "- Precision : 85.575 %\n",
      "- Recall : 84.374 %\n",
      "- F1 : 0.8497\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_BERT_Finetuned Test, 86.111, 85.575, 84.374, 0.8497, 83.857, 77.593, 0.80603, 87.294, 91.155, 0.89183, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
