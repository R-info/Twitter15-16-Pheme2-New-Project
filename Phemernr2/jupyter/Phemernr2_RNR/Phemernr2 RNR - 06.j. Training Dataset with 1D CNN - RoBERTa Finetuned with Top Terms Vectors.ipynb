{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'rumours']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 people have', 'Chocolate Cafe in', 'release the name', 'die as martyrs', 'as heavily armed', 'explosions heard at', 'Andreas Lubitz', 'Cpl Nathan Cirillo', 'at Massey Hall', 'gunmen were involved']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519, 1)\n",
      "(1456, 1519, 1)\n",
      "(630, 1519, 1)\n",
      "(4339, 1)\n",
      "(1456, 1)\n",
      "(630, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 85.852\n",
      "Saving after new best accuracy : 86.401\n",
      "-- Epoch 50, Train Loss : 1.6738231778144836, Test Loss : 0.4068821966648102\n",
      "-- Epoch 100, Train Loss : 1.4288496151566505, Test Loss : 0.3836439549922943\n",
      "Saving after new best accuracy : 86.47\n",
      "Saving after new best accuracy : 86.538\n",
      "Saving after new best accuracy : 86.676\n",
      "Saving after new best accuracy : 86.745\n",
      "Saving after new best accuracy : 86.813\n",
      "Saving after new best accuracy : 86.882\n",
      "Saving after new best accuracy : 87.019\n",
      "Saving after new best accuracy : 87.088\n",
      "Saving after new best accuracy : 87.157\n",
      "-- Epoch 150, Train Loss : 1.2883525639772415, Test Loss : 0.3962157666683197\n",
      "-- Epoch 200, Train Loss : 1.2286898717284203, Test Loss : 0.409005731344223\n",
      "-- Epoch 250, Train Loss : 1.2168442830443382, Test Loss : 0.4229825437068939\n",
      "-- Epoch 300, Train Loss : 1.1959557309746742, Test Loss : 0.4392302632331848\n",
      "-- Epoch 350, Train Loss : 1.1861369535326958, Test Loss : 0.4430299699306488\n",
      "-- Epoch 400, Train Loss : 1.1796501874923706, Test Loss : 0.4468797743320465\n",
      "-- Epoch 450, Train Loss : 1.174623742699623, Test Loss : 0.4567054212093353\n",
      "-- Epoch 500, Train Loss : 1.16957625746727, Test Loss : 0.45781949162483215\n",
      "-- Epoch 550, Train Loss : 1.1742305681109428, Test Loss : 0.4635040760040283\n",
      "-- Epoch 600, Train Loss : 1.1611195728182793, Test Loss : 0.46777185797691345\n",
      "-- Epoch 650, Train Loss : 1.1602853387594223, Test Loss : 0.4749529957771301\n",
      "-- Epoch 700, Train Loss : 1.1539220958948135, Test Loss : 0.4741787016391754\n",
      "-- Epoch 750, Train Loss : 1.155241683125496, Test Loss : 0.4876716732978821\n",
      "-- Epoch 800, Train Loss : 1.150863729417324, Test Loss : 0.48276612162590027\n",
      "-- Epoch 850, Train Loss : 1.143979474902153, Test Loss : 0.4883618652820587\n",
      "-- Epoch 900, Train Loss : 1.141875445842743, Test Loss : 0.4896749258041382\n",
      "-- Epoch 950, Train Loss : 1.1385424360632896, Test Loss : 0.5538629293441772\n",
      "-- Epoch 1000, Train Loss : 1.1374627500772476, Test Loss : 0.5483138561248779\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 79.48 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 441\n",
      "False Positive : 76\n",
      "False Negative : 111\n",
      "True Negative : 828\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 85.3 %\n",
      "- Recall : 79.891 %\n",
      "- F1 : 0.82507\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 88.179 %\n",
      "- Recall : 91.593 %\n",
      "- F1 : 0.89853\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.157 %\n",
      "- Precision : 86.739 %\n",
      "- Recall : 85.742 %\n",
      "- F1 : 0.86238\n",
      "- Average Confidence : 81.2 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 87.157, 86.739, 85.742, 0.86238, 85.3, 79.891, 0.82507, 88.179, 91.593, 0.89853, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 187\n",
      "False Positive : 28\n",
      "False Negative : 44\n",
      "True Negative : 371\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 86.977 %\n",
      "- Recall : 80.952 %\n",
      "- F1 : 0.83857\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.398 %\n",
      "- Recall : 92.982 %\n",
      "- F1 : 0.91155\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.571 %\n",
      "- Precision : 88.187 %\n",
      "- Recall : 86.967 %\n",
      "- F1 : 0.87573\n",
      "- Average Confidence : 82.22 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 88.571, 88.187, 86.967, 0.87573, 86.977, 80.952, 0.83857, 89.398, 92.982, 0.91155, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56e75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
