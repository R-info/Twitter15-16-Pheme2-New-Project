{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'rumours']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 people have', 'Chocolate Cafe in', 'release the name', 'die as martyrs', 'as heavily armed', 'explosions heard at', 'Andreas Lubitz', 'Cpl Nathan Cirillo', 'at Massey Hall', 'gunmen were involved']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519)\n",
      "(1456, 1519)\n",
      "(630, 1519)\n",
      "(4339, 1)\n",
      "(1456, 1)\n",
      "(630, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 86.332\n",
      "Saving after new best accuracy : 86.401\n",
      "-- Epoch 50, Train Loss : 1.6425029039382935, Test Loss : 0.39841228723526\n",
      "Saving after new best accuracy : 86.47\n",
      "-- Epoch 100, Train Loss : 1.390110269188881, Test Loss : 0.3893177807331085\n",
      "Saving after new best accuracy : 86.538\n",
      "Saving after new best accuracy : 86.676\n",
      "Saving after new best accuracy : 86.745\n",
      "Saving after new best accuracy : 86.813\n",
      "Saving after new best accuracy : 86.882\n",
      "Saving after new best accuracy : 86.951\n",
      "Saving after new best accuracy : 87.019\n",
      "Saving after new best accuracy : 87.088\n",
      "-- Epoch 150, Train Loss : 1.2548296079039574, Test Loss : 0.39726749062538147\n",
      "-- Epoch 200, Train Loss : 1.219995841383934, Test Loss : 0.4116547107696533\n",
      "-- Epoch 250, Train Loss : 1.209449902176857, Test Loss : 0.42539510130882263\n",
      "Saving after new best accuracy : 87.157\n",
      "-- Epoch 300, Train Loss : 1.1936508938670158, Test Loss : 0.43670856952667236\n",
      "-- Epoch 350, Train Loss : 1.1864968836307526, Test Loss : 0.4447299540042877\n",
      "-- Epoch 400, Train Loss : 1.180193804204464, Test Loss : 0.450459748506546\n",
      "-- Epoch 450, Train Loss : 1.1754196137189865, Test Loss : 0.4548584818840027\n",
      "-- Epoch 500, Train Loss : 1.1690463721752167, Test Loss : 0.4565713703632355\n",
      "-- Epoch 550, Train Loss : 1.1643533632159233, Test Loss : 0.4605070650577545\n",
      "-- Epoch 600, Train Loss : 1.161301575601101, Test Loss : 0.46663975715637207\n",
      "-- Epoch 650, Train Loss : 1.1574301570653915, Test Loss : 0.4730830192565918\n",
      "-- Epoch 700, Train Loss : 1.1533216536045074, Test Loss : 0.4767005145549774\n",
      "-- Epoch 750, Train Loss : 1.1537223011255264, Test Loss : 0.4809397757053375\n",
      "-- Epoch 800, Train Loss : 1.1461660265922546, Test Loss : 0.48776426911354065\n",
      "-- Epoch 850, Train Loss : 1.1487873792648315, Test Loss : 0.48502659797668457\n",
      "-- Epoch 900, Train Loss : 1.1456121057271957, Test Loss : 0.4910881817340851\n",
      "-- Epoch 950, Train Loss : 1.1362981125712395, Test Loss : 0.4960037171840668\n",
      "-- Epoch 1000, Train Loss : 1.1368546411395073, Test Loss : 0.49714401364326477\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 70.25 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 438\n",
      "False Positive : 73\n",
      "False Negative : 114\n",
      "True Negative : 831\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 85.714 %\n",
      "- Recall : 79.348 %\n",
      "- F1 : 0.82408\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 87.937 %\n",
      "- Recall : 91.925 %\n",
      "- F1 : 0.89886\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.157 %\n",
      "- Precision : 86.825 %\n",
      "- Recall : 85.636 %\n",
      "- F1 : 0.86226\n",
      "- Average Confidence : 88.59 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Validation, 87.157, 86.825, 85.636, 0.86226, 85.714, 79.348, 0.82408, 87.937, 91.925, 0.89886, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 186\n",
      "False Positive : 29\n",
      "False Negative : 45\n",
      "True Negative : 370\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 86.512 %\n",
      "- Recall : 80.519 %\n",
      "- F1 : 0.83408\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 89.157 %\n",
      "- Recall : 92.732 %\n",
      "- F1 : 0.90909\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.254 %\n",
      "- Precision : 87.834 %\n",
      "- Recall : 86.626 %\n",
      "- F1 : 0.87226\n",
      "- Average Confidence : 89.5 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_RoBERTa_Finetuned_with_TopTermsVectors Test, 88.254, 87.834, 86.626, 0.87226, 86.512, 80.519, 0.83408, 89.157, 92.732, 0.90909, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
