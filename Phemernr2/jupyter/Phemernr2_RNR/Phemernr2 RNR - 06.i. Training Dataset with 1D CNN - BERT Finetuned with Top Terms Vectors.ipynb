{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2      tvt2_1      tvt2_2    tvt2_3  \n",
       "0        2      test  validation    training  validation  training  \n",
       "1        3  training    training  validation    training  training  \n",
       "2        2      test    training  validation  validation  training  \n",
       "3        2      test    training    training    training  training  \n",
       "4        3  training    training  validation    training  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-rumours', 'rumours']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 people have', 'Chocolate Cafe in', 'release the name', 'die as martyrs', 'as heavily armed', 'explosions heard at', 'Andreas Lubitz', 'Cpl Nathan Cirillo', 'at Massey Hall', 'gunmen were involved']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "        \n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 1519, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors = vectors.reshape(vectors.shape[0], vectors.shape[1], 1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4339, 1519, 1)\n",
      "(1456, 1519, 1)\n",
      "(630, 1519, 1)\n",
      "(4339, 1)\n",
      "(1456, 1)\n",
      "(630, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(n_input, 512, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 128, 1, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=1, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 86.607\n",
      "Saving after new best accuracy : 86.676\n",
      "Saving after new best accuracy : 86.745\n",
      "-- Epoch 50, Train Loss : 0.13223862717859447, Test Loss : 0.9358474016189575\n",
      "Saving after new best accuracy : 86.813\n",
      "Saving after new best accuracy : 86.882\n",
      "-- Epoch 100, Train Loss : 0.12430575187318027, Test Loss : 1.1233471632003784\n",
      "-- Epoch 150, Train Loss : 0.11017070733942091, Test Loss : 4.038025379180908\n",
      "-- Epoch 200, Train Loss : 0.10334689519368112, Test Loss : 4.897950172424316\n",
      "-- Epoch 250, Train Loss : 0.09871919988654554, Test Loss : 5.211943626403809\n",
      "-- Epoch 300, Train Loss : 0.09517524298280478, Test Loss : 5.278070449829102\n",
      "-- Epoch 350, Train Loss : 0.0924965578597039, Test Loss : 5.355216979980469\n",
      "-- Epoch 400, Train Loss : 0.09046887210570276, Test Loss : 5.426380157470703\n",
      "-- Epoch 450, Train Loss : 0.08881783648394048, Test Loss : 5.550341606140137\n",
      "-- Epoch 500, Train Loss : 0.08724823663942516, Test Loss : 5.736112117767334\n",
      "-- Epoch 550, Train Loss : 0.08594404393807054, Test Loss : 5.803566932678223\n",
      "-- Epoch 600, Train Loss : 0.08472178084775805, Test Loss : 5.9341888427734375\n",
      "-- Epoch 650, Train Loss : 0.0838341258931905, Test Loss : 5.998615741729736\n",
      "-- Epoch 700, Train Loss : 0.08308707759715617, Test Loss : 6.003833293914795\n",
      "-- Epoch 750, Train Loss : 0.08238564757630229, Test Loss : 6.068665981292725\n",
      "-- Epoch 800, Train Loss : 0.0816292124800384, Test Loss : 6.073599338531494\n",
      "-- Epoch 850, Train Loss : 0.08114606235176325, Test Loss : 6.080718994140625\n",
      "-- Epoch 900, Train Loss : 0.08035919186659157, Test Loss : 6.146328926086426\n",
      "-- Epoch 950, Train Loss : 0.08005747268907726, Test Loss : 6.154369354248047\n",
      "Saving after new best accuracy : 86.951\n",
      "-- Epoch 1000, Train Loss : 0.08036512555554509, Test Loss : 6.163508415222168\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 79.21 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1456, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 466\n",
      "False Positive : 104\n",
      "False Negative : 86\n",
      "True Negative : 800\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 81.754 %\n",
      "- Recall : 84.42 %\n",
      "- F1 : 0.83066\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 90.293 %\n",
      "- Recall : 88.496 %\n",
      "- F1 : 0.89385\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.951 %\n",
      "- Precision : 86.024 %\n",
      "- Recall : 86.458 %\n",
      "- F1 : 0.8624\n",
      "- Average Confidence : 98.69 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_BERT_Finetuned_with_TopTermsVectors Validation, 86.951, 86.024, 86.458, 0.8624, 81.754, 84.42, 0.83066, 90.293, 88.496, 0.89385, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([630, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 198\n",
      "False Positive : 31\n",
      "False Negative : 33\n",
      "True Negative : 368\n",
      "\n",
      "Class rumours Evaluation\n",
      "- Precision : 86.463 %\n",
      "- Recall : 85.714 %\n",
      "- F1 : 0.86087\n",
      "\n",
      "Class non-rumours Evaluation\n",
      "- Precision : 91.771 %\n",
      "- Recall : 92.231 %\n",
      "- F1 : 0.92\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 89.841 %\n",
      "- Precision : 89.117 %\n",
      "- Recall : 88.972 %\n",
      "- F1 : 0.89044\n",
      "- Average Confidence : 98.58 %\n",
      "Model, Combined,,,,rumours,,,non-rumours,,,\n",
      "Phemernr2-RNR_4LayerNet_BERT_Finetuned_with_TopTermsVectors Test, 89.841, 89.117, 88.972, 0.89044, 86.463, 85.714, 0.86087, 91.771, 92.231, 0.92, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56e75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
