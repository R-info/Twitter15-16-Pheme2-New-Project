{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-RNR\"\n",
    "unique_name = \"DistilBERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-RNR_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tt</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552833795142209536</td>\n",
       "      <td>The East London Mosque would like to offer its...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>rumours</td>\n",
       "      <td>true</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576790814942236672</td>\n",
       "      <td>After #Putin disappeared Russian TV no longer ...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>putinmissing-all-rnr-threads</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499678822598340608</td>\n",
       "      <td>Saw #Ferguson for myself. #justiceformichaelbr...</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>non-rumours</td>\n",
       "      <td>ferguson-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  552833795142209536  The East London Mosque would like to offer its...   \n",
       "1  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "2  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "3  576790814942236672  After #Putin disappeared Russian TV no longer ...   \n",
       "4  499678822598340608  Saw #Ferguson for myself. #justiceformichaelbr...   \n",
       "\n",
       "         label       label2                              topic       tvt  \\\n",
       "0  non-rumours  non-rumours       charliehebdo-all-rnr-threads      test   \n",
       "1      rumours         true  germanwings-crash-all-rnr-threads  training   \n",
       "2      rumours         true       charliehebdo-all-rnr-threads      test   \n",
       "3  non-rumours  non-rumours       putinmissing-all-rnr-threads      test   \n",
       "4  non-rumours  non-rumours           ferguson-all-rnr-threads  training   \n",
       "\n",
       "   cv_fold        tt        tvt2  \n",
       "0        2      test    testting  \n",
       "1        3  training    training  \n",
       "2        2      test  validation  \n",
       "3        2      test    training  \n",
       "4        3  training  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4327, 768)\n",
      "(1450, 768)\n",
      "(648, 768)\n",
      "(4327,)\n",
      "(1450,)\n",
      "(648,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 87.241\n",
      "Saving after new best accuracy : 87.31\n",
      "Saving after new best accuracy : 87.379\n",
      "-- Epoch 50, Train Loss : 0.005570345811747757, Test Loss : 1.866409420967102\n",
      "-- Epoch 100, Train Loss : 0.0001956147185868673, Test Loss : 3.0905861854553223\n",
      "-- Epoch 150, Train Loss : 4.9798756152519275e-05, Test Loss : 3.7001383304595947\n",
      "-- Epoch 200, Train Loss : 2.0946100750318664e-05, Test Loss : 4.085099220275879\n",
      "-- Epoch 250, Train Loss : 1.0822034109070344e-05, Test Loss : 4.374940872192383\n",
      "-- Epoch 300, Train Loss : 6.275021054658048e-06, Test Loss : 4.613044738769531\n",
      "-- Epoch 350, Train Loss : 3.91767150541289e-06, Test Loss : 4.8185038566589355\n",
      "-- Epoch 400, Train Loss : 2.5759963015875575e-06, Test Loss : 5.001920223236084\n",
      "-- Epoch 450, Train Loss : 1.7456379373115283e-06, Test Loss : 5.170337200164795\n",
      "-- Epoch 500, Train Loss : 1.214616322187112e-06, Test Loss : 5.327396392822266\n",
      "-- Epoch 550, Train Loss : 8.62606719942427e-07, Test Loss : 5.475619316101074\n",
      "-- Epoch 600, Train Loss : 6.197792740136876e-07, Test Loss : 5.617247581481934\n",
      "-- Epoch 650, Train Loss : 4.5214863803044736e-07, Test Loss : 5.753411293029785\n",
      "-- Epoch 700, Train Loss : 3.3271041176285987e-07, Test Loss : 5.885199546813965\n",
      "-- Epoch 750, Train Loss : 2.46797975597679e-07, Test Loss : 6.013106822967529\n",
      "-- Epoch 800, Train Loss : 1.8463329963525066e-07, Test Loss : 6.137640953063965\n",
      "-- Epoch 850, Train Loss : 1.383006180133428e-07, Test Loss : 6.259303569793701\n",
      "-- Epoch 900, Train Loss : 1.0454050997088515e-07, Test Loss : 6.378350734710693\n",
      "-- Epoch 950, Train Loss : 7.986065048148916e-08, Test Loss : 6.4950432777404785\n",
      "-- Epoch 1000, Train Loss : 6.076864787762926e-08, Test Loss : 6.609371185302734\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 138.44 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1450])\n",
      "1450 vs 1450\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 84.799 %\n",
      "- Recall : 82.238 %\n",
      "- F1 : 0.83499\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 88.938 %\n",
      "- Recall : 90.643 %\n",
      "- F1 : 0.89782\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.379 %\n",
      "- Precision : 86.868 %\n",
      "- Recall : 86.44 %\n",
      "- F1 : 0.86653\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_DistilBERT_Finetuned Validation, 87.379, 86.868, 86.44, 0.86653, 84.799, 82.238, 0.83499, 88.938, 90.643, 0.89782, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([648])\n",
      "648 vs 648\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 81.448 %\n",
      "- Recall : 74.689 %\n",
      "- F1 : 0.77922\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 85.714 %\n",
      "- Recall : 89.926 %\n",
      "- F1 : 0.8777\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.259 %\n",
      "- Precision : 83.581 %\n",
      "- Recall : 82.308 %\n",
      "- F1 : 0.8294\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr2-RNR_4LayerNet_DistilBERT_Finetuned Test, 84.259, 83.581, 82.308, 0.8294, 81.448, 74.689, 0.77922, 85.714, 89.926, 0.8777, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
