{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-TF\"\n",
    "unique_name = \"DistilBERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1705, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-TF_DistilBERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>True</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>True</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580352540316946432</td>\n",
       "      <td>'No survivors' in #Germanwings crash says Fren...</td>\n",
       "      <td>False</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524983403775799297</td>\n",
       "      <td>Tragedy mounts as soldier shot this AM dies of...</td>\n",
       "      <td>True</td>\n",
       "      <td>ottawashooting-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544511915158810624</td>\n",
       "      <td>Watch the moment gunfire and explosions were h...</td>\n",
       "      <td>True</td>\n",
       "      <td>sydneysiege-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "1  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "2  580352540316946432  'No survivors' in #Germanwings crash says Fren...   \n",
       "3  524983403775799297  Tragedy mounts as soldier shot this AM dies of...   \n",
       "4  544511915158810624  Watch the moment gunfire and explosions were h...   \n",
       "\n",
       "   label                              topic      tvt2    tvt2_1      tvt2_2  \\\n",
       "0   True  germanwings-crash-all-rnr-threads  training  training    training   \n",
       "1   True       charliehebdo-all-rnr-threads  training  training    training   \n",
       "2  False  germanwings-crash-all-rnr-threads  training  training    training   \n",
       "3   True     ottawashooting-all-rnr-threads  training  training  validation   \n",
       "4   True        sydneysiege-all-rnr-threads  training  training    training   \n",
       "\n",
       "     tvt2_3  \n",
       "0  training  \n",
       "1  training  \n",
       "2  testting  \n",
       "3  training  \n",
       "4  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Massey Hall', 'in the window', 'Ottawa Police', 'by @LucilleClerc', 'CEO says', 'in Toronto', '#Prince #Toronto', 'shooting incident', '#cbcOTT #OTTnews', 'Banksy #JeSuisCharlie']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2-tf_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1705, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 1519)\n",
      "(384, 1519)\n",
      "(166, 1519)\n",
      "(1155, 1)\n",
      "(384, 1)\n",
      "(166, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 89.062\n",
      "Saving after new best accuracy : 89.323\n",
      "-- Epoch 50, Train Loss : 0.0015406951133627445, Test Loss : 0.6049544215202332\n",
      "-- Epoch 100, Train Loss : 0.0002638340993144084, Test Loss : 0.7460602521896362\n",
      "-- Epoch 150, Train Loss : 0.00010295165157003794, Test Loss : 0.8246824145317078\n",
      "-- Epoch 200, Train Loss : 5.3756788474856876e-05, Test Loss : 0.880184531211853\n",
      "-- Epoch 250, Train Loss : 3.266231897214311e-05, Test Loss : 0.9230644106864929\n",
      "-- Epoch 300, Train Loss : 2.175813324356568e-05, Test Loss : 0.9587178230285645\n",
      "-- Epoch 350, Train Loss : 1.5418911971210036e-05, Test Loss : 0.9887173175811768\n",
      "-- Epoch 400, Train Loss : 1.1415034805395408e-05, Test Loss : 1.0154833793640137\n",
      "-- Epoch 450, Train Loss : 8.73312262683612e-06, Test Loss : 1.0394679307937622\n",
      "-- Epoch 500, Train Loss : 6.855306423858565e-06, Test Loss : 1.0598325729370117\n",
      "-- Epoch 550, Train Loss : 5.481171569954313e-06, Test Loss : 1.0797536373138428\n",
      "-- Epoch 600, Train Loss : 4.449084258340008e-06, Test Loss : 1.0995168685913086\n",
      "-- Epoch 650, Train Loss : 3.666007557967532e-06, Test Loss : 1.115389108657837\n",
      "-- Epoch 700, Train Loss : 3.0487670414913737e-06, Test Loss : 1.132034182548523\n",
      "-- Epoch 750, Train Loss : 2.5625629973546893e-06, Test Loss : 1.1461730003356934\n",
      "-- Epoch 800, Train Loss : 2.173786867842864e-06, Test Loss : 1.1595325469970703\n",
      "-- Epoch 850, Train Loss : 1.8586221131045022e-06, Test Loss : 1.3913202285766602\n",
      "-- Epoch 900, Train Loss : 1.594780030700349e-06, Test Loss : 1.4036163091659546\n",
      "-- Epoch 950, Train Loss : 1.3788070418740972e-06, Test Loss : 1.6344738006591797\n",
      "-- Epoch 1000, Train Loss : 1.1927126308819425e-06, Test Loss : 1.6458470821380615\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAFXCAYAAABqe9OEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr8ElEQVR4nO3de7xVdZ3/8debA3IEyQteUhDQsiZERD0/ScvxApXZxXK6aJA46fAQKrRmNM0mGydmambS0vJCDVJ5vJR5Ky1vadJ4CxwvYDoSoRwyL6gIAsrl8/tjrYPb47nsc87ae+299vv5eOzH2ev+3YvN+ZzP97PWdykiMDMzy8KAvBtgZmbF4aBiZmaZcVAxM7PMOKiYmVlmHFTMzCwzDipmZpYZBxWzCpF0iKTHq3i8f5d0arWO18nxvyHpsm6W3y9p72q2yarPQcUqQtIySZPzbkc1SQpJb2+fjoj5EfHOKh17J+B44JJqHK+P/gs4J+9GWGU5qJj1kqSBebehEycAN0XEurwb0o0bgMMlvTXvhljlOKhYVUkaLOm7kv6Svr4raXC6bEdJv5L0kqQXJM2XNCBd9hVJKyStlvS4pEld7H9bST+R9JykJyV9TdKA9LgvSRpXsu5OktZJ2jmd/rCkB9P17pY0vmTdZWkbHgZe6RhYJN2Vvn1I0hpJn5Z0mKS2Dvs4TdLDkl6R9N+SdpH06/Rz3SZp+5L135224yVJD0k6rJtT+0Hgdx3a1NPnOVPSo5JelHSppOaS5f8gaUn673CDpN1Klu0t6dZ02TOSvlpy2K3S879a0mJJLe0LImI9sBD4QDefw+pdRPjlV+YvYBkwuZP55wD3AjsDOwF3A/+aLvt34GJgUPo6BBDwTmA5sFu63hjgbV0c9yfA9cCwdL3/A05Ml80FZpes+3ngN+n7/YBngYlAEzAt/QyDSz7Pg8DuwNZdHDuAt5dMHwa0dTgn9wK7ACPS4z2QHrsZ+C1wdrruCGAlcBTJH3/vS6d36uLYzwH/r2S6nM+zKP08OwD/A3wzXXYE8DywPzAYuAC4K102DHga+Me0zcOAiemybwDr0zY3pf+e93Zo5/nAuXl/P/2q3MuZilXbFOCciHg2Ip4D/gX4bLpsA7ArMDoiNkRSkwhgE8kvt7GSBkXEsoj4U8cdS2oCjgXOjIjVEbEM+E7J/i9Pl7f7TDoPYDpwSUTcFxGbIuLHwKvAu0vWPz8ilkf/upguiIhnImIFMB+4LyL+N5K/4q8lCQYAU0m6s26KiM0RcSuwgOQXdme2A1aXTJfzeb6ffp4XgNnAcen8KcDciHggIl4FzgQOkjQG+DDw14j4TkSsT8/zfSX7/H3a5k3AT4F9O7RzddpWKygHFau23YAnS6afTOcB/CewBLhF0lJJZwBExBLgVJK/hJ+VdGVpd0yJHUkynI77H5G+vwMYImli+gtyAskvcoDRwD+mXUUvSXqJ5K/40uMs7+2H7cQzJe/XdTK9TUl7PtmhPe8lCbqdeZEka2jX289T+u/whn+jiFhDkiWNSPfxpoBe4q8l79cCzR26CocBL3WzvdU5BxWrtr+Q/MJrNyqdR/pX7z9GxJ7AR4Evt9dOIuLyiHhvum0A3+5k38+TZDsd978i3ccm4Gckf5EfB/wqItr/ul9O0jW2XclrSERcUbKvag7pvRz4aYf2DI2Ib3Wx/sPAOzps39Pn2b3k/ZZ/Bzr8G0kaCgwnOY/LgT378bneBTzUj+2txjmoWCUNktRc8hoIXAF8LS2S7wh8HbgMthSW3y5JwCqSbq/Nkt4p6Yi0oL+e5C/6zR0PVhI0ZksaJmk08OX2/acuBz5N0sVzecn8HwInp1mMJA2V9CFJpX/99+QZ+vcLt9RlwEckfUBSU3r+DpM0sov1bwIOLZku5/N8XtJISTsAZwFXpfOvAP5e0oT0nP8bSTfdMuBXwK6STk0vfhgmaWI5Hyi9EOAA4NYyz4HVIQcVq6SbSAJA++sbwDdJagMPA4+QFKq/ma6/F3AbsAa4B7gwIu4gqad8iyQT+StJkf/MLo75ReAVYCnwe5LAMbd9Ydr//wpJF8+vS+YvAP4B+D5JV9ISkst0e+MbwI/T7qZP9XLbN4iI5cDRwFdJivDLgdPo+v/sT4CjJG2dbl/O57kcuIXkXP2J9N8hIm4D/hn4BUlR/m2ktag0s3sf8BGSf4sngMPL/FgfAe6MiL/0uKbVLSV1UDOrd5L+DXg2Ir5bxrrLgJPSAFIVku4juRJvUbWOadVXizdxmVkfRMRXe14rPxFRVjeZ1Td3f5mZWWbc/WVmZplxpmJmZplxUDEzs8wUqlAv7RjJcE+JAw7Iry1mZvVg4cKFz0fETlntr1BBJQkoCwAYPRoWLMi1MWZmNU/Skz2vVb5Cdn8NGQKzZ+fdCjOzxlO4oDJ6NMyZA1Om5N0SM7PGU6jurz32gKVL826FmVnjKlymYmZm+XFQMTOzzDiomJlZZgoVVDzijJlZvgoVVMzMLF8OKmZmlplCBRV3f5mZ5atQQcXMzPLloGJmZpmp2B31kuYCHyZ5Zva4TpafBrQPpjIQeBewU0S8kD4/ezWwCdgYES2VaqeZmWWnkpnKPODIrhZGxH9GxISImACcCfwuIl4oWeXwdLkDiplZnahYUImIu4AXelwxcRxwRf+P2d89mJlZf+ReU5E0hCSj+UXJ7ABukbRQ0vQetp8uaYGkBWvWrKlkU83MrAe5BxXgI8D/dOj6em9E7A98EPi8pL/tauOImBMRLRHRss0221S6rWZm1o1aCCrH0qHrKyJWpD+fBa4FDsyhXWZm1ku5BhVJ2wKHAteXzBsqaVj7e+D9wKJ8WmhmZr1RyUuKrwAOA3aU1AacDQwCiIiL09U+DtwSEa+UbLoLcK2k9vZdHhG/KeeYLtSbmeVLUaDfxKNGtcRTTy3IuxlmZnVD0sIsb92ohZqKmZkVhIOKmZllplBBpUA9eWZmdalQQcXMzPLloGJmZplxUDEzs8w4qJiZWWYKFVRcqDcz68bkySC94XUAHJDlIQoVVMzMGlJrKwwe/KaA8abX7bdXvCkVG6bFzMwyMHMmXHRR3q0omzMVM7NaVWcBBQoWVFxTMbNCmTMn7xb0WqGCiplZoWzalHcLes1BxcysVjU15d2CXnNQMTOrVdOnV27fkyZBBAthYZa7dVAxM6tVF14IM2b0frsZM5Iic3ev227Lvr0U7JJiF+rNrHAuvDC5v2T//eGKK/JuTY+cqZiZ1bpNm+qmvuKgYmZW6zZvhgH18eu6PlppZtbInKnkwzUVMyukTZucqZiZWUY2b3amYmZmGXGmYmZmmXGmYmZmmXGhPh8u1JtZIbn7y8zMMuPuLzMzy4wzFTMzy4wzFZA0V9KzkhZ1sfwwSaskPZi+vl6y7EhJj0taIumMSrXRzKwuuFAPwDzgyB7WmR8RE9LXOQCSmoAfAB8ExgLHSRpbzgFdqDezQnL3F0TEXcALfdj0QGBJRCyNiNeAK4GjM22cmVm9aH/+iTOVshwk6SFJv5a0dzpvBLC8ZJ22dF6nJE2XtEDSgnXr1lWyrWZm1bd5c/Kz0TOVMjwAjI6IfYELgOv6spOImBMRLRHRsvXWW2fZPjOz/LUHFWcq3YuIlyNiTfr+JmCQpB2BFcDuJauOTOeVsc/Mm2lmlq9Nm5KfDirdk/RWSUrfH5i2ZSXwB2AvSXtI2go4Frghr3aameWqzrq/KvaMeklXAIcBO0pqA84GBgFExMXAJ4AZkjYC64BjIyKAjZK+ANwMNAFzI2JxpdppZlbT6ixTqVhQiYjjelj+feD7XSy7CbipEu0yM6sr7UGlTjKV+milmVmjcqE+Py7Um1nhOFMxM7PMOFMxM7PM1Fmh3kHFzKyWufsrP66pmFldaW2FwYNB6vo1alSy7j/8A2y9dbJNDavYJcVmZg1t5ky46KJs97l+PRx/fPJ+ypRs952RQmUqZmZVMXNm99mFlH1Aabd5M5x1VmX2nQFnKmZmpSqRYWTtqafybkGXHFTMrHG1tsLnPgevvZZ3S3qnvc5SgwoVVFyoN7OytbbC1Kl5t6L3BgyA2bPzbkWXXFMxs8ZUw3WJLjU3w09+UrNFeihYpmJmVrZarEvMmAEXXph3K/rFmYqZNaZq1iWam+Gyy15/3nxXrzoPKFCwoOKaipmVLau6RDkBY926mu6yypK7v8ysMbX/kp827fWhUDpqboYf/ahhAkIWHFTMrHFNmZLcTHj88bBkCbztbXm3qO4VqvvrxRdhzJiaHxrHzGpJnY0CXOsKFVQAnnwSpk93YDGzMtXZKMC1rpBnce3a+rwE3cxyUGcPwap1hQwqUJuXoJtZDXKmkqnCnsUaHhrHzGqJM5VMFTKoDBlS00PjmFktcaE+U4ULKqNHw5w5vqzczMrUnqm4+ysThbpPZdttYdmyvFthZnXFmUqmHJrNrLG5UJ8pn0Uza2wu1GeqUEHFA0qaWa85U8mUz6KZNTZnKpmqWFCRNFfSs5IWdbF8iqSHJT0i6W5J+5YsW5bOf1DSgkq10czMhfpsVTJTmQcc2c3yPwOHRsQ+wL8CczosPzwiJkRES4XaZ2b2elCR8m1HQVTskuKIuEvSmG6W310yeS8wslJtMTPr0ubNzlIyVCs1lROBX5dMB3CLpIWSpne3oaTpkhZIWvDaa69VtJFmVkCbNrlIn6Hcb36UdDhJUHlvyez3RsQKSTsDt0p6LCLu6mz7iJhD2nX2lre0+PovM+sdZyqZyjU8SxoP/Ag4OiJWts+PiBXpz2eBa4ED82mhmRXepk0OKhnKLahIGgVcA3w2Iv6vZP5QScPa3wPvBzq9gszMrN/c/ZWpinV/SboCOAzYUVIbcDYwCCAiLga+DgwHLlRy1cXG9EqvXYBr03kDgcsj4jflHNM3P5pZr7n7K1OVvPrruB6WnwSc1Mn8pcC+b97CzKwCnKlkymfSzBqbM5VMOaiYWWNzoT5TDipm1tg2b3b3V4YKdSZdqDezXnOmkqlCBRUzsx61tsLgwclYXxJceiksX568nzkz79bVvdzvqDczy9TkyXD77X3b9qKLkp8XXphdexqMMxUzqy+TJ7+eZXT26mtAaTen44Dp1huFylRcUzErgP5kGlloHwrf+sSZiplV18yZlc00+stF+34pVKZiZjWgtRU+9zmo10dRTO/2aRvWA2cqZtZ3nWUdU6fWb0CZMcNF+n5ypmJm3cu7xlFpDiSZKlRQcaHerA/qvbuqO5MmwW235d2KhlKooGJmXShq4HDQqDkOKmZFU6TuKgeNuuNCvVk966xQXk8BpbkZLrss6bvu7OWAUncKlam4pmKFVc/ZhwvhDcWZilmt6DjQYb1lH11lHQ4oDaVQmYpZXajnorlrHNYDZypmlVSPNwfOmOEah/WZMxWzrNRTBuI6h1VIoYKKC/VWNTNnvv7sjVrm7iqrskIFFbOKqJcrr5qb4Uc/gilT8m6JNTAHFbNS9dCF5ezDapgL9da4ar2I3lXB3AHFapgzFWsctdqN5aK5FUihMhUX6m2LWhy+xDcHWgNwpmLFUItZiDMQa0AVzVQkzZX0rKRFXSyXpPMlLZH0sKT9S5ZNk/RE+ppWyXZanam1LMQZiNkWle7+mgcc2c3yDwJ7pa/pwEUAknYAzgYmAgcCZ0vavqIttdrVMYjkeX/IpElvDh7r1vkyXrNURYNKRNwFvNDNKkcDP4nEvcB2knYFPgDcGhEvRMSLwK10H5zS42XRastdx4EV8wwiHa/A8pVXZt3Ku6YyAlheMt2WzutqvhVRLdwb4hsHzTKRd1DpN0nTSbrOaGraL+fWWNnyLqz7BkKziiir+0vSUEkD0vfvkPRRSYMyOP4KYPeS6ZHpvK7mv0lEzImIlohoGTCgUFdIF0vHukg1A0pnhXQHFLOKKPe38F1As6QRwC3AZ0mK8P11A3B8ehXYu4FVEfE0cDPwfknbpwX696fzrJ5MnpxPXaRjMd2FdLOqKbf7SxGxVtKJwIUR8R+SHuxxI+kK4DBgR0ltJFd0DQKIiIuBm4CjgCXAWuDv02UvSPpX4A/prs6JiO4K/iTblflprDLyGLnXtRCzmlJ2UJF0EDAFODGd19TTRhFxXA/LA/h8F8vmAnPLbJ/lpdq1EQcRs5pWbvfXqcCZwLURsVjSnsAdFWuV1bbSbq1qBJTSy3rdlWVW08rKVCLid8DvANKC/fMRMauSDbMaU82MxMObmNWtcq/+ulzSWyQNBRYBj0o6rbJN6z3XVDJWrYykY2HdAcWsbpXb/TU2Il4GPgb8GtiD5AowK5pqBJKOl/j68l6zwig3qAxK70v5GHBDRGwAnBcURek9JJUKJKXZiOsiZoVVblC5BFgGDAXukjQaeLlSjbIqKB1fqxKXATsbMWtIij4WIiQNjIiNGbenXwYObImNGxfk3YzaVsmCu4c+Mas7khZGREtW+yu3UL+tpHMlLUhf3yHJWmqKC/VdqGT3Vmm3lgOKWcMrt/trLrAa+FT6ehm4tFKNsoy0F92z7t5yIDGzLpR7R/3bIuLvSqb/pZxhWiwHlRpG3l1bZlaGcjOVdZLe2z4h6T3Auso0yfqkvYtr6tTsAoozEjPrpXIzlZOBn0jaNp1+Eai558Y3ZE0l68K7x9Yys34od5iWh4B9Jb0lnX5Z0qnAwxVsm3Un62DioVHMLAO9eqpVRLyc3lkP8OUKtMe609oK22yT3VVcpd1bDihmloH+PCpRmbXCutfaCgMHJvWSV17p375Kb0p0ncTMMtafZ9Q3YgWjulpbYdo02LSp//vy1VtmVgXdBhVJq+k8eAjYuiIt6odCFer33hsefbT/+3GtxMyqqNvur4gYFhFv6eQ1LCL6k+VUzJgxyR/4dav9hsX+BJTSLi4HFDOrov7UVGrSk0/C9Ol1GFja7zPpTwG+vfDuUYDNLCeFCyoAa9fCWWfl3YoytbbCgAH9G0qlPZi4ZmJmOavJLqwsPPVU3i0oQ3/rJq6XmFmNKWSmAjBqVN4t6EZ7V1dfA8qMGa6XmFlNKmSmMmQIzJ6ddyu6MGIE/OUvfdvWmYmZ1bjCZSqjRsGcOTVYp25tTbKTvgSU9pqJA4qZ1bjCZSpPPAFbbZV3Kzroa+1k7FhYvDj79piZVUjhMpWaugGyPTvpbUBpakruM3FAMbM6U7hMZfPmvFuQ6usowq6bmFkdK1xQqYlMpS/dXe7qMrMCKFz3V+6ZyogRvQsokru6zKwwKpqpSDoS+B7QBPwoIr7VYfl5wOHp5BBg54jYLl22CXgkXfZURHy0nGPmGlS23x5eeqn89XfbDVasqFhzzMyqrWKZiqQm4AfAB4GxwHGSxpauExFfiogJETEBuAC4pmTxuvZl5QaUZJ/9b3uvtRfkexNQZsxwQDGzwqlkpnIgsCQilgJIuhI4Guiqb+g44Oz+HrTqmcrMmb0bt8vZiZkVWCVrKiOA5SXTbem8N5E0GtgD+G3J7GZJCyTdK+ljXR1E0vR0vQVQ5UyltwFl0iQHFDMrtFop1B8LXB0RpY84HB0RLcBngO9KeltnG0bEnIhoSdetXqbS24AyY4ZHETazwqtkUFkB7F4yPTKd15ljgStKZ0TEivTnUuBOYL9yDlqVTKU3AaX96i7fe2JmDaCSNZU/AHtJ2oMkmBxLknW8gaS/AbYH7imZtz2wNiJelbQj8B7gP8o5aMUzld4ElO22gxdfrGhzzMxqScWCSkRslPQF4GaSS4rnRsRiSecACyLihnTVY4ErI96QY7wLuETSZpJs6lsRUdbNHxUNKr0JKC7Im1kDUtTELejZkFpixYoF7LZbBXbe2gpTp5a3ru+ON7M6IWlhe006C7VSqM9MxTKVadPKW88BxcwaWOGCSkUSrxEjYNOmntdzQDGzBle4oJJ5prL33uU9WMsBxcyseEEl00xl8uTyBod0QDEzAwoYVDLLVFpby3seigOKmdkWhQsqmWUqJ5zQ8zq77eaAYmZWonBBJZNMZfJk2Lix+3Uk34diZtaBg0pH5XZ7/fSn/TyQmVnxFC6o9Lv7q5xurxkzYMqUfh7IzKx4ChdU+pWplNPtNWmSB4c0M+tC4YJKnzOVcrq9mpo8fL2ZWTcKF1T6nKmcdFLP6/z4x33cuZlZYyhcUOlTptLaCuvXd7/OpEmuo5iZ9aBwQaVPmUpPxXl3e5mZlcVBZebMnovz7vYyMytL4YJKr7u/enrolru9zMzKVrig0qtMZfLkntdxt5eZWdkKF1TKzlTKuYR4xox+t8fMrJEULqiUnamcfHL3y5uafJOjmVkvFS6olJWptLbCmjXdr+PivJlZrxUuqJSVqfSUpWy1lYvzZmZ9ULig0mOmUk6WMnduZu0xM2skikyfv5uvFil+v8tomr8zu+tMY8cdYeXKrncydGjPQcfMrCAkLYyIlqz2V7hMpfmZJ2H69CQj6Ux3AQXgkkuyb5SZWYMoXFABYO1aOOusN8+fObP77YYOdS3FzKwfihlUAJ566s3zLr64+22cpZiZ9Utxg8qoUW+cbm3tvorvLMXMrN+KGVSGDIHZs984r6fLiJ2lmJn1W+GCyrqdR8OcOW/MOnq6jNj3pZiZZaKiQUXSkZIel7RE0hmdLD9B0nOSHkxfJ5UsmybpifQ1rZzjPcUo7py37M0B4pRTut/Q96WYmWViYKV2LKkJ+AHwPqAN+IOkGyLi0Q6rXhURX+iw7Q7A2UALEMDCdNsXuz0m0fkd9T1dRuwsxcwsE5XMVA4ElkTE0oh4DbgSOLrMbT8A3BoRL6SB5FbgyJ42EvHmWnxX96u0Gz68zCaZmVlPKhlURgDLS6bb0nkd/Z2khyVdLWn3Xm6LpOmSFkha0Gmm0lPX1/e+1/1yMzMrW96F+l8CYyJiPEk20uuhgSNiTkS0RESLCD72MRgzpiRB6WlIFnd9mZllppJBZQWwe8n0yHTeFhGxMiJeTSd/BBxQ7radae/+ejIdqeX3M3vo+vJlxGZmmarYgJKSBgL/B0wiCQh/AD4TEYtL1tk1Ip5O338c+EpEvDst1C8E9k9XfQA4ICJe6O6YI7VrrODpLdMrB+zIDpu7yVQKNJimmVlfZD2gZMWu/oqIjZK+ANwMNAFzI2KxpHOABRFxAzBL0keBjcALwAnpti9I+leSQARwTk8BBZJMpdT23QUUF+jNzDJXqKHvR2mXWM4zW6Y3I9TVypdd5nqKmTU8D33fDfH6pV8nDOqhnuKAYmaWuYIFlSTrGj0aLhp8StdZiru+zMwqonBBZd48WLYMmtd0U0/xvSlmZhVRuKCyaVMZK7rry8ysIip29VceduBFPnnaGFhwVN5NMTNrSIW6+qtFigUAUtf3oAwfDs8/X81mmZnVLF/9VY7uAqXrKWZmFVPMoNId11PMzCqm8YKKmZlVjIOKmZllpnBBpdvLDnzTo5lZRRUqqKxja0LdfCQX6c3MKqpQQUUEis4eUp9ykd7MrKIKFVSa2Jh3E8zMGlqhgspANnoQSTOzHBUqqHQZUMD1FDOzKihUUOmS5HqKmVkVNEZQKdD4ZmZmtawxgkpTU94tMDNrCI0RVMp6yIqZmfVXYwSV0aPzboGZWUNojKAye3beLTAzawjFDyq+8svMrGqKH1R85ZeZWdUUP6j4yi8zs6opflDxlV9mZlVT/KDiK7/MzKqm0EElwFd+mZlVUaGDyqts5Su/zMyqqKJBRdKRkh6XtETSGZ0s/7KkRyU9LOl2SaNLlm2S9GD6uqG3x95AEycyt78fwczMeqFiQUVSE/AD4IPAWOA4SWM7rPa/QEtEjAeuBv6jZNm6iJiQvj5azjFfYys2I5Yxmmn8mP8Z7SzFzKyaBlZw3wcCSyJiKYCkK4GjgUfbV4iIO0rWvxeY2p8DPsI+NLEAgCFDYI7LKWZmVVXJoDICWF4y3QZM7Gb9E4Ffl0w3S1oAbAS+FRHXdbaRpOnA9GRqfyC54Gv2bJdTzOrZhg0baGtrY/369Xk3pRCam5sZOXIkgwYNquhxKhlUyiZpKtACHFoye3RErJC0J/BbSY9ExJ86bhsRc4A5AMOGtcQBB8Cdd1aj1WZWSW1tbQwbNowxY8YgdftcV+tBRLBy5Ura2trYY489KnqsShbqVwC7l0yPTOe9gaTJwFnARyPi1fb5EbEi/bkUuBPYr6cDSvDaa/1rtJnVhvXr1zN8+HAHlAxIYvjw4VXJ+ioZVP4A7CVpD0lbAccCb7iKS9J+wCUkAeXZkvnbSxqcvt8ReA8ltZiuSLBhQ4afwMxy5YCSnWqdy4oFlYjYCHwBuBn4I/CziFgs6RxJ7Vdz/SewDfDzDpcOvwtYIOkh4A6SmkpZQcWZipllYeXKlUyYMIEJEybw1re+lREjRmyZfq2HXzQLFixg1qxZvTremDFjeP755/vT5JpQ0ZpKRNwE3NRh3tdL3k/uYru7gX16e7wBA5ypmDWq1lY46yx46ikYNar/F+sMHz6cBx98EIBvfOMbbLPNNvzTP/3TluUbN25k4MDOf4W2tLTQ0tLS94PXsULdUe/uL7PG1NoK06fDk08mT7t48slkurU12+OccMIJnHzyyUycOJHTTz+d+++/n4MOOoj99tuPgw8+mMcffxyAO++8kw9/+MNAEpA+97nPcdhhh7Hnnnty/vnnl328ZcuWccQRRzB+/HgmTZrEU089BcDPf/5zxo0bx7777svf/u3fArB48WIOPPBAJkyYwPjx43niiSey/fBlqomrv7Li7i+zYjr1VEiThk7dey+8+uob561dCyeeCD/8YefbTJgA3/1u79vS1tbG3XffTVNTEy+//DLz589n4MCB3HbbbXz1q1/lF7/4xZu2eeyxx7jjjjtYvXo173znO5kxY0ZZl/Z+8YtfZNq0aUybNo25c+cya9YsrrvuOs455xxuvvlmRowYwUsvvQTAxRdfzCmnnMKUKVN47bXX2JTTCO2FCyrOVMwaT8eA0tP8/vjkJz9JU/qcplWrVjFt2jSeeOIJJLGhi19AH/rQhxg8eDCDBw9m55135plnnmHkyJE9Huuee+7hmmuuAeCzn/0sp59+OgDvec97OOGEE/jUpz7FMcccA8BBBx3E7NmzaWtr45hjjmGvvfbK4uP2WuGCijMVs+LpKaMYMybp8upo9Ojs71sbOnTolvf//M//zOGHH861117LsmXLOOywwzrdZvDgwVveNzU1sXHjxn614eKLL+a+++7jxhtv5IADDmDhwoV85jOfYeLEidx4440cddRRXHLJJRxxxBH9Ok5fFKqmsnJl8hozJvu+VDOrXbNnJ0MzlRoypPJPvli1ahUjRowAYN68eZnv/+CDD+bKK68EoLW1lUMOOQSAP/3pT0ycOJFzzjmHnXbaieXLl7N06VL23HNPZs2axdFHH83DDz+ceXvKUaigsnlz8rNSRTozq01TpsCcOUlmIiU/58yp/FBNp59+OmeeeSb77bdfv7MPgPHjxzNy5EhGjhzJl7/8ZS644AIuvfRSxo8fz09/+lO+973vAXDaaaexzz77MG7cOA4++GD23XdffvaznzFu3DgmTJjAokWLOP744/vdnr5QRORy4EqQWoJ0QElIvljLluXXHjPruz/+8Y+8613vyrsZhdLZOZW0MCIyu/65UJlKR+nVd2ZmViWFDiqjRuXdAjOzxlLYoFKNIp2Zmb1RoYJKeuk4u+1WnSKdmZm9UaHuUxk9GpYuhVtugb33zrs1ZmaNp1CZyoD006xdm287zMwaVaGCypo1yc+JE30DpJn1T3+GvodkUMm7776702Xz5s3jC1/4QtZNrgmFCirPPJP8rOQopWZWo1pbk78mBwzI5K/K9qHvH3zwQU4++WS+9KUvbZneaqutety+u6BSZIUKKh3v41y7Nnm+gpkVXJXGvl+4cCGHHnooBxxwAB/4wAd4+umnATj//PMZO3Ys48eP59hjj2XZsmVcfPHFnHfeeUyYMIH58+eXtf9zzz2XcePGMW7cOL6bDnj2yiuv8KEPfYh9992XcePGcdVVVwFwxhlnbDlm6XNe8laoQn1nfAOkWQHUwNj3EcEXv/hFrr/+enbaaSeuuuoqzjrrLObOncu3vvUt/vznPzN48GBeeukltttuO04++eQ3PdirOwsXLuTSSy/lvvvuIyKYOHEihx56KEuXLmW33XbjxhtvBJLxxlauXMm1117LY489hqQtw9/XgkJlKp3xDZBmDaAKY9+/+uqrLFq0iPe9731MmDCBb37zm7S1tQHJmF1Tpkzhsssu6/JpkD35/e9/z8c//nGGDh3KNttswzHHHMP8+fPZZ599uPXWW/nKV77C/Pnz2Xbbbdl2221pbm7mxBNP5JprrmFIx9E0c1T4TOWoo/JugZn1Ww2MfR8R7L333txzzz1vWnbjjTdy11138ctf/pLZs2fzyCOPZHJMgHe84x088MAD3HTTTXzta19j0qRJfP3rX+f+++/n9ttv5+qrr+b73/8+v/3tbzM7Zn8UPlO56aa8W2BmFVeFse8HDx7Mc889tyWobNiwgcWLF7N582aWL1/O4Ycfzre//W1WrVrFmjVrGDZsGKtXry57/4cccgjXXXcda9eu5ZVXXuHaa6/lkEMO4S9/+QtDhgxh6tSpnHbaaTzwwAOsWbOGVatWcdRRR3Heeefx0EMPZfY5+6vwmYprKmYNoH34jLPOSv7TjxqVBJQMh9UYMGAAV199NbNmzWLVqlVs3LiRU089lXe84x1MnTqVVatWERHMmjWL7bbbjo985CN84hOf4Prrr+eCCy7Y8iyUdvPmzeO6667bMn3vvfdywgkncOCBBwJw0kknsd9++3HzzTdz2mmnMWDAAAYNGsRFF13E6tWrOfroo1m/fj0RwbnnnpvZ5+yvQg99DzB8ODz/fE4NMrM+89D32fPQ9xlYvz7vFpiZNY7CB5VXXvENkGZm1VL4oAJwyil5t8DMrDE0RFBZuTLvFphZXxSp5pu3ap3LhggqADNn5t0CM+uN5uZmVq5c6cCSgYhg5cqVNDc3V/xYhb/6q9TYsbB4cRUbZGZ9tmHDBtra2ljvq20y0dzczMiRIxk0aNAb5md99Veh7lNpaoJNm7pe/uijIHW9fMYMuPDC7NtlZr03aNAg9thjj7ybYb1UqExlzz1b4s9/7jpTMTOzjlqIWNDNn9u9U6iayg47dJ+JmJlZZRUqqACcfHLeLTAza1yF6v6StBp4HPYeC81b590eM7Pat4yI5zPr4ylUoR54PMurGOqZpAU+Fz4PpXwuXudz8TpJmRaiC9f9ZWZm+XFQMTOzzBQtqMzJuwE1xOci4fPwOp+L1/lcvC7Tc1GoQr2ZmeWraJmKmZnlqBBBRdKRkh6XtETSGXm3p9Ik7S7pDkmPSlos6ZR0/g6SbpX0RPpz+3S+JJ2fnp+HJe2f7yfInqQmSf8r6Vfp9B6S7ks/81WStkrnD06nl6TLx+Ta8IxJ2k7S1ZIek/RHSQc16vdC0pfS/x+LJF0hqblRvheS5kp6VtKiknm9/h5Impau/4SkaeUcu+6DiqQm4AfAB4GxwHGSxubbqorbCPxjRIwF3g18Pv3MZwC3R8RewO3pNCTnZq/0NR24qPpNrrhTgD+WTH8bOC8i3g68CJyYzj8ReDGdf166XpF8D/hNRPwNsC/JOWm474WkEcAsoCUixgFNwLE0zvdiHnBkh3m9+h5I2gE4G5gIHAic3R6IuhURdf0CDgJuLpk+Ezgz73ZV+RxcD7wPeBzYNZ23K8l9OwCXAMeVrL9lvSK8gJHpf5IjgF8BAp4HBnb8jgA3Awel7wem6ynvz5DRedgW+HPHz9OI3wtgBLAc2CH9d/4V8IFG+l4AY4BFff0eAMcBl5TMf8N6Xb3qPlPh9S9Pu7Z0XkNI0/T9gPuAXSLi6XTRX4Fd0vdFP0ffBU4HNqfTw4GXImJjOl36ebeci3T5qnT9ItgDeA64NO0K/JGkoTTg9yIiVgD/BTwFPE3y77yQxvxetOvt96BP348iBJWGJWkb4BfAqRHxcumySP60KPylfZI+DDwbEQvzbksNGAjsD1wUEfsBr/B6FwfQUN+L7YGjSQLtbsBQ3twd1LAq+T0oQlBZAexeMj0ynVdokgaRBJTWiLgmnf2MpF3T5bsCz6bzi3yO3gN8VNIy4EqSLrDvAdtJah+GqPTzbjkX6fJtgaI8cLoNaIuI+9Lpq0mCTCN+LyYDf46I5yJiA3ANyXelEb8X7Xr7PejT96MIQeUPwF7pVR1bkRTjbsi5TRUlScB/A3+MiHNLFt0AtF+hMY2k1tI+//j0Ko93A6tK0uC6FhFnRsTIiBhD8m//24iYAtwBfCJdreO5aD9Hn0jXL8Rf7hHxV2C5pHemsyYBj9KA3wuSbq93SxqS/n9pPxcN970o0dvvwc3A+yVtn2Z+70/ndS/vYlJGBamjgP8D/gSclXd7qvB530uSuj4MPJi+jiLpA74deAK4DdghXV8kV8j9CXiE5IqY3D9HBc7LYcCv0vd7AvcDS4CfA4PT+c3p9JJ0+Z55tzvjczCB5JnaDwPXAds36vcC+BfgMWAR8FNgcKN8L4ArSGpJG0gy2BP78j0APpeekyXA35dzbN9Rb2ZmmSlC95eZmdUIBxUzM8uMg4qZmWXGQcXMzDLjoGJmZplxUDHrBUmbJD1Y8spsVGxJY0pHlTWrRwN7XsXMSqyLiAl5N8KsVjlTMcuApGWS/kPSI5Lul/T2dP4YSb9Nn1Nxu6RR6fxdJF0r6aH0dXC6qyZJP0yfA3KLpK1z+1BmfeCgYtY7W3fo/vp0ybJVEbEP8H2SkZMBLgB+HBHjgVbg/HT++cDvImJfkvG5Fqfz9wJ+EBF7Ay8Bf1fRT2OWMd9Rb9YLktZExDadzF8GHBERS9PBPv8aEcMlPU/yDIsN6fynI2JHSc8BIyPi1ZJ9jAFujeQhSkj6CjAoIr5ZhY9mlglnKmbZiS7e98arJe834bqn1RkHFbPsfLrk5z3p+7tJRk8GmALMT9/fDsyA5JHYkratViPNKsl/BZn1ztaSHiyZ/k1EtF9WvL2kh0myjePSeV8keRLjaSRPZfz7dP4pwBxJJ5JkJDNIRpU1q2uuqZhlIK2ptETE83m3xSxP7v4yM7PMOFMxM7PMOFMxM7PMOKiYmVlmHFTMzCwzDipmZpYZBxUzM8uMg4qZmWXm/wO1RsQlx7AQSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 23.1 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([384, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 110\n",
      "False Positive : 6\n",
      "False Negative : 35\n",
      "True Negative : 233\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 94.828 %\n",
      "- Recall : 75.862 %\n",
      "- F1 : 0.84291\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 86.94 %\n",
      "- Recall : 97.49 %\n",
      "- F1 : 0.91913\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 89.323 %\n",
      "- Precision : 90.884 %\n",
      "- Recall : 86.676 %\n",
      "- F1 : 0.8873\n",
      "- Average Confidence : 82.1 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Phemernr2-TF_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Validation, 89.323, 90.884, 86.676, 0.8873, 94.828, 75.862, 0.84291, 86.94, 97.49, 0.91913, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([166, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 54\n",
      "False Positive : 5\n",
      "False Negative : 8\n",
      "True Negative : 99\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 91.525 %\n",
      "- Recall : 87.097 %\n",
      "- F1 : 0.89256\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 92.523 %\n",
      "- Recall : 95.192 %\n",
      "- F1 : 0.93839\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 92.169 %\n",
      "- Precision : 92.024 %\n",
      "- Recall : 91.145 %\n",
      "- F1 : 0.91582\n",
      "- Average Confidence : 84.2 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Phemernr2-TF_2LMLP_DistilBERT_Finetuned_with_TopTermsVectors Test, 92.169, 92.024, 91.145, 0.91582, 91.525, 87.097, 0.89256, 92.523, 95.192, 0.93839, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
