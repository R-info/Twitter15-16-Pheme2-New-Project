{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-TF\"\n",
    "unique_name = \"BERT_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1705, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-TF_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>True</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>True</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580352540316946432</td>\n",
       "      <td>'No survivors' in #Germanwings crash says Fren...</td>\n",
       "      <td>False</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524983403775799297</td>\n",
       "      <td>Tragedy mounts as soldier shot this AM dies of...</td>\n",
       "      <td>True</td>\n",
       "      <td>ottawashooting-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544511915158810624</td>\n",
       "      <td>Watch the moment gunfire and explosions were h...</td>\n",
       "      <td>True</td>\n",
       "      <td>sydneysiege-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "1  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "2  580352540316946432  'No survivors' in #Germanwings crash says Fren...   \n",
       "3  524983403775799297  Tragedy mounts as soldier shot this AM dies of...   \n",
       "4  544511915158810624  Watch the moment gunfire and explosions were h...   \n",
       "\n",
       "   label                              topic      tvt2    tvt2_1      tvt2_2  \\\n",
       "0   True  germanwings-crash-all-rnr-threads  training  training    training   \n",
       "1   True       charliehebdo-all-rnr-threads  training  training    training   \n",
       "2  False  germanwings-crash-all-rnr-threads  training  training    training   \n",
       "3   True     ottawashooting-all-rnr-threads  training  training  validation   \n",
       "4   True        sydneysiege-all-rnr-threads  training  training    training   \n",
       "\n",
       "     tvt2_3  \n",
       "0  training  \n",
       "1  training  \n",
       "2  testting  \n",
       "3  training  \n",
       "4  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Massey Hall', 'in the window', 'Ottawa Police', 'by @LucilleClerc', 'CEO says', 'in Toronto', '#Prince #Toronto', 'shooting incident', '#cbcOTT #OTTnews', 'Banksy #JeSuisCharlie']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2-tf_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1705, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 1519)\n",
      "(384, 1519)\n",
      "(166, 1519)\n",
      "(1155, 1)\n",
      "(384, 1)\n",
      "(166, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 88.281\n",
      "Saving after new best accuracy : 89.583\n",
      "Saving after new best accuracy : 90.104\n",
      "Saving after new best accuracy : 90.625\n",
      "Saving after new best accuracy : 90.885\n",
      "-- Epoch 50, Train Loss : 0.0021967904758639634, Test Loss : 0.4717795252799988\n",
      "-- Epoch 100, Train Loss : 0.0005621041782433167, Test Loss : 0.581023633480072\n",
      "Saving after new best accuracy : 91.146\n",
      "-- Epoch 150, Train Loss : 0.00024573568589403294, Test Loss : 0.6501156687736511\n",
      "-- Epoch 200, Train Loss : 0.0001348351488559274, Test Loss : 0.7006849646568298\n",
      "-- Epoch 250, Train Loss : 8.393916505156085e-05, Test Loss : 0.7406131625175476\n",
      "-- Epoch 300, Train Loss : 5.666364813805558e-05, Test Loss : 0.7736936807632446\n",
      "-- Epoch 350, Train Loss : 4.046622689202195e-05, Test Loss : 0.8020877242088318\n",
      "-- Epoch 400, Train Loss : 3.012050865436322e-05, Test Loss : 0.8272389769554138\n",
      "-- Epoch 450, Train Loss : 2.313800246156461e-05, Test Loss : 0.8495488166809082\n",
      "-- Epoch 500, Train Loss : 1.8214843521491275e-05, Test Loss : 0.8695969581604004\n",
      "-- Epoch 550, Train Loss : 1.4623789184042835e-05, Test Loss : 0.8882279396057129\n",
      "-- Epoch 600, Train Loss : 1.1938964689761633e-05, Test Loss : 0.90582674741745\n",
      "-- Epoch 650, Train Loss : 9.880469292511407e-06, Test Loss : 0.9212958812713623\n",
      "-- Epoch 700, Train Loss : 8.269633781310404e-06, Test Loss : 0.9376317858695984\n",
      "-- Epoch 750, Train Loss : 6.988875213664869e-06, Test Loss : 0.9513672590255737\n",
      "-- Epoch 800, Train Loss : 5.9518753801057755e-06, Test Loss : 0.9644119143486023\n",
      "-- Epoch 850, Train Loss : 5.11176574491401e-06, Test Loss : 0.9768905639648438\n",
      "-- Epoch 900, Train Loss : 4.412730163494416e-06, Test Loss : 0.988860011100769\n",
      "-- Epoch 950, Train Loss : 3.834251657508503e-06, Test Loss : 1.000353217124939\n",
      "-- Epoch 1000, Train Loss : 3.3459971575666714e-06, Test Loss : 1.2303448915481567\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 23.28 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([384, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 122\n",
      "False Positive : 11\n",
      "False Negative : 23\n",
      "True Negative : 228\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 91.729 %\n",
      "- Recall : 84.138 %\n",
      "- F1 : 0.8777\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 90.837 %\n",
      "- Recall : 95.397 %\n",
      "- F1 : 0.93061\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 91.146 %\n",
      "- Precision : 91.283 %\n",
      "- Recall : 89.768 %\n",
      "- F1 : 0.90519\n",
      "- Average Confidence : 97.74 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Phemernr2-TF_2LMLP_BERT_Finetuned_with_TopTermsVectors Validation, 91.146, 91.283, 89.768, 0.90519, 91.729, 84.138, 0.8777, 90.837, 95.397, 0.93061, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([166, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 58\n",
      "False Positive : 6\n",
      "False Negative : 4\n",
      "True Negative : 98\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 90.625 %\n",
      "- Recall : 93.548 %\n",
      "- F1 : 0.92063\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 96.078 %\n",
      "- Recall : 94.231 %\n",
      "- F1 : 0.95146\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 93.976 %\n",
      "- Precision : 93.352 %\n",
      "- Recall : 93.89 %\n",
      "- F1 : 0.9362\n",
      "- Average Confidence : 99.52 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Phemernr2-TF_2LMLP_BERT_Finetuned_with_TopTermsVectors Test, 93.976, 93.352, 93.89, 0.9362, 90.625, 93.548, 0.92063, 96.078, 94.231, 0.95146, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
