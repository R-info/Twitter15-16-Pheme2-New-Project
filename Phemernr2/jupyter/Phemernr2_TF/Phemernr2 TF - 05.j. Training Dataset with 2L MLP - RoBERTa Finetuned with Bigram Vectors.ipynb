{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr2-TF\"\n",
    "unique_name = \"RoBERTa_Finetuned_with_TopTermsVectors\"\n",
    "tvt_set = \"tvt2_3\"\n",
    "\n",
    "bigram_limit = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1705, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr2-TF_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>tvt2</th>\n",
       "      <th>tvt2_1</th>\n",
       "      <th>tvt2_2</th>\n",
       "      <th>tvt2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580318210609696769</td>\n",
       "      <td>BREAKING - A Germanwings Airbus A320 plane rep...</td>\n",
       "      <td>True</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552798891994009601</td>\n",
       "      <td>Reports that two of the dead in the #CharlieHe...</td>\n",
       "      <td>True</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580352540316946432</td>\n",
       "      <td>'No survivors' in #Germanwings crash says Fren...</td>\n",
       "      <td>False</td>\n",
       "      <td>germanwings-crash-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524983403775799297</td>\n",
       "      <td>Tragedy mounts as soldier shot this AM dies of...</td>\n",
       "      <td>True</td>\n",
       "      <td>ottawashooting-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>validation</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544511915158810624</td>\n",
       "      <td>Watch the moment gunfire and explosions were h...</td>\n",
       "      <td>True</td>\n",
       "      <td>sydneysiege-all-rnr-threads</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>testting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                         tweet_text  \\\n",
       "0  580318210609696769  BREAKING - A Germanwings Airbus A320 plane rep...   \n",
       "1  552798891994009601  Reports that two of the dead in the #CharlieHe...   \n",
       "2  580352540316946432  'No survivors' in #Germanwings crash says Fren...   \n",
       "3  524983403775799297  Tragedy mounts as soldier shot this AM dies of...   \n",
       "4  544511915158810624  Watch the moment gunfire and explosions were h...   \n",
       "\n",
       "   label                              topic      tvt2    tvt2_1      tvt2_2  \\\n",
       "0   True  germanwings-crash-all-rnr-threads  training  training    training   \n",
       "1   True       charliehebdo-all-rnr-threads  training  training    training   \n",
       "2  False  germanwings-crash-all-rnr-threads  training  training    training   \n",
       "3   True     ottawashooting-all-rnr-threads  training  training  validation   \n",
       "4   True        sydneysiege-all-rnr-threads  training  training    training   \n",
       "\n",
       "     tvt2_3  \n",
       "0  training  \n",
       "1  training  \n",
       "2  testting  \n",
       "3  training  \n",
       "4  testting  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr2-tf_dataset.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_type = \"label\"\n",
    "labels_str = data[label_type].unique().tolist()\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [0], [0], [0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "    lab = labels_str.index(d[label_type])\n",
    "    labels.append([lab])\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e09753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Massey Hall', 'in the window', 'Ottawa Police', 'by @LucilleClerc', 'CEO says', 'in Toronto', '#Prince #Toronto', 'shooting incident', '#cbcOTT #OTTnews', 'Banksy #JeSuisCharlie']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_terms = []\n",
    "with open(\"../../data/processed/phemernr2-tf_best_terms.txt\", \"r\") as f:\n",
    "    for t in f.readlines():\n",
    "        vector_terms.append(t.strip())\n",
    "\n",
    "print(vector_terms[:10])\n",
    "len(vector_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340c288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "\n",
    "def text2unigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def text2bigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    bigrams = nltk.bigrams(text)\n",
    "    bigrams = map(' '.join, bigrams)\n",
    "    bigrams = [bgr for bgr in bigrams]\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "\n",
    "def text2trigrams(text):\n",
    "    text = tokenizer.tokenize(text.encode('ascii', 'ignore').decode('utf8'))\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    text = [t for t in text if t not in ['URL', '‘', '’']]\n",
    "    \n",
    "    trigrams = nltk.trigrams(text)\n",
    "    trigrams = map(' '.join, trigrams)\n",
    "    trigrams = [bgr for bgr in trigrams]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bigrams_vectors_generation(texts):\n",
    "    bigram_vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(bigram_vector_base) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in bigram_vector_base:\n",
    "                idx = bigram_vector_base.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        bigram_vectors.append(init_vec)\n",
    "    \n",
    "    return bigram_vectors\n",
    "\n",
    "\n",
    "def custom_vectors_generation(texts, vector_terms):\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        bigrams = text2bigrams(text)\n",
    "        trigrams = text2trigrams(text)\n",
    "\n",
    "        init_vec = [0.0 for _ in range(len(vector_terms) + 1)]\n",
    "        for bgr in bigrams:\n",
    "            if bgr in vector_terms:\n",
    "                idx = vector_terms.index(bgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        for tgr in trigrams:\n",
    "            if tgr in vector_terms:\n",
    "                idx = vector_terms.index(tgr)\n",
    "                init_vec[idx] = 1.0\n",
    "            else:\n",
    "                init_vec[-1] = 1.0\n",
    "        vectors.append(init_vec)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd75fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1705, 1519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['tweet_text'].tolist()\n",
    "# bigram_vectors = bigrams_vectors_generation(texts)\n",
    "terms_vectors = custom_vectors_generation(texts, vector_terms)\n",
    "\n",
    "vectors = np.concatenate([vectors, terms_vectors], axis=1)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d[tvt_set] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 1519)\n",
      "(384, 1519)\n",
      "(166, 1519)\n",
      "(1155, 1)\n",
      "(384, 1)\n",
      "(166, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        binary: bool = False,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x, binary=binary)\n",
    "                if binary:\n",
    "                    preds = np.array([p[0] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([v[0] for v in test_y])\n",
    "                else:\n",
    "                    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "                    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y])\n",
    "                \n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=label_target,\n",
    "                    predictions=preds,\n",
    "                    binary=binary\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x, binary=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            \n",
    "            if binary:\n",
    "                return preds\n",
    "            else:\n",
    "                _, preds = torch.max(preds, dim = 1)\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 91.667\n",
      "Saving after new best accuracy : 91.927\n",
      "Saving after new best accuracy : 92.448\n",
      "-- Epoch 50, Train Loss : 0.026530826813541353, Test Loss : 0.4406520128250122\n",
      "-- Epoch 100, Train Loss : 0.024575492134317756, Test Loss : 0.4699624478816986\n",
      "-- Epoch 150, Train Loss : 0.021589369396679103, Test Loss : 0.47490614652633667\n",
      "Saving after new best accuracy : 92.708\n",
      "-- Epoch 200, Train Loss : 0.01654884172603488, Test Loss : 0.47362256050109863\n",
      "-- Epoch 250, Train Loss : 0.010635361075401306, Test Loss : 0.48692768812179565\n",
      "-- Epoch 300, Train Loss : 0.0056536957854405046, Test Loss : 0.5263721346855164\n",
      "-- Epoch 350, Train Loss : 0.002044628228759393, Test Loss : 0.581161379814148\n",
      "-- Epoch 400, Train Loss : 0.000900855302461423, Test Loss : 0.6319739818572998\n",
      "-- Epoch 450, Train Loss : 0.00048577583220321685, Test Loss : 0.6737378835678101\n",
      "-- Epoch 500, Train Loss : 0.00030816539947409183, Test Loss : 0.7046771049499512\n",
      "-- Epoch 550, Train Loss : 0.00020597816910594702, Test Loss : 0.734602689743042\n",
      "-- Epoch 600, Train Loss : 0.00015038171477499418, Test Loss : 0.7564342021942139\n",
      "-- Epoch 650, Train Loss : 0.00011301278209430166, Test Loss : 0.7773964405059814\n",
      "-- Epoch 700, Train Loss : 8.895357314031571e-05, Test Loss : 0.7944790720939636\n",
      "-- Epoch 750, Train Loss : 7.048808947729412e-05, Test Loss : 0.812151312828064\n",
      "-- Epoch 800, Train Loss : 5.6810859859979246e-05, Test Loss : 0.8287398219108582\n",
      "-- Epoch 850, Train Loss : 4.696592804975808e-05, Test Loss : 0.8426200151443481\n",
      "-- Epoch 900, Train Loss : 3.930818729713792e-05, Test Loss : 0.8552494049072266\n",
      "-- Epoch 950, Train Loss : 3.30473885696847e-05, Test Loss : 0.8685778379440308\n",
      "-- Epoch 1000, Train Loss : 2.828066362781101e-05, Test Loss : 0.8799533843994141\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 23.15 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([384, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 129\n",
      "False Positive : 12\n",
      "False Negative : 16\n",
      "True Negative : 227\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 91.489 %\n",
      "- Recall : 88.966 %\n",
      "- F1 : 0.9021\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 93.416 %\n",
      "- Recall : 94.979 %\n",
      "- F1 : 0.94191\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 92.708 %\n",
      "- Precision : 92.452 %\n",
      "- Recall : 91.972 %\n",
      "- F1 : 0.92211\n",
      "- Average Confidence : 98.99 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Phemernr2-TF_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Validation, 92.708, 92.452, 91.972, 0.92211, 91.489, 88.966, 0.9021, 93.416, 94.979, 0.94191, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([166, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 58\n",
      "False Positive : 2\n",
      "False Negative : 4\n",
      "True Negative : 102\n",
      "\n",
      "Class False Evaluation\n",
      "- Precision : 96.667 %\n",
      "- Recall : 93.548 %\n",
      "- F1 : 0.95082\n",
      "\n",
      "Class True Evaluation\n",
      "- Precision : 96.226 %\n",
      "- Recall : 98.077 %\n",
      "- F1 : 0.97143\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 96.386 %\n",
      "- Precision : 96.447 %\n",
      "- Recall : 95.813 %\n",
      "- F1 : 0.96129\n",
      "- Average Confidence : 99.45 %\n",
      "Model, Combined,,,,False,,,True,,,\n",
      "Phemernr2-TF_2LMLP_RoBERTa_Finetuned_with_TopTermsVectors Test, 96.386, 96.447, 95.813, 0.96129, 96.667, 93.548, 0.95082, 96.226, 98.077, 0.97143, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "binary = True\n",
    "\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_2LMLP_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=1, criterion=nn.BCELoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                binary=binary,\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in val_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors, binary=binary)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "if binary:\n",
    "    preds = np.array([p[0] for p in preds])\n",
    "    label_target = np.array([v[0] for v in test_labels])\n",
    "else:\n",
    "    preds = np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()])\n",
    "    label_target = np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels])\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=label_target,\n",
    "    predictions=preds,\n",
    "    binary=True,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a3e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
